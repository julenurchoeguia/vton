script = "autoencodeur_trainer.py" # not used for now
path_dataset_train = "datasets/data_cats/train"
path_dataset_test = "datasets/data_cats/test"
path_dataset_val = "datasets/data_cats/val"

[wandb]
mode = "online"  # online : enregistrer le test sur wandb, offline : ne pas enregistrer le test sur wandb
entity = "finegrain-cs"
project = "cats"
name = "autoencodeur_cats_refiners"    

[models]
autoencoder = {train = true}#{checkpoint="/home/daniel/work/vton/notebooks/autoencodeur_models/test.safetensors", train=true}

[training]
duration = "20:epoch"
seed = 42
gpu_index = 0
num_epochs = 20
batch_size = 1
gradient_accumulation = "1:step"
evaluation_interval = "1:epoch"
evaluation_seed = 42


[optimizer]
optimizer = "Adam" # "AdamW", "AdamW8bit", "Lion8bit", "Prodigy", "SGD", "Adam"
learning_rate = 1e-4


[scheduler]
scheduler_type = "ConstantLR"
update_interval = "1:step"

[dropout]
dropout_probability = 0.1


[dataset]
# on a besoin de le laisser Ã  cause du model BaseConfig

[checkpointing]
save_folder = "notebooks/models/training1"
save_interval = "1:epoch"

