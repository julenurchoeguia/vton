{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDi6KKK+ZP3EKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAABrUlEQVR4Ae3TwQ0AMAyDQLf779yOweeyABLE582VBm4Jx94EiL9AAAFiAzHeAgSIDcR4CxAgNhDjLUCA2ECMtwABYgMx3gIEiA3EeAsQIDYQ4y1AgNhAjLcAAWIDMd4CBIgNxHgLECA2EOMtQIDYQIy3AAFiAzHeAgSIDcR4CxAgNhDjLUCA2ECMtwABYgMx3gIEiA3EeAsQIDYQ4y1AgNhAjLcAAWIDMd4CBIgNxHgLECA2EOMtQIDYQIy3AAFiAzHeAgSIDcR4CxAgNhDjLUCA2ECMtwABYgMx3gIEiA3EeAsQIDYQ4y1AgNhAjLcAAWIDMd4CBIgNxHgLECA2EOMtQIDYQIy3AAFiAzHeAgSIDcR4CxAgNhDjLUCA2ECMtwABYgMx3gIEiA3EeAsQIDYQ4y1AgNhAjLcAAWIDMd4CBIgNxHgLECA2EOMtQIDYQIy3AAFiAzHeAgSIDcR4CxAgNhDjLUCA2ECMtwABYgMx3gIEiA3EeAsQIDYQ4y1AgNhAjLcAAWIDMd4CBIgNxHgLECA2EOMtQIDYQIy3AAFiAzHeAgSIDcR4C4gDfM/hAf+qY6fJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.new('RGB', (128, 128), color = 'red')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = np.array(img)\n",
    "img_array = img_array/255\n",
    "img_array = img_array.transpose(2, 0, 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "img_tensor = torch.from_numpy(img_array)\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(image: Image) -> torch.Tensor:\n",
    "    img_array = np.array(image)\n",
    "    img_array = img_array/255\n",
    "    img_array = img_array.transpose(2, 0, 1).astype(np.float32)\n",
    "    img_tensor = torch.from_numpy(img_array)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    return img_tensor\n",
    "\n",
    "def tensor_to_image(tensor: torch.Tensor) -> Image:\n",
    "    img_array = tensor.squeeze(0).numpy()\n",
    "    img_array = img_array.transpose(1, 2, 0)\n",
    "    img_array = img_array*255\n",
    "    img_array = img_array.astype(np.uint8)\n",
    "    image = Image.fromarray(img_array)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = tuple[int, int, int]\n",
    "def create_empty_image(resolution: int, color: color=(0,0,0)) -> Image:\n",
    "    return Image.new('RGB', (resolution, resolution), color = color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_tensor = image_to_tensor(create_empty_image(128, color=(255, 0, 0)))\n",
    "target_tensor = image_to_tensor(create_empty_image(128, color=(0, 255, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, loss :  138.296616)\n",
      "step : 1, loss :  136.697449)\n",
      "step : 2, loss :  133.484924)\n",
      "step : 3, loss :  128.671936)\n",
      "step : 4, loss :  122.261955)\n",
      "step : 5, loss :  114.252052)\n",
      "step : 6, loss :  104.648865)\n",
      "step : 7, loss :  93.452911)\n",
      "step : 8, loss :  80.680923)\n",
      "step : 9, loss :  66.360771)\n",
      "step : 10, loss :  50.546074)\n",
      "step : 11, loss :  33.437279)\n",
      "step : 12, loss :  16.151430)\n",
      "step : 13, loss :  12.513351)\n",
      "step : 14, loss :  28.872328)\n",
      "step : 15, loss :  46.138206)\n",
      "step : 16, loss :  62.219967)\n",
      "step : 17, loss :  76.840500)\n",
      "step : 18, loss :  89.922966)\n",
      "step : 19, loss :  101.424759)\n",
      "step : 20, loss :  111.351677)\n",
      "step : 21, loss :  119.686073)\n",
      "step : 22, loss :  126.411407)\n",
      "step : 23, loss :  131.542572)\n",
      "step : 24, loss :  135.065720)\n",
      "step : 25, loss :  136.994492)\n",
      "step : 26, loss :  137.310104)\n",
      "step : 27, loss :  136.031906)\n",
      "step : 28, loss :  133.138245)\n",
      "step : 29, loss :  128.650726)\n",
      "step : 30, loss :  122.554878)\n",
      "step : 31, loss :  114.865601)\n",
      "step : 32, loss :  105.574638)\n",
      "step : 33, loss :  94.690163)\n",
      "step : 34, loss :  82.230988)\n",
      "step : 35, loss :  68.205917)\n",
      "step : 36, loss :  52.677410)\n",
      "step : 37, loss :  35.784958)\n",
      "step : 38, loss :  18.303883)\n",
      "step : 39, loss :  10.614962)\n",
      "step : 40, loss :  25.991240)\n",
      "step : 41, loss :  43.279587)\n",
      "step : 42, loss :  59.451866)\n",
      "step : 43, loss :  74.175606)\n",
      "step : 44, loss :  87.357025)\n",
      "step : 45, loss :  98.966652)\n",
      "step : 46, loss :  108.992569)\n",
      "step : 47, loss :  117.423042)\n",
      "step : 48, loss :  124.252266)\n",
      "step : 49, loss :  129.487137)\n",
      "step : 50, loss :  133.113083)\n",
      "step : 51, loss :  135.141891)\n",
      "step : 52, loss :  135.560196)\n",
      "step : 53, loss :  134.377563)\n",
      "step : 54, loss :  131.583038)\n",
      "step : 55, loss :  127.185371)\n",
      "step : 56, loss :  121.192436)\n",
      "step : 57, loss :  113.589233)\n",
      "step : 58, loss :  104.395752)\n",
      "step : 59, loss :  93.603012)\n",
      "step : 60, loss :  81.228188)\n",
      "step : 61, loss :  67.292099)\n",
      "step : 62, loss :  51.831722)\n",
      "step : 63, loss :  34.984867)\n",
      "step : 64, loss :  17.479761)\n",
      "step : 65, loss :  10.267719)\n",
      "step : 66, loss :  26.056404)\n",
      "step : 67, loss :  43.264950)\n",
      "step : 68, loss :  59.278881)\n",
      "step : 69, loss :  73.820259)\n",
      "step : 70, loss :  86.814484)\n",
      "step : 71, loss :  98.231873)\n",
      "step : 72, loss :  108.053520)\n",
      "step : 73, loss :  116.294540)\n",
      "step : 74, loss :  122.913841)\n",
      "step : 75, loss :  127.947227)\n",
      "step : 76, loss :  131.370529)\n",
      "step : 77, loss :  133.183151)\n",
      "step : 78, loss :  133.397369)\n",
      "step : 79, loss :  131.994705)\n",
      "step : 80, loss :  128.997269)\n",
      "step : 81, loss :  124.391708)\n",
      "step : 82, loss :  118.182541)\n",
      "step : 83, loss :  110.363617)\n",
      "step : 84, loss :  100.950043)\n",
      "step : 85, loss :  89.940910)\n",
      "step : 86, loss :  77.343880)\n",
      "step : 87, loss :  63.182453)\n",
      "step : 88, loss :  47.492908)\n",
      "step : 89, loss :  30.435486)\n",
      "step : 90, loss :  13.076487)\n",
      "step : 91, loss :  12.702277)\n",
      "step : 92, loss :  29.994394)\n",
      "step : 93, loss :  47.057892)\n",
      "step : 94, loss :  62.758331)\n",
      "step : 95, loss :  76.935829)\n",
      "step : 96, loss :  89.545654)\n",
      "step : 97, loss :  100.569794)\n",
      "step : 98, loss :  109.994675)\n",
      "step : 99, loss :  117.815361)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDlISfIj5/hH8qfk+tMh/1Ef+6P5U+rWx785PmeoZPrRk+tFFMnmfcMn1oyfWiigOZ9wyfWjJ9aKKA5n3DJ9aMn1oooDmfcMn1oyfWiigOZ9wyfWjJ9aKKA5n3DJ9as6fzqVqDyDMn8xVarOnf8hO0/67J/6EKmfwsak77lOH/UR/7o/lT6ZD/qI/8AdH8qfTjsE/iYUUUUyQooooAKKKKACiiigAooooAKKKKACrOnf8hO0/67J/6EKrVZ07/kJ2n/AF2T/wBCFTP4WC3KcP8AqI/90fyp9Mh/1Ef+6P5U+nHYqfxMKKKKZIUUUUAFFFFABRRRQAUUUUAFFFFABVnTv+Qnaf8AXZP/AEIVWqzp3/ITtP8Arsn/AKEKmfwsFuU4f9RH/uj+VPpkP+oj/wB0fyp9OOxU/iYUUUUyQooooAKKKKACiiigAooooAKKKKACrOnf8hO0/wCuyf8AoQqtVnTv+Qnaf9dk/wDQhUz+FgtynD/qI/8AdH8qfTIf9RH/ALo/lT6cdip/EwooopkhRRRQAUUUUAFFFFABRRRQAUUUUAFWdO/5Cdp/12T/ANCFVqs6d/yE7T/rsn/oQqZ/CwW5Th/1Ef8Auj+VPpkP+oj/AN0fyp9OOxU/iYUUUUyQooooAKKKKACiiigAooooAKKKKACrOnf8hO0/67J/6EKrVZ07/kJ2n/XZP/QhUz+FgtynD/qI/wDdH8qfTIf9RH/uj+VPpx2Kn8TCiiimSFFFFABRRRQAUUUUAFFFFABRRRQAVZ07/kJ2n/XZP/QhVarOnf8AITtP+uyf+hCpn8LBblOH/UR/7o/lT6bED5KcH7op2D6Uozjbc0nTnzPQKKMH0owfSnzx7k+zn2YUUYPpRg+lHPHuHs59mFFGD6UYPpRzx7h7OfZhRRg+lGD6Uc8e4ezn2YUUYPpRg+lHPHuHs59mFFGD6UYPpRzx7h7OfZhVnTv+Qnaf9dk/9CFVsH0qxYsseoWzuwVFlUszHAAyOTUznHleo+SS1aP/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAB3klEQVR4Ae3ToY0CARQG4V1AQRAXksVBAgLcJWgcoUkqQ5w5iaUCyvgE8xqYl5n842N1+znvh04Y+L2+FvPl/3O9E/SYw+WwmaXBGiiA9T8UoADYAMa3gAJgAxjfAgqADWB8CygANoDxLaAA2ADGt4ACYAMY3wIKgA1gfAsoADaA8S2gANgAxreAAmADGN8CCoANYHwLKAA2gPEtoADYAMa3gAJgAxjfAgqADWB8CygANoDxLaAA2ADGt4ACYAMY3wIKgA1gfAsoADaA8S2gANgAxreAAmADGN8CCoANYHwLKAA2gPEtoADYAMa3gAJgAxjfAgqADWB8CygANoDxLaAA2ADGt4ACYAMY3wIKgA1gfAsoADaA8S2gANgAxreAAmADGN8CCoANYHwLKAA2gPEtoADYAMa3gAJgAxjfAgqADWB8CygANoDxLaAA2ADGt4ACYAMY3wIKgA1gfAsoADaA8S2gANgAxreAAmADGN8CCoANYHwLKAA2gPEtoADYAMa3gAJgAxjfAgqADWB8CygANoDxLaAA2ADGt4ACYAMY3wIKgA1gfAsoADaA8S2gANgAxreAAmADGN8CCoANYHwLKAA2gPEtoADYAMa3ABxg/NuO7+mIv/hW/P00fQAz0QiOYZ35bgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init_tensor.grad  \n",
    "conv = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1)\n",
    "lr = 1e-5\n",
    "num_step = 100\n",
    "\n",
    "for step in range(num_step):\n",
    "    y = conv(init_tensor)\n",
    "    loss = (y - target_tensor).norm()\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(f'step : {step}, loss : {loss.item(): 3f})')\n",
    "        for param in conv.parameters():\n",
    "            assert param.grad is not None\n",
    "            param -= lr * param.grad\n",
    "    # conv.zero_grad()\n",
    "\n",
    "result = conv(init_tensor)\n",
    "tensor_to_image(result.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDlISfIj5/hH8qfk+tMh/1Ef+6P5U+rWx785PmeoZPrRk+tFFMnmfcMn1oyfWiigOZ9wyfWjJ9aKKA5n3DJ9aMn1oooDmfcMn1oyfWiigOZ9wyfWjJ9aKKA5n3DJ9as6fzqVqDyDMn8xVarOnf8hO0/67J/6EKmfwsak77lOH/UR/7o/lT6ZD/qI/8AdH8qfTjsE/iYUUUUyQooooAKKKKACiiigAooooAKKKKACrOnf8hO0/67J/6EKrVZ07/kJ2n/AF2T/wBCFTP4WC3KcP8AqI/90fyp9Mh/1Ef+6P5U+nHYqfxMKKKKZIUUUUAFFFFABRRRQAUUUUAFFFFABVnTv+Qnaf8AXZP/AEIVWqzp3/ITtP8Arsn/AKEKmfwsFuU4f9RH/uj+VPpkP+oj/wB0fyp9OOxU/iYUUUUyQooooAKKKKACiiigAooooAKKKKACrOnf8hO0/wCuyf8AoQqtVnTv+Qnaf9dk/wDQhUz+FgtynD/qI/8AdH8qfTIf9RH/ALo/lT6cdip/EwooopkhRRRQAUUUUAFFFFABRRRQAUUUUAFWdO/5Cdp/12T/ANCFVqs6d/yE7T/rsn/oQqZ/CwW5Th/1Ef8Auj+VPpkP+oj/AN0fyp9OOxU/iYUUUUyQooooAKKKKACiiigAooooAKKKKACrOnf8hO0/67J/6EKrVZ07/kJ2n/XZP/QhUz+FgtynD/qI/wDdH8qfTIf9RH/uj+VPpx2Kn8TCiiimSFFFFABRRRQAUUUUAFFFFABRRRQAVZ07/kJ2n/XZP/QhVarOnf8AITtP+uyf+hCpn8LBblOH/UR/7o/lT6bED5KcH7op2D6Uozjbc0nTnzPQKKMH0owfSnzx7k+zn2YUUYPpRg+lHPHuHs59mFFGD6UYPpRzx7h7OfZhRRg+lGD6Uc8e4ezn2YUUYPpRg+lHPHuHs59mFFGD6UYPpRzx7h7OfZhVnTv+Qnaf9dk/9CFVsH0qxYsseoWzuwVFlUszHAAyOTUznHleo+SS1aP/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAB3klEQVR4Ae3ToY0CARQG4V1AQRAXksVBAgLcJWgcoUkqQ5w5iaUCyvgE8xqYl5n842N1+znvh04Y+L2+FvPl/3O9E/SYw+WwmaXBGiiA9T8UoADYAMa3gAJgAxjfAgqADWB8CygANoDxLaAA2ADGt4ACYAMY3wIKgA1gfAsoADaA8S2gANgAxreAAmADGN8CCoANYHwLKAA2gPEtoADYAMa3gAJgAxjfAgqADWB8CygANoDxLaAA2ADGt4ACYAMY3wIKgA1gfAsoADaA8S2gANgAxreAAmADGN8CCoANYHwLKAA2gPEtoADYAMa3gAJgAxjfAgqADWB8CygANoDxLaAA2ADGt4ACYAMY3wIKgA1gfAsoADaA8S2gANgAxreAAmADGN8CCoANYHwLKAA2gPEtoADYAMa3gAJgAxjfAgqADWB8CygANoDxLaAA2ADGt4ACYAMY3wIKgA1gfAsoADaA8S2gANgAxreAAmADGN8CCoANYHwLKAA2gPEtoADYAMa3gAJgAxjfAgqADWB8CygANoDxLaAA2ADGt4ACYAMY3wIKgA1gfAsoADaA8S2gANgAxreAAmADGN8CCoANYHwLKAA2gPEtoADYAMa3ABxg/NuO7+mIv/hW/P00fQAz0QiOYZ35bgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_to_image(conv(init_tensor).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDWooor80PyAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAABr0lEQVR4Ae3TwREAMAiEQJP+ezbpYj/YADPgndnpoIEL2aG/gQLgNyhAAbABjG8BBcAGML4FFAAbwPgWUABsAONbQAGwAYxvAQXABjC+BRQAG8D4FlAAbADjW0ABsAGMbwEFwAYwvgUUABvA+BZQAGwA41tAAbABjG8BBcAGML4FFAAbwPgWUABsAONbQAGwAYxvAQXABjC+BRQAG8D4FlAAbADjW0ABsAGMbwEFwAYwvgUUABvA+BZQAGwA41tAAbABjG8BBcAGML4FFAAbwPgWUABsAONbQAGwAYxvAQXABjC+BRQAG8D4FlAAbADjW0ABsAGMbwEFwAYwvgUUABvA+BZQAGwA41tAAbABjG8BBcAGML4FFAAbwPgWUABsAONbQAGwAYxvAQXABjC+BRQAG8D4FlAAbADjW0ABsAGMbwEFwAYwvgUUABvA+BZQAGwA41tAAbABjG8BBcAGML4FFAAbwPgWUABsAONbQAGwAYxvAQXABjC+BRQAG8D4FlAAbADjW0ABsAGMbwEFwAYwvgUUABvA+BZQAGwA41tAAbABjG8BBcAGML4F4AAPzuIB/0LykZIAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_to_image(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features: int=1, out_features: int=1) -> None:\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x @ self.weight.t() + self.bias\n",
    "\n",
    "linear = Linear(in_features=3, out_features=3)\n",
    "x = torch.randn(1, 3)\n",
    "target_tensor = torch.randn(1, 3)\n",
    "y = linear(x)\n",
    "loss = ((y - target_tensor)**2).mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7509,  0.4282, -0.6134],\n",
       "        [-2.1181,  1.2078, -1.7301],\n",
       "        [ 2.4860, -1.4176,  2.0306]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resblock(nn.Module):\n",
    "    def __init__(self, in_channels : int = 1, out_channels : int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n",
    "        self.activation = nn.SiLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n",
    "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        y = self.conv1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.conv2(y)\n",
    "        # y = self.activation(y)\n",
    "        return y + x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/laure/tuto_pytorch/autoencoder_laure.ipynb Cell 14\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/laure/tuto_pytorch/autoencoder_laure.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_step):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/laure/tuto_pytorch/autoencoder_laure.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     y \u001b[39m=\u001b[39m block(init_tensor)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/laure/tuto_pytorch/autoencoder_laure.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     loss \u001b[39m=\u001b[39m (y \u001b[39m-\u001b[39;49m target_tensor)\u001b[39m.\u001b[39mnorm()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/laure/tuto_pytorch/autoencoder_laure.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/laure/tuto_pytorch/autoencoder_laure.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "block = Resblock(in_channels = 3, out_channels =3)\n",
    "\n",
    "lr = 1e-5\n",
    "num_step = 10000\n",
    "for step in range(num_step):\n",
    "    y = block(init_tensor)\n",
    "    loss = (y - target_tensor).norm()\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(f'step : {step}, loss : {loss.item(): 3f})')\n",
    "        for param in block.parameters():\n",
    "            assert param.grad is not None\n",
    "            param -= lr * param.grad\n",
    "    # conv.zero_grad()\n",
    "            \n",
    "result = conv(init_tensor)\n",
    "tensor_to_image(result.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_channels: int = 3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.silu = nn.SiLU()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.conv1(x)\n",
    "        y = self.maxpool(y)\n",
    "        y = self.silu(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.maxpool(y)\n",
    "        y = self.silu(y)\n",
    "        y = self.conv3(y)\n",
    "        y = self.maxpool(y)\n",
    "        y = self.silu(y)\n",
    "        y = self.conv4(y)\n",
    "        y = self.maxpool(y)\n",
    "        # y = self.silu(y)\n",
    "        return y\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_channels: int = 3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(256, 128, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, output_channels, 3, padding=1)\n",
    "        self.silu = nn.SiLU()\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.conv1(x)\n",
    "        y = self.upsample(y)\n",
    "        y = self.silu(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.upsample(y)\n",
    "        y = self.silu(y)\n",
    "        y = self.conv3(y)\n",
    "        y = self.upsample(y)\n",
    "        y = self.silu(y)\n",
    "        y = self.conv4(y)\n",
    "        # y = self.silu(y)\n",
    "        y = self.upsample(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__() # type: ignore\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.decoder(self.encoder(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self) -> None:\n",
    "        self.data = list(range(100))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f'Dataset(len={len(self)})'\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self)\n",
    "    \n",
    "    def __getitem__(self, key : str|int) -> int:\n",
    "        match key:\n",
    "            case key if isinstance(key, str):\n",
    "                raise ValueError('Dataset does not take string as index.')\n",
    "            case _:\n",
    "                return self.data[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "dataset[2]\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 : loss 127.6457290649414\n",
      "step 1 : loss 127.33029174804688\n",
      "step 2 : loss 127.00260162353516\n",
      "step 3 : loss 126.64268493652344\n",
      "step 4 : loss 126.22867584228516\n",
      "step 5 : loss 125.73936462402344\n",
      "step 6 : loss 125.13591003417969\n",
      "step 7 : loss 124.37490844726562\n",
      "step 8 : loss 123.40460205078125\n",
      "step 9 : loss 122.14845275878906\n",
      "step 10 : loss 120.51678466796875\n",
      "step 11 : loss 118.3977279663086\n",
      "step 12 : loss 115.65338134765625\n",
      "step 13 : loss 112.12434387207031\n",
      "step 14 : loss 107.61593627929688\n",
      "step 15 : loss 101.91558837890625\n",
      "step 16 : loss 94.80987548828125\n",
      "step 17 : loss 86.15779876708984\n",
      "step 18 : loss 76.09049224853516\n",
      "step 19 : loss 65.58273315429688\n",
      "step 20 : loss 57.867218017578125\n",
      "step 21 : loss 57.84002685546875\n",
      "step 22 : loss 60.51716613769531\n",
      "step 23 : loss 57.675254821777344\n",
      "step 24 : loss 50.589595794677734\n",
      "step 25 : loss 43.270164489746094\n",
      "step 26 : loss 39.01624298095703\n",
      "step 27 : loss 38.548274993896484\n",
      "step 28 : loss 40.0908203125\n",
      "step 29 : loss 41.796688079833984\n",
      "step 30 : loss 42.78792953491211\n",
      "step 31 : loss 42.820377349853516\n",
      "step 32 : loss 41.93498992919922\n",
      "step 33 : loss 40.30571365356445\n",
      "step 34 : loss 38.192535400390625\n",
      "step 35 : loss 35.9223518371582\n",
      "step 36 : loss 33.848628997802734\n",
      "step 37 : loss 32.259456634521484\n",
      "step 38 : loss 31.245986938476562\n",
      "step 39 : loss 30.654659271240234\n",
      "step 40 : loss 30.204715728759766\n",
      "step 41 : loss 29.670207977294922\n",
      "step 42 : loss 28.97331428527832\n",
      "step 43 : loss 28.16121482849121\n",
      "step 44 : loss 27.338613510131836\n",
      "step 45 : loss 26.597902297973633\n",
      "step 46 : loss 25.96268653869629\n",
      "step 47 : loss 25.365034103393555\n",
      "step 48 : loss 24.683927536010742\n",
      "step 49 : loss 23.841079711914062\n",
      "step 50 : loss 22.903499603271484\n",
      "step 51 : loss 22.107999801635742\n",
      "step 52 : loss 21.70086669921875\n",
      "step 53 : loss 21.622575759887695\n",
      "step 54 : loss 21.456523895263672\n",
      "step 55 : loss 20.893638610839844\n",
      "step 56 : loss 20.098848342895508\n",
      "step 57 : loss 19.51214599609375\n",
      "step 58 : loss 19.317075729370117\n",
      "step 59 : loss 19.25018882751465\n",
      "step 60 : loss 19.029600143432617\n",
      "step 61 : loss 18.698564529418945\n",
      "step 62 : loss 18.44247817993164\n",
      "step 63 : loss 18.221601486206055\n",
      "step 64 : loss 17.84676742553711\n",
      "step 65 : loss 17.40755271911621\n",
      "step 66 : loss 17.19893455505371\n",
      "step 67 : loss 17.169626235961914\n",
      "step 68 : loss 16.993757247924805\n",
      "step 69 : loss 16.662811279296875\n",
      "step 70 : loss 16.424320220947266\n",
      "step 71 : loss 16.2482852935791\n",
      "step 72 : loss 15.98613452911377\n",
      "step 73 : loss 15.791471481323242\n",
      "step 74 : loss 15.712916374206543\n",
      "step 75 : loss 15.533860206604004\n",
      "step 76 : loss 15.281218528747559\n",
      "step 77 : loss 15.109647750854492\n",
      "step 78 : loss 14.919280052185059\n",
      "step 79 : loss 14.738593101501465\n",
      "step 80 : loss 14.651686668395996\n",
      "step 81 : loss 14.473400115966797\n",
      "step 82 : loss 14.253459930419922\n",
      "step 83 : loss 14.112881660461426\n",
      "step 84 : loss 13.942805290222168\n",
      "step 85 : loss 13.817217826843262\n",
      "step 86 : loss 13.67116928100586\n",
      "step 87 : loss 13.47248649597168\n",
      "step 88 : loss 13.334447860717773\n",
      "step 89 : loss 13.16818618774414\n",
      "step 90 : loss 13.047107696533203\n",
      "step 91 : loss 12.8897066116333\n",
      "step 92 : loss 12.726194381713867\n",
      "step 93 : loss 12.581896781921387\n",
      "step 94 : loss 12.445520401000977\n",
      "step 95 : loss 12.313885688781738\n",
      "step 96 : loss 12.153215408325195\n",
      "step 97 : loss 12.017114639282227\n",
      "step 98 : loss 11.883301734924316\n",
      "step 99 : loss 11.748028755187988\n",
      "step 100 : loss 11.6072359085083\n",
      "step 101 : loss 11.461069107055664\n",
      "step 102 : loss 11.341139793395996\n",
      "step 103 : loss 11.196154594421387\n",
      "step 104 : loss 11.057106971740723\n",
      "step 105 : loss 10.924127578735352\n",
      "step 106 : loss 10.784053802490234\n",
      "step 107 : loss 10.64711856842041\n",
      "step 108 : loss 10.508902549743652\n",
      "step 109 : loss 10.367535591125488\n",
      "step 110 : loss 10.226313591003418\n",
      "step 111 : loss 10.087369918823242\n",
      "step 112 : loss 9.950740814208984\n",
      "step 113 : loss 9.80257511138916\n",
      "step 114 : loss 9.653470993041992\n",
      "step 115 : loss 9.510760307312012\n",
      "step 116 : loss 9.364799499511719\n",
      "step 117 : loss 9.221324920654297\n",
      "step 118 : loss 9.087165832519531\n",
      "step 119 : loss 8.975975036621094\n",
      "step 120 : loss 8.975478172302246\n",
      "step 121 : loss 9.246865272521973\n",
      "step 122 : loss 9.523904800415039\n",
      "step 123 : loss 8.588170051574707\n",
      "step 124 : loss 8.3895263671875\n",
      "step 125 : loss 8.858855247497559\n",
      "step 126 : loss 8.296492576599121\n",
      "step 127 : loss 7.974809169769287\n",
      "step 128 : loss 8.281533241271973\n",
      "step 129 : loss 7.954352378845215\n",
      "step 130 : loss 7.619749546051025\n",
      "step 131 : loss 7.771584987640381\n",
      "step 132 : loss 7.661807537078857\n",
      "step 133 : loss 7.326755523681641\n",
      "step 134 : loss 7.281106472015381\n",
      "step 135 : loss 7.348385810852051\n",
      "step 136 : loss 7.17981481552124\n",
      "step 137 : loss 6.921656608581543\n",
      "step 138 : loss 6.883900165557861\n",
      "step 139 : loss 6.943098068237305\n",
      "step 140 : loss 6.815556526184082\n",
      "step 141 : loss 6.5969414710998535\n",
      "step 142 : loss 6.451995849609375\n",
      "step 143 : loss 6.4270734786987305\n",
      "step 144 : loss 6.461520671844482\n",
      "step 145 : loss 6.434161186218262\n",
      "step 146 : loss 6.338428497314453\n",
      "step 147 : loss 6.15686559677124\n",
      "step 148 : loss 6.001313209533691\n",
      "step 149 : loss 5.883336544036865\n",
      "step 150 : loss 5.795266628265381\n",
      "step 151 : loss 5.724637985229492\n",
      "step 152 : loss 5.675300598144531\n",
      "step 153 : loss 5.686614036560059\n",
      "step 154 : loss 5.881251811981201\n",
      "step 155 : loss 6.4706711769104\n",
      "step 156 : loss 6.354618072509766\n",
      "step 157 : loss 5.760404586791992\n",
      "step 158 : loss 5.295521259307861\n",
      "step 159 : loss 5.303652763366699\n",
      "step 160 : loss 5.667380332946777\n",
      "step 161 : loss 5.811839580535889\n",
      "step 162 : loss 5.496227741241455\n",
      "step 163 : loss 5.065197467803955\n",
      "step 164 : loss 5.016328811645508\n",
      "step 165 : loss 5.270023822784424\n",
      "step 166 : loss 5.430969715118408\n",
      "step 167 : loss 5.253177642822266\n",
      "step 168 : loss 4.877844333648682\n",
      "step 169 : loss 4.765941619873047\n",
      "step 170 : loss 4.890799045562744\n",
      "step 171 : loss 5.0792083740234375\n",
      "step 172 : loss 5.097771644592285\n",
      "step 173 : loss 4.78281307220459\n",
      "step 174 : loss 4.586267948150635\n",
      "step 175 : loss 4.567681789398193\n",
      "step 176 : loss 4.679400444030762\n",
      "step 177 : loss 4.8354058265686035\n",
      "step 178 : loss 4.769708156585693\n",
      "step 179 : loss 4.598626613616943\n",
      "step 180 : loss 4.425963401794434\n",
      "step 181 : loss 4.344688892364502\n",
      "step 182 : loss 4.334683418273926\n",
      "step 183 : loss 4.384602069854736\n",
      "step 184 : loss 4.502119064331055\n",
      "step 185 : loss 4.592402458190918\n",
      "step 186 : loss 4.610391139984131\n",
      "step 187 : loss 4.417012691497803\n",
      "step 188 : loss 4.2560014724731445\n",
      "step 189 : loss 4.150901794433594\n",
      "step 190 : loss 4.097684860229492\n",
      "step 191 : loss 4.072123050689697\n",
      "step 192 : loss 4.067496299743652\n",
      "step 193 : loss 4.096720218658447\n",
      "step 194 : loss 4.187450408935547\n",
      "step 195 : loss 4.38397216796875\n",
      "step 196 : loss 4.476047039031982\n",
      "step 197 : loss 4.419527053833008\n",
      "step 198 : loss 4.136178016662598\n",
      "step 199 : loss 3.973569393157959\n",
      "step 200 : loss 3.9012744426727295\n",
      "step 201 : loss 3.876513719558716\n",
      "step 202 : loss 3.8751847743988037\n",
      "step 203 : loss 3.9172909259796143\n",
      "step 204 : loss 4.058261394500732\n",
      "step 205 : loss 4.226102352142334\n",
      "step 206 : loss 4.3076934814453125\n",
      "step 207 : loss 4.033954620361328\n",
      "step 208 : loss 3.8438286781311035\n",
      "step 209 : loss 3.747560739517212\n",
      "step 210 : loss 3.7030584812164307\n",
      "step 211 : loss 3.6840555667877197\n",
      "step 212 : loss 3.7007298469543457\n",
      "step 213 : loss 3.781111717224121\n",
      "step 214 : loss 3.9285242557525635\n",
      "step 215 : loss 4.113283157348633\n",
      "step 216 : loss 4.017847537994385\n",
      "step 217 : loss 3.8553056716918945\n",
      "step 218 : loss 3.6785647869110107\n",
      "step 219 : loss 3.587533712387085\n",
      "step 220 : loss 3.546645164489746\n",
      "step 221 : loss 3.529813528060913\n",
      "step 222 : loss 3.5194554328918457\n",
      "step 223 : loss 3.5144107341766357\n",
      "step 224 : loss 3.5328643321990967\n",
      "step 225 : loss 3.6087522506713867\n",
      "step 226 : loss 3.8008041381835938\n",
      "step 227 : loss 3.968757152557373\n",
      "step 228 : loss 3.985409736633301\n",
      "step 229 : loss 3.6737852096557617\n",
      "step 230 : loss 3.4899470806121826\n",
      "step 231 : loss 3.408414840698242\n",
      "step 232 : loss 3.382587194442749\n",
      "step 233 : loss 3.389578342437744\n",
      "step 234 : loss 3.4376723766326904\n",
      "step 235 : loss 3.5676839351654053\n",
      "step 236 : loss 3.7433624267578125\n",
      "step 237 : loss 3.869643449783325\n",
      "step 238 : loss 3.631263256072998\n",
      "step 239 : loss 3.4380440711975098\n",
      "step 240 : loss 3.330758810043335\n",
      "step 241 : loss 3.2872555255889893\n",
      "step 242 : loss 3.2686753273010254\n",
      "step 243 : loss 3.260451078414917\n",
      "step 244 : loss 3.262279987335205\n",
      "step 245 : loss 3.2873294353485107\n",
      "step 246 : loss 3.3726580142974854\n",
      "step 247 : loss 3.537451982498169\n",
      "step 248 : loss 3.746018171310425\n",
      "step 249 : loss 3.599097728729248\n",
      "step 250 : loss 3.4105470180511475\n",
      "step 251 : loss 3.2648088932037354\n",
      "step 252 : loss 3.20056414604187\n",
      "step 253 : loss 3.1700260639190674\n",
      "step 254 : loss 3.1540446281433105\n",
      "step 255 : loss 3.1454460620880127\n",
      "step 256 : loss 3.1468729972839355\n",
      "step 257 : loss 3.1701059341430664\n",
      "step 258 : loss 3.252647876739502\n",
      "step 259 : loss 3.41860294342041\n",
      "step 260 : loss 3.6399929523468018\n",
      "step 261 : loss 3.4944896697998047\n",
      "step 262 : loss 3.30188250541687\n",
      "step 263 : loss 3.153557777404785\n",
      "step 264 : loss 3.0904457569122314\n",
      "step 265 : loss 3.062199354171753\n",
      "step 266 : loss 3.050706624984741\n",
      "step 267 : loss 3.0511045455932617\n",
      "step 268 : loss 3.0762009620666504\n",
      "step 269 : loss 3.1503405570983887\n",
      "step 270 : loss 3.3221652507781982\n",
      "step 271 : loss 3.443882703781128\n",
      "step 272 : loss 3.438763380050659\n",
      "step 273 : loss 3.198660135269165\n",
      "step 274 : loss 3.05743670463562\n",
      "step 275 : loss 2.9896581172943115\n",
      "step 276 : loss 2.9620282649993896\n",
      "step 277 : loss 2.9490814208984375\n",
      "step 278 : loss 2.946082353591919\n",
      "step 279 : loss 2.9581680297851562\n",
      "step 280 : loss 3.009749412536621\n",
      "step 281 : loss 3.129107713699341\n",
      "step 282 : loss 3.3351824283599854\n",
      "step 283 : loss 3.3249876499176025\n",
      "step 284 : loss 3.2005059719085693\n",
      "step 285 : loss 3.0207455158233643\n",
      "step 286 : loss 2.9349613189697266\n",
      "step 287 : loss 2.896555185317993\n",
      "step 288 : loss 2.8868825435638428\n",
      "step 289 : loss 2.8980979919433594\n",
      "step 290 : loss 2.950035572052002\n",
      "step 291 : loss 3.0509748458862305\n",
      "step 292 : loss 3.2040178775787354\n",
      "step 293 : loss 3.1780643463134766\n",
      "step 294 : loss 3.0813040733337402\n",
      "step 295 : loss 2.941433906555176\n",
      "step 296 : loss 2.8724801540374756\n",
      "step 297 : loss 2.8405277729034424\n",
      "step 298 : loss 2.8413872718811035\n",
      "step 299 : loss 2.8682689666748047\n",
      "step 300 : loss 2.943481683731079\n",
      "step 301 : loss 3.025546073913574\n",
      "step 302 : loss 3.094672441482544\n",
      "step 303 : loss 3.000558853149414\n",
      "step 304 : loss 2.9074885845184326\n",
      "step 305 : loss 2.8268861770629883\n",
      "step 306 : loss 2.7938265800476074\n",
      "step 307 : loss 2.784769296646118\n",
      "step 308 : loss 2.808828592300415\n",
      "step 309 : loss 2.8562114238739014\n",
      "step 310 : loss 2.9408435821533203\n",
      "step 311 : loss 2.96212100982666\n",
      "step 312 : loss 2.9469170570373535\n",
      "step 313 : loss 2.8494856357574463\n",
      "step 314 : loss 2.786184072494507\n",
      "step 315 : loss 2.743424415588379\n",
      "step 316 : loss 2.7355172634124756\n",
      "step 317 : loss 2.74652099609375\n",
      "step 318 : loss 2.7919328212738037\n",
      "step 319 : loss 2.838118076324463\n",
      "step 320 : loss 2.8886661529541016\n",
      "step 321 : loss 2.848271369934082\n",
      "step 322 : loss 2.8001444339752197\n",
      "step 323 : loss 2.7339863777160645\n",
      "step 324 : loss 2.704336404800415\n",
      "step 325 : loss 2.690192461013794\n",
      "step 326 : loss 2.7077488899230957\n",
      "step 327 : loss 2.7332751750946045\n",
      "step 328 : loss 2.7816452980041504\n",
      "step 329 : loss 2.782656192779541\n",
      "step 330 : loss 2.774550437927246\n",
      "step 331 : loss 2.7170724868774414\n",
      "step 332 : loss 2.683932065963745\n",
      "step 333 : loss 2.657072067260742\n",
      "step 334 : loss 2.6622397899627686\n",
      "step 335 : loss 2.674696922302246\n",
      "step 336 : loss 2.7067759037017822\n",
      "step 337 : loss 2.709174394607544\n",
      "step 338 : loss 2.7042460441589355\n",
      "step 339 : loss 2.6639952659606934\n",
      "step 340 : loss 2.645746946334839\n",
      "step 341 : loss 2.6299760341644287\n",
      "step 342 : loss 2.6441824436187744\n",
      "step 343 : loss 2.6439247131347656\n",
      "step 344 : loss 2.652703285217285\n",
      "step 345 : loss 2.627426862716675\n",
      "step 346 : loss 2.6203060150146484\n",
      "step 347 : loss 2.6065361499786377\n",
      "step 348 : loss 2.618410587310791\n",
      "step 349 : loss 2.612309455871582\n",
      "step 350 : loss 2.6111741065979004\n",
      "step 351 : loss 2.5849082469940186\n",
      "step 352 : loss 2.577726125717163\n",
      "step 353 : loss 2.5675652027130127\n",
      "step 354 : loss 2.5829944610595703\n",
      "step 355 : loss 2.5770957469940186\n",
      "step 356 : loss 2.5804624557495117\n",
      "step 357 : loss 2.5544016361236572\n",
      "step 358 : loss 2.548737049102783\n",
      "step 359 : loss 2.5348544120788574\n",
      "step 360 : loss 2.542600631713867\n",
      "step 361 : loss 2.533604145050049\n",
      "step 362 : loss 2.5357489585876465\n",
      "step 363 : loss 2.5185863971710205\n",
      "step 364 : loss 2.5206117630004883\n",
      "step 365 : loss 2.5091793537139893\n",
      "step 366 : loss 2.516514539718628\n",
      "step 367 : loss 2.5004892349243164\n",
      "step 368 : loss 2.499434232711792\n",
      "step 369 : loss 2.480264186859131\n",
      "step 370 : loss 2.482980251312256\n",
      "step 371 : loss 2.474043846130371\n",
      "step 372 : loss 2.4828970432281494\n",
      "step 373 : loss 2.4704058170318604\n",
      "step 374 : loss 2.470144033432007\n",
      "step 375 : loss 2.4506895542144775\n",
      "step 376 : loss 2.4507100582122803\n",
      "step 377 : loss 2.4384377002716064\n",
      "step 378 : loss 2.4464664459228516\n",
      "step 379 : loss 2.435242176055908\n",
      "step 380 : loss 2.4397900104522705\n",
      "step 381 : loss 2.4222476482391357\n",
      "step 382 : loss 2.4229724407196045\n",
      "step 383 : loss 2.4081249237060547\n",
      "step 384 : loss 2.412832021713257\n",
      "step 385 : loss 2.4013054370880127\n",
      "step 386 : loss 2.4057424068450928\n",
      "step 387 : loss 2.391042709350586\n",
      "step 388 : loss 2.3928136825561523\n",
      "step 389 : loss 2.3781282901763916\n",
      "step 390 : loss 2.382721424102783\n",
      "step 391 : loss 2.370523452758789\n",
      "step 392 : loss 2.3764262199401855\n",
      "step 393 : loss 2.361556053161621\n",
      "step 394 : loss 2.3639276027679443\n",
      "step 395 : loss 2.3472700119018555\n",
      "step 396 : loss 2.3501477241516113\n",
      "step 397 : loss 2.337460994720459\n",
      "step 398 : loss 2.3441262245178223\n",
      "step 399 : loss 2.3327794075012207\n",
      "step 400 : loss 2.3376474380493164\n",
      "step 401 : loss 2.3219640254974365\n",
      "step 402 : loss 2.3226659297943115\n",
      "step 403 : loss 2.3067753314971924\n",
      "step 404 : loss 2.3101251125335693\n",
      "step 405 : loss 2.2988648414611816\n",
      "step 406 : loss 2.3067331314086914\n",
      "step 407 : loss 2.295168399810791\n",
      "step 408 : loss 2.3004860877990723\n",
      "step 409 : loss 2.28342604637146\n",
      "step 410 : loss 2.28448748588562\n",
      "step 411 : loss 2.267585515975952\n",
      "step 412 : loss 2.2713711261749268\n",
      "step 413 : loss 2.2594916820526123\n",
      "step 414 : loss 2.2675065994262695\n",
      "step 415 : loss 2.2561113834381104\n",
      "step 416 : loss 2.2621073722839355\n",
      "step 417 : loss 2.2466835975646973\n",
      "step 418 : loss 2.249021530151367\n",
      "step 419 : loss 2.233727216720581\n",
      "step 420 : loss 2.2374448776245117\n",
      "step 421 : loss 2.2253026962280273\n",
      "step 422 : loss 2.230477809906006\n",
      "step 423 : loss 2.21763277053833\n",
      "step 424 : loss 2.2204275131225586\n",
      "step 425 : loss 2.2055890560150146\n",
      "step 426 : loss 2.2083990573883057\n",
      "step 427 : loss 2.196131706237793\n",
      "step 428 : loss 2.2038049697875977\n",
      "step 429 : loss 2.1938140392303467\n",
      "step 430 : loss 2.2028250694274902\n",
      "step 431 : loss 2.18822979927063\n",
      "step 432 : loss 2.1921164989471436\n",
      "step 433 : loss 2.172950029373169\n",
      "step 434 : loss 2.174078941345215\n",
      "step 435 : loss 2.156123161315918\n",
      "step 436 : loss 2.158803701400757\n",
      "step 437 : loss 2.1450116634368896\n",
      "step 438 : loss 2.153609037399292\n",
      "step 439 : loss 2.1472549438476562\n",
      "step 440 : loss 2.1633381843566895\n",
      "step 441 : loss 2.1555368900299072\n",
      "step 442 : loss 2.1615848541259766\n",
      "step 443 : loss 2.1389808654785156\n",
      "step 444 : loss 2.1293294429779053\n",
      "step 445 : loss 2.106426239013672\n",
      "step 446 : loss 2.1026432514190674\n",
      "step 447 : loss 2.096529960632324\n",
      "step 448 : loss 2.1159322261810303\n",
      "step 449 : loss 2.12300968170166\n",
      "step 450 : loss 2.144310474395752\n",
      "step 451 : loss 2.11871337890625\n",
      "step 452 : loss 2.1035730838775635\n",
      "step 453 : loss 2.0677502155303955\n",
      "step 454 : loss 2.0619986057281494\n",
      "step 455 : loss 2.058077096939087\n",
      "step 456 : loss 2.085728406906128\n",
      "step 457 : loss 2.0956673622131348\n",
      "step 458 : loss 2.1131415367126465\n",
      "step 459 : loss 2.0813260078430176\n",
      "step 460 : loss 2.061293601989746\n",
      "step 461 : loss 2.0322554111480713\n",
      "step 462 : loss 2.0335988998413086\n",
      "step 463 : loss 2.037090539932251\n",
      "step 464 : loss 2.0652854442596436\n",
      "step 465 : loss 2.0651447772979736\n",
      "step 466 : loss 2.0703353881835938\n",
      "step 467 : loss 2.035709857940674\n",
      "step 468 : loss 2.022894859313965\n",
      "step 469 : loss 2.0030341148376465\n",
      "step 470 : loss 2.0139219760894775\n",
      "step 471 : loss 2.015716314315796\n",
      "step 472 : loss 2.0371439456939697\n",
      "step 473 : loss 2.024332046508789\n",
      "step 474 : loss 2.0231237411499023\n",
      "step 475 : loss 1.9970532655715942\n",
      "step 476 : loss 1.9950191974639893\n",
      "step 477 : loss 1.9847545623779297\n",
      "step 478 : loss 1.9971197843551636\n",
      "step 479 : loss 1.9912185668945312\n",
      "step 480 : loss 1.9982906579971313\n",
      "step 481 : loss 1.9799453020095825\n",
      "step 482 : loss 1.9799153804779053\n",
      "step 483 : loss 1.9652186632156372\n",
      "step 484 : loss 1.9748854637145996\n",
      "step 485 : loss 1.9663517475128174\n",
      "step 486 : loss 1.976314902305603\n",
      "step 487 : loss 1.9581267833709717\n",
      "step 488 : loss 1.9582805633544922\n",
      "step 489 : loss 1.9392348527908325\n",
      "step 490 : loss 1.944948673248291\n",
      "step 491 : loss 1.9367619752883911\n",
      "step 492 : loss 1.9508007764816284\n",
      "step 493 : loss 1.9409146308898926\n",
      "step 494 : loss 1.9468786716461182\n",
      "step 495 : loss 1.9278734922409058\n",
      "step 496 : loss 1.9282145500183105\n",
      "step 497 : loss 1.9141747951507568\n",
      "step 498 : loss 1.920477032661438\n",
      "step 499 : loss 1.9111438989639282\n",
      "step 500 : loss 1.9170997142791748\n",
      "step 501 : loss 1.90337336063385\n",
      "step 502 : loss 1.9069656133651733\n",
      "step 503 : loss 1.8949452638626099\n",
      "step 504 : loss 1.9050575494766235\n",
      "step 505 : loss 1.8959264755249023\n",
      "step 506 : loss 1.905963659286499\n",
      "step 507 : loss 1.8883315324783325\n",
      "step 508 : loss 1.8898086547851562\n",
      "step 509 : loss 1.8697293996810913\n",
      "step 510 : loss 1.8733354806900024\n",
      "step 511 : loss 1.8611173629760742\n",
      "step 512 : loss 1.8722115755081177\n",
      "step 513 : loss 1.8634663820266724\n",
      "step 514 : loss 1.8751249313354492\n",
      "step 515 : loss 1.8623768091201782\n",
      "step 516 : loss 1.8689287900924683\n",
      "step 517 : loss 1.8537275791168213\n",
      "step 518 : loss 1.8570696115493774\n",
      "step 519 : loss 1.8424581289291382\n",
      "step 520 : loss 1.843493938446045\n",
      "step 521 : loss 1.8294461965560913\n",
      "step 522 : loss 1.832167148590088\n",
      "step 523 : loss 1.823895812034607\n",
      "step 524 : loss 1.8372262716293335\n",
      "step 525 : loss 1.832914113998413\n",
      "step 526 : loss 1.84599769115448\n",
      "step 527 : loss 1.8261778354644775\n",
      "step 528 : loss 1.8237801790237427\n",
      "step 529 : loss 1.7998512983322144\n",
      "step 530 : loss 1.801853895187378\n",
      "step 531 : loss 1.79230535030365\n",
      "step 532 : loss 1.8081592321395874\n",
      "step 533 : loss 1.8035812377929688\n",
      "step 534 : loss 1.816872239112854\n",
      "step 535 : loss 1.8001021146774292\n",
      "step 536 : loss 1.8005865812301636\n",
      "step 537 : loss 1.78207528591156\n",
      "step 538 : loss 1.7840237617492676\n",
      "step 539 : loss 1.7730509042739868\n",
      "step 540 : loss 1.7797939777374268\n",
      "step 541 : loss 1.7707101106643677\n",
      "step 542 : loss 1.7797176837921143\n",
      "step 543 : loss 1.7698845863342285\n",
      "step 544 : loss 1.7797036170959473\n",
      "step 545 : loss 1.7647050619125366\n",
      "step 546 : loss 1.7687036991119385\n",
      "step 547 : loss 1.7491966485977173\n",
      "step 548 : loss 1.7522408962249756\n",
      "step 549 : loss 1.738972783088684\n",
      "step 550 : loss 1.7499721050262451\n",
      "step 551 : loss 1.7424392700195312\n",
      "step 552 : loss 1.7549185752868652\n",
      "step 553 : loss 1.7415189743041992\n",
      "step 554 : loss 1.7455118894577026\n",
      "step 555 : loss 1.7286558151245117\n",
      "step 556 : loss 1.731445550918579\n",
      "step 557 : loss 1.7195625305175781\n",
      "step 558 : loss 1.7255727052688599\n",
      "step 559 : loss 1.715259075164795\n",
      "step 560 : loss 1.7219165563583374\n",
      "step 561 : loss 1.7111473083496094\n",
      "step 562 : loss 1.720017671585083\n",
      "step 563 : loss 1.7087494134902954\n",
      "step 564 : loss 1.716918706893921\n",
      "step 565 : loss 1.7008391618728638\n",
      "step 566 : loss 1.704823613166809\n",
      "step 567 : loss 1.6882683038711548\n",
      "step 568 : loss 1.694456696510315\n",
      "step 569 : loss 1.6829934120178223\n",
      "step 570 : loss 1.693538784980774\n",
      "step 571 : loss 1.6830127239227295\n",
      "step 572 : loss 1.692109227180481\n",
      "step 573 : loss 1.678775429725647\n",
      "step 574 : loss 1.685013771057129\n",
      "step 575 : loss 1.6720800399780273\n",
      "step 576 : loss 1.6776247024536133\n",
      "step 577 : loss 1.665360927581787\n",
      "step 578 : loss 1.6688563823699951\n",
      "step 579 : loss 1.6560710668563843\n",
      "step 580 : loss 1.6596169471740723\n",
      "step 581 : loss 1.6497557163238525\n",
      "step 582 : loss 1.658610463142395\n",
      "step 583 : loss 1.6510833501815796\n",
      "step 584 : loss 1.6617872714996338\n",
      "step 585 : loss 1.6486536264419556\n",
      "step 586 : loss 1.6542335748672485\n",
      "step 587 : loss 1.637046456336975\n",
      "step 588 : loss 1.6418884992599487\n",
      "step 589 : loss 1.627520203590393\n",
      "step 590 : loss 1.6349287033081055\n",
      "step 591 : loss 1.6222126483917236\n",
      "step 592 : loss 1.6305346488952637\n",
      "step 593 : loss 1.619278073310852\n",
      "step 594 : loss 1.6299083232879639\n",
      "step 595 : loss 1.62016761302948\n",
      "step 596 : loss 1.6296322345733643\n",
      "step 597 : loss 1.61642587184906\n",
      "step 598 : loss 1.619831919670105\n",
      "step 599 : loss 1.6054041385650635\n",
      "step 600 : loss 1.6073200702667236\n",
      "step 601 : loss 1.5960012674331665\n",
      "step 602 : loss 1.5998297929763794\n",
      "step 603 : loss 1.5910683870315552\n",
      "step 604 : loss 1.5993887186050415\n",
      "step 605 : loss 1.593073844909668\n",
      "step 606 : loss 1.6053510904312134\n",
      "step 607 : loss 1.5938314199447632\n",
      "step 608 : loss 1.599621057510376\n",
      "step 609 : loss 1.5801764726638794\n",
      "step 610 : loss 1.582261085510254\n",
      "step 611 : loss 1.5670636892318726\n",
      "step 612 : loss 1.5751845836639404\n",
      "step 613 : loss 1.5658851861953735\n",
      "step 614 : loss 1.5777051448822021\n",
      "step 615 : loss 1.5679782629013062\n",
      "step 616 : loss 1.5779274702072144\n",
      "step 617 : loss 1.5655688047409058\n",
      "step 618 : loss 1.5714579820632935\n",
      "step 619 : loss 1.5576343536376953\n",
      "step 620 : loss 1.5600863695144653\n",
      "step 621 : loss 1.5471848249435425\n",
      "step 622 : loss 1.550087332725525\n",
      "step 623 : loss 1.5407840013504028\n",
      "step 624 : loss 1.5487709045410156\n",
      "step 625 : loss 1.5424249172210693\n",
      "step 626 : loss 1.553565263748169\n",
      "step 627 : loss 1.5424128770828247\n",
      "step 628 : loss 1.5485626459121704\n",
      "step 629 : loss 1.531432032585144\n",
      "step 630 : loss 1.5352659225463867\n",
      "step 631 : loss 1.5210126638412476\n",
      "step 632 : loss 1.5287463665008545\n",
      "step 633 : loss 1.5180089473724365\n",
      "step 634 : loss 1.5276652574539185\n",
      "step 635 : loss 1.5170133113861084\n",
      "step 636 : loss 1.5263410806655884\n",
      "step 637 : loss 1.5153231620788574\n",
      "step 638 : loss 1.522818684577942\n",
      "step 639 : loss 1.5104979276657104\n",
      "step 640 : loss 1.514491081237793\n",
      "step 641 : loss 1.5018551349639893\n",
      "step 642 : loss 1.5048677921295166\n",
      "step 643 : loss 1.494560718536377\n",
      "step 644 : loss 1.4999897480010986\n",
      "step 645 : loss 1.491917371749878\n",
      "step 646 : loss 1.500394582748413\n",
      "step 647 : loss 1.4918451309204102\n",
      "step 648 : loss 1.5006301403045654\n",
      "step 649 : loss 1.4881404638290405\n",
      "step 650 : loss 1.4942681789398193\n",
      "step 651 : loss 1.4794379472732544\n",
      "step 652 : loss 1.4850460290908813\n",
      "step 653 : loss 1.4716631174087524\n",
      "step 654 : loss 1.4789246320724487\n",
      "step 655 : loss 1.4673221111297607\n",
      "step 656 : loss 1.4759166240692139\n",
      "step 657 : loss 1.4654171466827393\n",
      "step 658 : loss 1.474879264831543\n",
      "step 659 : loss 1.4646395444869995\n",
      "step 660 : loss 1.4727414846420288\n",
      "step 661 : loss 1.4611537456512451\n",
      "step 662 : loss 1.4661946296691895\n",
      "step 663 : loss 1.454602837562561\n",
      "step 664 : loss 1.4580512046813965\n",
      "step 665 : loss 1.4475141763687134\n",
      "step 666 : loss 1.4503322839736938\n",
      "step 667 : loss 1.44082510471344\n",
      "step 668 : loss 1.4459058046340942\n",
      "step 669 : loss 1.4391542673110962\n",
      "step 670 : loss 1.449148416519165\n",
      "step 671 : loss 1.4417961835861206\n",
      "step 672 : loss 1.4509137868881226\n",
      "step 673 : loss 1.4369642734527588\n",
      "step 674 : loss 1.4416698217391968\n",
      "step 675 : loss 1.4263923168182373\n",
      "step 676 : loss 1.4321473836898804\n",
      "step 677 : loss 1.4194815158843994\n",
      "step 678 : loss 1.4267735481262207\n",
      "step 679 : loss 1.4152549505233765\n",
      "step 680 : loss 1.424127459526062\n",
      "step 681 : loss 1.4152394533157349\n",
      "step 682 : loss 1.4264284372329712\n",
      "step 683 : loss 1.4169615507125854\n",
      "step 684 : loss 1.4241840839385986\n",
      "step 685 : loss 1.4112415313720703\n",
      "step 686 : loss 1.4141632318496704\n",
      "step 687 : loss 1.4028600454330444\n",
      "step 688 : loss 1.405869960784912\n",
      "step 689 : loss 1.3964899778366089\n",
      "step 690 : loss 1.3998874425888062\n",
      "step 691 : loss 1.3920038938522339\n",
      "step 692 : loss 1.3997660875320435\n",
      "step 693 : loss 1.39443838596344\n",
      "step 694 : loss 1.4053876399993896\n",
      "step 695 : loss 1.394460916519165\n",
      "step 696 : loss 1.3996307849884033\n",
      "step 697 : loss 1.3832848072052002\n",
      "step 698 : loss 1.3874577283859253\n",
      "step 699 : loss 1.3749769926071167\n",
      "step 700 : loss 1.3829399347305298\n",
      "step 701 : loss 1.3724491596221924\n",
      "step 702 : loss 1.3809820413589478\n",
      "step 703 : loss 1.3709869384765625\n",
      "step 704 : loss 1.3807379007339478\n",
      "step 705 : loss 1.371708631515503\n",
      "step 706 : loss 1.3798800706863403\n",
      "step 707 : loss 1.3681331872940063\n",
      "step 708 : loss 1.3715226650238037\n",
      "step 709 : loss 1.3598401546478271\n",
      "step 710 : loss 1.3629744052886963\n",
      "step 711 : loss 1.3541208505630493\n",
      "step 712 : loss 1.3584010601043701\n",
      "step 713 : loss 1.350412368774414\n",
      "step 714 : loss 1.3566737174987793\n",
      "step 715 : loss 1.3498483896255493\n",
      "step 716 : loss 1.3591830730438232\n",
      "step 717 : loss 1.3501321077346802\n",
      "step 718 : loss 1.3570977449417114\n",
      "step 719 : loss 1.3430596590042114\n",
      "step 720 : loss 1.3477073907852173\n",
      "step 721 : loss 1.3347135782241821\n",
      "step 722 : loss 1.341652274131775\n",
      "step 723 : loss 1.3308145999908447\n",
      "step 724 : loss 1.3386017084121704\n",
      "step 725 : loss 1.3279430866241455\n",
      "step 726 : loss 1.3363529443740845\n",
      "step 727 : loss 1.327187418937683\n",
      "step 728 : loss 1.336312174797058\n",
      "step 729 : loss 1.3265342712402344\n",
      "step 730 : loss 1.3326492309570312\n",
      "step 731 : loss 1.3216345310211182\n",
      "step 732 : loss 1.325621247291565\n",
      "step 733 : loss 1.3160878419876099\n",
      "step 734 : loss 1.3194279670715332\n",
      "step 735 : loss 1.3104499578475952\n",
      "step 736 : loss 1.313169240951538\n",
      "step 737 : loss 1.3052650690078735\n",
      "step 738 : loss 1.311258316040039\n",
      "step 739 : loss 1.3057299852371216\n",
      "step 740 : loss 1.3150806427001953\n",
      "step 741 : loss 1.3067048788070679\n",
      "step 742 : loss 1.3138110637664795\n",
      "step 743 : loss 1.3009215593338013\n",
      "step 744 : loss 1.3064554929733276\n",
      "step 745 : loss 1.2938045263290405\n",
      "step 746 : loss 1.3000882863998413\n",
      "step 747 : loss 1.287893295288086\n",
      "step 748 : loss 1.294225811958313\n",
      "step 749 : loss 1.283368468284607\n",
      "step 750 : loss 1.2918881177902222\n",
      "step 751 : loss 1.2835859060287476\n",
      "step 752 : loss 1.293555498123169\n",
      "step 753 : loss 1.2843132019042969\n",
      "step 754 : loss 1.2914103269577026\n",
      "step 755 : loss 1.2808421850204468\n",
      "step 756 : loss 1.2857954502105713\n",
      "step 757 : loss 1.2763394117355347\n",
      "step 758 : loss 1.2795066833496094\n",
      "step 759 : loss 1.2700519561767578\n",
      "step 760 : loss 1.27151358127594\n",
      "step 761 : loss 1.2634137868881226\n",
      "step 762 : loss 1.2679181098937988\n",
      "step 763 : loss 1.263084888458252\n",
      "step 764 : loss 1.2719707489013672\n",
      "step 765 : loss 1.265715479850769\n",
      "step 766 : loss 1.2737281322479248\n",
      "step 767 : loss 1.2621641159057617\n",
      "step 768 : loss 1.2675780057907104\n",
      "step 769 : loss 1.2545090913772583\n",
      "step 770 : loss 1.2600520849227905\n",
      "step 771 : loss 1.2479466199874878\n",
      "step 772 : loss 1.254240870475769\n",
      "step 773 : loss 1.2437080144882202\n",
      "step 774 : loss 1.2519617080688477\n",
      "step 775 : loss 1.2436459064483643\n",
      "step 776 : loss 1.2533597946166992\n",
      "step 777 : loss 1.2445647716522217\n",
      "step 778 : loss 1.2518401145935059\n",
      "step 779 : loss 1.2415112257003784\n",
      "step 780 : loss 1.2462835311889648\n",
      "step 781 : loss 1.236769676208496\n",
      "step 782 : loss 1.2400768995285034\n",
      "step 783 : loss 1.2311136722564697\n",
      "step 784 : loss 1.2333813905715942\n",
      "step 785 : loss 1.225692629814148\n",
      "step 786 : loss 1.2303441762924194\n",
      "step 787 : loss 1.2249021530151367\n",
      "step 788 : loss 1.2328484058380127\n",
      "step 789 : loss 1.2261483669281006\n",
      "step 790 : loss 1.2336057424545288\n",
      "step 791 : loss 1.222848653793335\n",
      "step 792 : loss 1.228592872619629\n",
      "step 793 : loss 1.2166094779968262\n",
      "step 794 : loss 1.222449779510498\n",
      "step 795 : loss 1.2108899354934692\n",
      "step 796 : loss 1.2170947790145874\n",
      "step 797 : loss 1.206552505493164\n",
      "step 798 : loss 1.2140662670135498\n",
      "step 799 : loss 1.2052404880523682\n",
      "step 800 : loss 1.2139198780059814\n",
      "step 801 : loss 1.20527184009552\n",
      "step 802 : loss 1.2128764390945435\n",
      "step 803 : loss 1.2035590410232544\n",
      "step 804 : loss 1.2094268798828125\n",
      "step 805 : loss 1.2005172967910767\n",
      "step 806 : loss 1.2047345638275146\n",
      "step 807 : loss 1.1960692405700684\n",
      "step 808 : loss 1.1983407735824585\n",
      "step 809 : loss 1.1901576519012451\n",
      "step 810 : loss 1.1926218271255493\n",
      "step 811 : loss 1.18621027469635\n",
      "step 812 : loss 1.1913074254989624\n",
      "step 813 : loss 1.1860545873641968\n",
      "step 814 : loss 1.1935981512069702\n",
      "step 815 : loss 1.1867910623550415\n",
      "step 816 : loss 1.1943402290344238\n",
      "step 817 : loss 1.1841838359832764\n",
      "step 818 : loss 1.1901845932006836\n",
      "step 819 : loss 1.1782350540161133\n",
      "step 820 : loss 1.1836903095245361\n",
      "step 821 : loss 1.1720995903015137\n",
      "step 822 : loss 1.1780803203582764\n",
      "step 823 : loss 1.1676726341247559\n",
      "step 824 : loss 1.174812912940979\n",
      "step 825 : loss 1.1660337448120117\n",
      "step 826 : loss 1.1746816635131836\n",
      "step 827 : loss 1.1667345762252808\n",
      "step 828 : loss 1.1750370264053345\n",
      "step 829 : loss 1.1662909984588623\n",
      "step 830 : loss 1.172428846359253\n",
      "step 831 : loss 1.1635240316390991\n",
      "step 832 : loss 1.1676639318466187\n",
      "step 833 : loss 1.1592477560043335\n",
      "step 834 : loss 1.1612745523452759\n",
      "step 835 : loss 1.1532257795333862\n",
      "step 836 : loss 1.1548466682434082\n",
      "step 837 : loss 1.1486241817474365\n",
      "step 838 : loss 1.153057336807251\n",
      "step 839 : loss 1.1486735343933105\n",
      "step 840 : loss 1.156215786933899\n",
      "step 841 : loss 1.1503924131393433\n",
      "step 842 : loss 1.1579463481903076\n",
      "step 843 : loss 1.1481924057006836\n",
      "step 844 : loss 1.1538630723953247\n",
      "step 845 : loss 1.1419743299484253\n",
      "step 846 : loss 1.147086262702942\n",
      "step 847 : loss 1.1357471942901611\n",
      "step 848 : loss 1.1416115760803223\n",
      "step 849 : loss 1.1316840648651123\n",
      "step 850 : loss 1.1389667987823486\n",
      "step 851 : loss 1.1307231187820435\n",
      "step 852 : loss 1.1393728256225586\n",
      "step 853 : loss 1.1316183805465698\n",
      "step 854 : loss 1.1394579410552979\n",
      "step 855 : loss 1.1307687759399414\n",
      "step 856 : loss 1.1363400220870972\n",
      "step 857 : loss 1.1276185512542725\n",
      "step 858 : loss 1.131354808807373\n",
      "step 859 : loss 1.1232281923294067\n",
      "step 860 : loss 1.1253787279129028\n",
      "step 861 : loss 1.1179338693618774\n",
      "step 862 : loss 1.1203645467758179\n",
      "step 863 : loss 1.1146284341812134\n",
      "step 864 : loss 1.1196767091751099\n",
      "step 865 : loss 1.1148879528045654\n",
      "step 866 : loss 1.1219311952590942\n",
      "step 867 : loss 1.1152032613754272\n",
      "step 868 : loss 1.121943473815918\n",
      "step 869 : loss 1.112351894378662\n",
      "step 870 : loss 1.118072509765625\n",
      "step 871 : loss 1.1071133613586426\n",
      "step 872 : loss 1.1124815940856934\n",
      "step 873 : loss 1.1017909049987793\n",
      "step 874 : loss 1.1076867580413818\n",
      "step 875 : loss 1.0981519222259521\n",
      "step 876 : loss 1.1051273345947266\n",
      "step 877 : loss 1.0967636108398438\n",
      "step 878 : loss 1.1045764684677124\n",
      "step 879 : loss 1.096688985824585\n",
      "step 880 : loss 1.104163408279419\n",
      "step 881 : loss 1.09613037109375\n",
      "step 882 : loss 1.1022299528121948\n",
      "step 883 : loss 1.0942457914352417\n",
      "step 884 : loss 1.0986249446868896\n",
      "step 885 : loss 1.0909593105316162\n",
      "step 886 : loss 1.0933537483215332\n",
      "step 887 : loss 1.0860595703125\n",
      "step 888 : loss 1.0875691175460815\n",
      "step 889 : loss 1.0814259052276611\n",
      "step 890 : loss 1.084242582321167\n",
      "step 891 : loss 1.0794715881347656\n",
      "step 892 : loss 1.0849202871322632\n",
      "step 893 : loss 1.080396056175232\n",
      "step 894 : loss 1.0877870321273804\n",
      "step 895 : loss 1.0809893608093262\n",
      "step 896 : loss 1.087653398513794\n",
      "step 897 : loss 1.0775789022445679\n",
      "step 898 : loss 1.0828561782836914\n",
      "step 899 : loss 1.0718759298324585\n",
      "step 900 : loss 1.0771147012710571\n",
      "step 901 : loss 1.0666519403457642\n",
      "step 902 : loss 1.0723117589950562\n",
      "step 903 : loss 1.0630261898040771\n",
      "step 904 : loss 1.0700938701629639\n",
      "step 905 : loss 1.0625046491622925\n",
      "step 906 : loss 1.070770025253296\n",
      "step 907 : loss 1.0634280443191528\n",
      "step 908 : loss 1.0708739757537842\n",
      "step 909 : loss 1.0629267692565918\n",
      "step 910 : loss 1.0686339139938354\n",
      "step 911 : loss 1.060815691947937\n",
      "step 912 : loss 1.064444899559021\n",
      "step 913 : loss 1.056857943534851\n",
      "step 914 : loss 1.0585120916366577\n",
      "step 915 : loss 1.0516551733016968\n",
      "step 916 : loss 1.0533006191253662\n",
      "step 917 : loss 1.048032283782959\n",
      "step 918 : loss 1.0516974925994873\n",
      "step 919 : loss 1.047577977180481\n",
      "step 920 : loss 1.053817629814148\n",
      "step 921 : loss 1.0489095449447632\n",
      "step 922 : loss 1.0559097528457642\n",
      "step 923 : loss 1.0478726625442505\n",
      "step 924 : loss 1.0534957647323608\n",
      "step 925 : loss 1.0431132316589355\n",
      "step 926 : loss 1.0480573177337646\n",
      "step 927 : loss 1.0377323627471924\n",
      "step 928 : loss 1.0431156158447266\n",
      "step 929 : loss 1.0336902141571045\n",
      "step 930 : loss 1.03993821144104\n",
      "step 931 : loss 1.0318187475204468\n",
      "step 932 : loss 1.039238691329956\n",
      "step 933 : loss 1.0319756269454956\n",
      "step 934 : loss 1.0395097732543945\n",
      "step 935 : loss 1.0320242643356323\n",
      "step 936 : loss 1.0383200645446777\n",
      "step 937 : loss 1.030718207359314\n",
      "step 938 : loss 1.0354052782058716\n",
      "step 939 : loss 1.0281130075454712\n",
      "step 940 : loss 1.0309453010559082\n",
      "step 941 : loss 1.0240089893341064\n",
      "step 942 : loss 1.0256431102752686\n",
      "step 943 : loss 1.0196728706359863\n",
      "step 944 : loss 1.0219666957855225\n",
      "step 945 : loss 1.017207145690918\n",
      "step 946 : loss 1.0214054584503174\n",
      "step 947 : loss 1.017068862915039\n",
      "step 948 : loss 1.023223638534546\n",
      "step 949 : loss 1.017723798751831\n",
      "step 950 : loss 1.0242841243743896\n",
      "step 951 : loss 1.0161259174346924\n",
      "step 952 : loss 1.0216286182403564\n",
      "step 953 : loss 1.0117628574371338\n",
      "step 954 : loss 1.0168601274490356\n",
      "step 955 : loss 1.0070452690124512\n",
      "step 956 : loss 1.0123732089996338\n",
      "step 957 : loss 1.0031527280807495\n",
      "step 958 : loss 1.0090843439102173\n",
      "step 959 : loss 1.000999093055725\n",
      "step 960 : loss 1.007993459701538\n",
      "step 961 : loss 1.0007740259170532\n",
      "step 962 : loss 1.0080946683883667\n",
      "step 963 : loss 1.0009864568710327\n",
      "step 964 : loss 1.0075796842575073\n",
      "step 965 : loss 1.0005131959915161\n",
      "step 966 : loss 1.0057291984558105\n",
      "step 967 : loss 0.9988022446632385\n",
      "step 968 : loss 1.0020259618759155\n",
      "step 969 : loss 0.9954102635383606\n",
      "step 970 : loss 0.9968361854553223\n",
      "step 971 : loss 0.9908514618873596\n",
      "step 972 : loss 0.9918505549430847\n",
      "step 973 : loss 0.9869789481163025\n",
      "step 974 : loss 0.9894514083862305\n",
      "step 975 : loss 0.9858091473579407\n",
      "step 976 : loss 0.9909911751747131\n",
      "step 977 : loss 0.9873677492141724\n",
      "step 978 : loss 0.9941917061805725\n",
      "step 979 : loss 0.9879889488220215\n",
      "step 980 : loss 0.9940697550773621\n",
      "step 981 : loss 0.9848647117614746\n",
      "step 982 : loss 0.9897076487541199\n",
      "step 983 : loss 0.9795545339584351\n",
      "step 984 : loss 0.984283983707428\n",
      "step 985 : loss 0.9747273921966553\n",
      "step 986 : loss 0.9801108241081238\n",
      "step 987 : loss 0.971855640411377\n",
      "step 988 : loss 0.9785557389259338\n",
      "step 989 : loss 0.9716073274612427\n",
      "step 990 : loss 0.9791613817214966\n",
      "step 991 : loss 0.9725063443183899\n",
      "step 992 : loss 0.9794941544532776\n",
      "step 993 : loss 0.9724502563476562\n",
      "step 994 : loss 0.9778104424476624\n",
      "step 995 : loss 0.970658004283905\n",
      "step 996 : loss 0.9740254878997803\n",
      "step 997 : loss 0.9672451615333557\n",
      "step 998 : loss 0.9690316915512085\n",
      "step 999 : loss 0.9630751609802246\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAK/klEQVR4Ae1dUXbjRg4UKXo2k7x85QB7/xvtz+4F8vZ3M2NL5BJVaLNokBp6ZDUlB8oLCaLBbqAK6G7S9qj516E7HA7/PJ7HY3f8Ph5/e/kyHp/b8XA4o7U/n0bZtIfDIEeIfqC+OTQr7Wp7XzI9X/NJ41HLHjewlUcPHfoOpu1wHK/65nk8PjUmn4DqabC7//OXIQ/FeM7PTgg03/9rI//+u/Fz/mJ10JyNn+fGeO3BG/P+2Jh+EKIHUN+AbWaHV4Cqxns+yydWQMlfnIEP4QF4I5JAdZxHxkwHWG1n8tO3f4zHl18Nz9LDKOZnDwS64x82bP/VjkNrc/35aKwMzGLO+UPJb7OaPp7oPgVCT0NNlcn84aWYrSV0C3hwlCzMoQUER6uAxpJ+PJnmeXgZj09QfYUc+zTj/FRDoDmCxBMIGzrj43i2i9OT+QCSRvJMQ67KGoAbMOE1rBJOe7Bkm93/WT66trHubf5+xQQBF0RwboAWTHugdAIyRPvYW2v3ZNVAVK2v/OyCQPeCChiw8zm0xgeZHGw58E8PG5/xvb20TWe7r8yJk/ZzSMQkhu5YSdg+Q7SmoprLQYsK6ADlgB3RdzwlZAXsnCHd0GN37xtXeANaG7DUg3TKPteLw0K8aD+vWOLFmQeWAGTugrhasA5QBgeuAQ2eqPrOTE98YkA1ZAXsnC/NWdjjktxhgSdvhWAzalENXP3pdcO6gZ6WMZo1fbS8Zw1AcgcpF2Qmrz1SbzArzhlUYAnAm7XxqWv8b1xrz5b9WQETgrtI2Pm/7nywbjtjcIdsk0nZ2rqruiqwMjw7PAvMjJq4f/AuHuWEMLgPdJc9VLviOzGNsewY0YobaE6UeuR9a4/JWQFAZ8dD51whZ4eFCcmYG0gu85rO0j6sAbPnZLX3ECVtdgz6J4ZGkhMHxiAwjG+BtEe2v7VSE21bgFw7S/nWCPBHNz6LcS7jPEXGfPYHZaovbk28qr1rSfRkMt40uyidPOR5FiMioIbvzRiSzxwSHxHWFSIrQODZQ8STWclMpmw8Orfwj3VAVzXFKavew9EGVz3iaapd3wtJ8IoP1b4/FBuPGaYOCeSsgJ2zgW8lfG7mDMW3dzMZTpI3VkD57Qd6b1RqFqis8amesrbuK3tWwgn1s3j1NpmJT1zUSj9v7dmP9swtZFZAQXinc+ePqqBGZ7eS45KpkVRdzgv1YyDaj+aImBz8ESImRn0gNC2Jg/qgTkPv0YmNdkA11wDBzq21Mz49ZAUIkHuInWYo39xwJ+tznPhE5ssaAHYDxWR4plbSpbeZuMVmdsOHXsjo7j9OLm8YSqvZOyMEfmFd6GShs05WwAaAb2kyew4gM5ybNIsp8yfD8/cek2vRfpYLk6FLniLb0yz0cI1CvWU/M0fQrDacD9TG/efNYipi2RrCpuitD59joM8KIIS7He0XdMcPueVrPecZqe4yTi7zhi3HQvqiLXubr0CLhjdR+ujb+2Ys775tGoDrBH9urMBkBUwY7SJ5BSyM/e6En/q4IlGmTu5KihFFzQ8c1rQX06wAAWMPcb0CVhjbw8n9x9RdEL3RRUHlma86i6gsRlkBAsYe4joBI2Pvnuf2iOAexrwCq3UC7iGwv4EPC2uATv5r8mVkVufEy7c9euvKLH85rKyAy/jcvHWhAj5szC0ZscXmwxwKHW0ZnTbh1gWFThcLzcuqrIBlXKppFypgS1q4fyum25Nm1k+1oN8/0OWIvFWNNldDVsD72fjQOxYqYIG8tW3Ngql55+YrrTP/t9jMbqh+AQ/jk/CCHz8VS1bAApI1VQsVcP3wOhle39s99DD7PY/o0E/lPrvJCohwVtUkAVXhjoMlARGTqpokoCrccbAkIGJSVZMEVIU7DpYEREyqapKAqnDHwZKAiElVTRJQFe44WBIQMamqSQKqwh0HSwIiJlU1SUBVuONgSUDEpKomCagKdxwsCYiYVNUkAVXhjoMlARGTqpokoCrccbAkIGJSVZMEVIU7DpYEREyqapKAqnDHwZKAiElVTRJQFe44WBIQMamqSQKqwh0HSwIiJlU1SUBVuONgSUDEpKomCagKdxwsCYiYVNUkAVXhjoMlARGTqpoZAeOfOl3x106T3x/Vz9Tj3tLtIpoRsHeYf8fxZ38lyb9u5JGl4PI7/+zRzbWjNWy32Kzde41eI7pc9Wq5NuIVUWQFrIFaST+rgNUxtRxWjULD5cyi+Rab0PEHKLaPuyF2/mvCC6Uio6z9i8NZAR/A5jVdbKuABXKvGfTx7r0MwGorG1AH5V/OfRt7VsBbRCpfb6sA5bCyg3cyXFgJVrNeHZY1YO0JKytAAdtB3lYBcEzp3MHTRx9S1gMNJStA0dhBnlVAzPGo2eIj79o0S27p7g5sYkSqUfm9zmYFvBexD7afVQBzVierNfmyF58p9xlpjEg1Kl9GJrZmBURMqmrK9wn7oOQSc9p08Da+zVid79gA21UbCW2LjZh/sCjOes9rWVws7Tz7Dr3SsNWzFfusgK0A3siufJckuuf3W2kuuIwTZT+ST1z4u0A2eD88XfJZzC+Z3aht++jFkmepA1eUdnNUQHG/Y9qbfYNSIm5ZAQ7VXqfyXZIgMvK15la01DrwTMApWq71eQ96T+voCnKWa4BHND/JHRcjxj/B27M33JMVINDtIfouiNOXzmfujKtwkvTgLEYb/rvKC87LTQutd6zyoGcems6/NfViioebXpeGt3Aw97MCZojVv2j4Hamzn9cIw/xmaP0+JW+UJOHsT9eppo3K9QP7uRHVZ5U1ulnPGiobXPP2bl7z25i1t6yAGZ71L0iMp3gvX/VcdqkTxcqhz4bwN7LqO6L60dxsxAmFHw3xNvNf7dEwCMItOs0KeEVoH6Hj02/fHsfxe6TuwPTG0RnDRodZ4PmuSY6GshcqJWWLP+9gYKuZsU/cs28JVD9X3GH+qqEGNAU9hm0XGrs2srWsrDZWVsAK4rXUHTNXj84P2PZikFxmBegaQLkkRzm/7po9kklPBa81jWqFrONPY87ydFK75N7+wF1rXjIxHXtoBUmKWQEB7LqK7tyCM85ckqYDX3yApoGtNKR/aikez/gXGzFxURtVjpb3oFnw0FU8IcexLnKGKPZ29kctT3XTENthMFVWwM78+rugFuzZTqjMVtzm+JzmSwHYA7nMdD1C7W9LvHjYvBKgNqq8Yr6zehaph0qXrIUraIP5n5YD4PP9JJOcoHC3eUCdQJ8VsDO13fH0PLpwbL+Ox/5wHo/2f1nNGxLENYDLNigu9QFTOcz0yBSmi5jctej5G31EQ68RuSx3QONrAPMdja2jZxfN2WYZTP6HY2NyVkAEu6qm6w/2q0HNYHnfNicMzrXAGGNGk6Uz+BRqF/e86EAOuEmuH0Fc85l6vh2gXJ6H7Iq1zpVgwN6SNi1w4l1tgwrp7dj1hnxWwM4Z0f2vxS/HgYgGnJCVHtN/B4r5ZoM/OXCeQS5lVgnZ3jmaWw/PIBm2PyHZkCV2OztWmEqO2O0MvYHLvf/LYA38VZTT0TrKChhB2PPTdf2Ljd/arPTUPpnIXSpobcEQWeXe1qc6u2f8FO6nGZD6z3b0WkdYzGXPXEfJGvx9AWw4W0AcV1Y7U9NhvmlOX6DJXRAR2vXY/dkZD98s9Q9fsUE9Pls19C2XBeOe3LaYy8q6j9Wc8yDqYKoF6+lRP2tR+JMtwuJ+hjXBn2pxImg4c8DG+wGelH1nia3k6RdD79/9t/GYawAA2+/wf8YU2wuaoQvkAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = AutoEncoder()\n",
    "lr = 1e-4\n",
    "num_steps = 1000\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters() , lr=lr)\n",
    "for step in range(num_steps):\n",
    "    y = autoencoder(init_tensor)\n",
    "    loss = (y-init_tensor).norm()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"step {step} : loss {loss.item()}\")\n",
    "\n",
    "result = autoencoder(init_tensor)\n",
    "tensor_to_image(result.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDi6KKK+ZP3EKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAABrUlEQVR4Ae3TwQ0AMAyDQLf779yOweeyABLE582VBm4Jx94EiL9AAAFiAzHeAgSIDcR4CxAgNhDjLUCA2ECMtwABYgMx3gIEiA3EeAsQIDYQ4y1AgNhAjLcAAWIDMd4CBIgNxHgLECA2EOMtQIDYQIy3AAFiAzHeAgSIDcR4CxAgNhDjLUCA2ECMtwABYgMx3gIEiA3EeAsQIDYQ4y1AgNhAjLcAAWIDMd4CBIgNxHgLECA2EOMtQIDYQIy3AAFiAzHeAgSIDcR4CxAgNhDjLUCA2ECMtwABYgMx3gIEiA3EeAsQIDYQ4y1AgNhAjLcAAWIDMd4CBIgNxHgLECA2EOMtQIDYQIy3AAFiAzHeAgSIDcR4CxAgNhDjLUCA2ECMtwABYgMx3gIEiA3EeAsQIDYQ4y1AgNhAjLcAAWIDMd4CBIgNxHgLECA2EOMtQIDYQIy3AAFiAzHeAgSIDcR4CxAgNhDjLUCA2ECMtwABYgMx3gIEiA3EeAsQIDYQ4y1AgNhAjLcAAWIDMd4CBIgNxHgLECA2EOMtQIDYQIy3AAFiAzHeAgSIDcR4C4gDfM/hAf+qY6fJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_to_image(init_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "\n",
    "def generate_image(size): # , num_images):\n",
    "    # for i in range(num_images):\n",
    "    # Create a new image with a random background color\n",
    "    img = Image.new(\"RGB\", size, color=(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)))\n",
    "\n",
    "    # Get a drawing context\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Choose a random shape (circle, square, or triangle)\n",
    "    # shape = random.choice([\"circle\", \"square\", \"triangle\"])\n",
    "    shape = \"circle\"\n",
    "\n",
    "    # Choose a random position\n",
    "    position = (random.randint(20, size[0]-20), random.randint(20, size[1]-20))\n",
    "\n",
    "    # Choose a random color for the shape\n",
    "    shape_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "    # Draw the shape on the image\n",
    "    if shape == \"circle\":\n",
    "        draw.ellipse([position[0]-20, position[1]-20, position[0]+20, position[1]+20], fill=shape_color)\n",
    "    elif shape == \"square\":\n",
    "        draw.rectangle([position[0]-20, position[1]-20, position[0]+20, position[1]+20], fill=shape_color)\n",
    "    elif shape == \"triangle\":\n",
    "        draw.polygon([(position[0], position[1]-20), (position[0]-20, position[1]+20), (position[0]+20, position[1]+20)], fill=shape_color)\n",
    "\n",
    "    # Show the image\n",
    "    # img.show()\n",
    "    # print(type(img))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDqqKKK+kPiQooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKkiglnbbGhY/yqWztDdSEZwi/eNbqIsaBEACjoBXzuc5/DAP2NJc0/wXr/AJHdhME6y5paL8zHGk3BAJaMexJ4/SoprG4gBLJuUfxLzW/RXzdLivGxneaTXa1v6/E9CWW0WrK6OXorW1CxDBp4gARy49fesmvuMuzGlj6Kq0/muzPHr0JUZ8sgoooruMQooooAKKKKACiiigAooooA37CLyrNOmW+Y49//AK2Ks1DaMHs4SpyNgH5cVNX47j5zniqkp78z/M+popKnFLawUUUVyGoVzt1F5NzJGMYB4x6dq6KsC/YPfSlTkZA/IYr63hCc1iqkVs46+qat+bPMzRL2cX1uVqKKK/QDxAooooAKKKKACiiigAooooA09LuguYHbGTlM/wAq1a5etG31VkASZS4H8Q6//Xr4zPuH6lao8ThVdvdfqv1R62Cx0Yx9nU+TNeiqg1K1IBMhHsVPFRTarEoIiUu3YngV8vSyfH1J8ipSXqrL73oehLFUYq7kizdXK20JYkbj90eprnySxJJJJ5JNPmmeeQySHJP6VHX6FkuUrLqLUnect/8AJHiYvEuvLTZbBRRRXsnIFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAC9ElEQVR4Ae2b0UlDQRBFjdiOrfhnH5ZiLTZhAZZiA24IhIDkQvbNnft4e/yQ4MCe5Zw3IR/x9P79+8RPzsBzDg35bIAA4eeAAAQIGwjj2QAChA2E8WwAAcIGwng2gABhA2E8G0CAsIEwng0gQNhAGM8GECBsIIxnAwgQNhDGswEECBsI49kAAoQNhPFsAAHCBsJ4NoAAYQNhPBtAgLCBMJ4NIEDYQBjPBhAgbCCMZwMIEDYQxrMBBAgbCONfGvgfr2/3KJ8/X/dGi/z95PsvSeH9v9xlS1gCPKT+NsaCGYoDTKtfNkPlp6AS+6NE1Tm3UXf7uixArbXa03Zrf1ysJoDDl+PMHZYoCOAz5Tt5PyW2BnA7cp8fL7EpQI+dHkqqxKYAqUsfiTsfoPPB7GQ1150P0HzRo+ImA/Q/kv3EnuSTAXoutwKFAOHKMwFS7wYprjXRTADrhVY7nADh4gQgQNhAGM8GECBsIIxnAwgQNhDGz2xA6ssjKa410UwA64VWO5wA4eKTAfrfDfqJPWUmA/RcbgXKfIDOR7KT1Vx9PkDzRY+K2xSg58HsoaQCbwowLu224z4/5f3K3RrA2uDw9oe9ggCmBivYLwtQ3mAR+5UBChusY39IK/4XpXHi+Jn++sJS6i+uLAEuRz+UYUH19gAXwPgtSizr/SrHuAFXBi+EgZqPoQLASBsggPZjnxLArlgDCKD92KcEsCvWAAJoP/YpAeyKNYAA2o99SgC7Yg0ggPZjnxLArlgDCKD92KcEsCvWAAJoP/YpAeyKNYAA2o99SgC7Yg0ggPZjnxLArlgDCKD92KcEsCvWAAJoP/YpAeyKNYAA2o99SgC7Yg0ggPZjnxLArlgDCKD92KcEsCvWAAJoP/YpAeyKNYAA2o99SgC7Yg0ggPZjnxLArlgDCKD92KcEsCvWAAJoP/YpAeyKNYAA2o99SgC7Yg0ggPZjnxLArlgDCKD92KcEsCvWAAJoP/YpAeyKNYAA2o99SgC7Yg34Awi0XHO0pIzHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_size = (128, 128)\n",
    "num_images = 5  # Change this to the number of images you want to generate\n",
    "\n",
    "new_image = generate_image(image_size)\n",
    "new_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 : loss 161.52218627929688\n",
      "step 1 : loss 161.2043914794922\n",
      "step 2 : loss 160.88043212890625\n",
      "step 3 : loss 160.5339813232422\n",
      "step 4 : loss 160.14744567871094\n",
      "step 5 : loss 159.70086669921875\n",
      "step 6 : loss 159.16635131835938\n",
      "step 7 : loss 158.51004028320312\n",
      "step 8 : loss 157.68443298339844\n",
      "step 9 : loss 156.62936401367188\n",
      "step 10 : loss 155.26724243164062\n",
      "step 11 : loss 153.50189208984375\n",
      "step 12 : loss 151.2122802734375\n",
      "step 13 : loss 148.25054931640625\n",
      "step 14 : loss 144.4362030029297\n",
      "step 15 : loss 139.55438232421875\n",
      "step 16 : loss 133.35879516601562\n",
      "step 17 : loss 125.58444213867188\n",
      "step 18 : loss 115.98430633544922\n",
      "step 19 : loss 104.42536163330078\n",
      "step 20 : loss 91.14025115966797\n",
      "step 21 : loss 77.4955825805664\n",
      "step 22 : loss 68.03919982910156\n",
      "step 23 : loss 70.60318756103516\n",
      "step 24 : loss 78.18612670898438\n",
      "step 25 : loss 78.10783386230469\n",
      "step 26 : loss 71.59979248046875\n",
      "step 27 : loss 63.5612678527832\n",
      "step 28 : loss 57.93244552612305\n",
      "step 29 : loss 56.01136779785156\n",
      "step 30 : loss 56.536521911621094\n",
      "step 31 : loss 57.7119255065918\n",
      "step 32 : loss 58.491371154785156\n",
      "step 33 : loss 58.521484375\n",
      "step 34 : loss 57.8098258972168\n",
      "step 35 : loss 56.52971649169922\n",
      "step 36 : loss 54.937767028808594\n",
      "step 37 : loss 53.32997131347656\n",
      "step 38 : loss 51.98310089111328\n",
      "step 39 : loss 51.052589416503906\n",
      "step 40 : loss 50.47386932373047\n",
      "step 41 : loss 49.98221206665039\n",
      "step 42 : loss 49.29123306274414\n",
      "step 43 : loss 48.283599853515625\n",
      "step 44 : loss 47.06462478637695\n",
      "step 45 : loss 45.87437057495117\n",
      "step 46 : loss 44.94161605834961\n",
      "step 47 : loss 44.3700065612793\n",
      "step 48 : loss 44.10993576049805\n",
      "step 49 : loss 44.01138687133789\n",
      "step 50 : loss 43.908660888671875\n",
      "step 51 : loss 43.68377685546875\n",
      "step 52 : loss 43.293148040771484\n",
      "step 53 : loss 42.76401901245117\n",
      "step 54 : loss 42.17292022705078\n",
      "step 55 : loss 41.6115608215332\n",
      "step 56 : loss 41.147335052490234\n",
      "step 57 : loss 40.792625427246094\n",
      "step 58 : loss 40.503578186035156\n",
      "step 59 : loss 40.21818161010742\n",
      "step 60 : loss 39.9072265625\n",
      "step 61 : loss 39.59444808959961\n",
      "step 62 : loss 39.32902145385742\n",
      "step 63 : loss 39.13475799560547\n",
      "step 64 : loss 38.98396301269531\n",
      "step 65 : loss 38.81633377075195\n",
      "step 66 : loss 38.585697174072266\n",
      "step 67 : loss 38.29377365112305\n",
      "step 68 : loss 37.987159729003906\n",
      "step 69 : loss 37.722373962402344\n",
      "step 70 : loss 37.524696350097656\n",
      "step 71 : loss 37.37343215942383\n",
      "step 72 : loss 37.22554397583008\n",
      "step 73 : loss 37.05564880371094\n",
      "step 74 : loss 36.87253189086914\n",
      "step 75 : loss 36.70170593261719\n",
      "step 76 : loss 36.55461120605469\n",
      "step 77 : loss 36.41709518432617\n",
      "step 78 : loss 36.266021728515625\n",
      "step 79 : loss 36.0953254699707\n",
      "step 80 : loss 35.92388153076172\n",
      "step 81 : loss 35.776649475097656\n",
      "step 82 : loss 35.65884780883789\n",
      "step 83 : loss 35.55005645751953\n",
      "step 84 : loss 35.42721176147461\n",
      "step 85 : loss 35.28878402709961\n",
      "step 86 : loss 35.1510124206543\n",
      "step 87 : loss 35.024375915527344\n",
      "step 88 : loss 34.901268005371094\n",
      "step 89 : loss 34.76993942260742\n",
      "step 90 : loss 34.6336669921875\n",
      "step 91 : loss 34.50640869140625\n",
      "step 92 : loss 34.39131546020508\n",
      "step 93 : loss 34.274444580078125\n",
      "step 94 : loss 34.144203186035156\n",
      "step 95 : loss 34.00776672363281\n",
      "step 96 : loss 33.878013610839844\n",
      "step 97 : loss 33.75372314453125\n",
      "step 98 : loss 33.62546157836914\n",
      "step 99 : loss 33.49482727050781\n",
      "step 100 : loss 33.36991882324219\n",
      "step 101 : loss 33.246097564697266\n",
      "step 102 : loss 33.11348342895508\n",
      "step 103 : loss 32.97767639160156\n",
      "step 104 : loss 32.8483772277832\n",
      "step 105 : loss 32.71991729736328\n",
      "step 106 : loss 32.58642578125\n",
      "step 107 : loss 32.45365905761719\n",
      "step 108 : loss 32.32020568847656\n",
      "step 109 : loss 32.18028259277344\n",
      "step 110 : loss 32.041473388671875\n",
      "step 111 : loss 31.906272888183594\n",
      "step 112 : loss 31.766036987304688\n",
      "step 113 : loss 31.624460220336914\n",
      "step 114 : loss 31.482955932617188\n",
      "step 115 : loss 31.337352752685547\n",
      "step 116 : loss 31.194316864013672\n",
      "step 117 : loss 31.050765991210938\n",
      "step 118 : loss 30.90321159362793\n",
      "step 119 : loss 30.756534576416016\n",
      "step 120 : loss 30.607099533081055\n",
      "step 121 : loss 30.45844078063965\n",
      "step 122 : loss 30.30769920349121\n",
      "step 123 : loss 30.153465270996094\n",
      "step 124 : loss 29.99824333190918\n",
      "step 125 : loss 29.839839935302734\n",
      "step 126 : loss 29.679916381835938\n",
      "step 127 : loss 29.514774322509766\n",
      "step 128 : loss 29.34718132019043\n",
      "step 129 : loss 29.17525863647461\n",
      "step 130 : loss 28.99921226501465\n",
      "step 131 : loss 28.81756591796875\n",
      "step 132 : loss 28.630605697631836\n",
      "step 133 : loss 28.438884735107422\n",
      "step 134 : loss 28.23965835571289\n",
      "step 135 : loss 28.034378051757812\n",
      "step 136 : loss 27.82245445251465\n",
      "step 137 : loss 27.60194206237793\n",
      "step 138 : loss 27.37351417541504\n",
      "step 139 : loss 27.137218475341797\n",
      "step 140 : loss 26.891923904418945\n",
      "step 141 : loss 26.636945724487305\n",
      "step 142 : loss 26.373266220092773\n",
      "step 143 : loss 26.101093292236328\n",
      "step 144 : loss 25.828889846801758\n",
      "step 145 : loss 25.58705711364746\n",
      "step 146 : loss 25.504657745361328\n",
      "step 147 : loss 25.552040100097656\n",
      "step 148 : loss 25.011852264404297\n",
      "step 149 : loss 24.43297576904297\n",
      "step 150 : loss 24.451749801635742\n",
      "step 151 : loss 24.270647048950195\n",
      "step 152 : loss 23.687211990356445\n",
      "step 153 : loss 23.432283401489258\n",
      "step 154 : loss 23.423715591430664\n",
      "step 155 : loss 23.07402992248535\n",
      "step 156 : loss 22.563764572143555\n",
      "step 157 : loss 22.393068313598633\n",
      "step 158 : loss 22.34991455078125\n",
      "step 159 : loss 22.048593521118164\n",
      "step 160 : loss 21.56641387939453\n",
      "step 161 : loss 21.253631591796875\n",
      "step 162 : loss 21.171327590942383\n",
      "step 163 : loss 21.114063262939453\n",
      "step 164 : loss 20.8660831451416\n",
      "step 165 : loss 20.461069107055664\n",
      "step 166 : loss 20.07809829711914\n",
      "step 167 : loss 19.873262405395508\n",
      "step 168 : loss 19.792518615722656\n",
      "step 169 : loss 19.7813777923584\n",
      "step 170 : loss 19.724109649658203\n",
      "step 171 : loss 19.418561935424805\n",
      "step 172 : loss 19.022274017333984\n",
      "step 173 : loss 18.71096420288086\n",
      "step 174 : loss 18.61421775817871\n",
      "step 175 : loss 18.6307315826416\n",
      "step 176 : loss 18.617528915405273\n",
      "step 177 : loss 18.461181640625\n",
      "step 178 : loss 18.141096115112305\n",
      "step 179 : loss 17.887487411499023\n",
      "step 180 : loss 17.78303337097168\n",
      "step 181 : loss 17.79800033569336\n",
      "step 182 : loss 17.81109619140625\n",
      "step 183 : loss 17.70746612548828\n",
      "step 184 : loss 17.50408935546875\n",
      "step 185 : loss 17.298545837402344\n",
      "step 186 : loss 17.185955047607422\n",
      "step 187 : loss 17.160184860229492\n",
      "step 188 : loss 17.173364639282227\n",
      "step 189 : loss 17.16693878173828\n",
      "step 190 : loss 17.08915138244629\n",
      "step 191 : loss 16.9537296295166\n",
      "step 192 : loss 16.801183700561523\n",
      "step 193 : loss 16.682241439819336\n",
      "step 194 : loss 16.609355926513672\n",
      "step 195 : loss 16.57681655883789\n",
      "step 196 : loss 16.571399688720703\n",
      "step 197 : loss 16.592018127441406\n",
      "step 198 : loss 16.637123107910156\n",
      "step 199 : loss 16.667253494262695\n",
      "step 200 : loss 16.66202163696289\n",
      "step 201 : loss 16.52450180053711\n",
      "step 202 : loss 16.33652687072754\n",
      "step 203 : loss 16.1589412689209\n",
      "step 204 : loss 16.06283187866211\n",
      "step 205 : loss 16.04380226135254\n",
      "step 206 : loss 16.07735252380371\n",
      "step 207 : loss 16.13400650024414\n",
      "step 208 : loss 16.158287048339844\n",
      "step 209 : loss 16.132543563842773\n",
      "step 210 : loss 16.015775680541992\n",
      "step 211 : loss 15.875802040100098\n",
      "step 212 : loss 15.752238273620605\n",
      "step 213 : loss 15.681772232055664\n",
      "step 214 : loss 15.660322189331055\n",
      "step 215 : loss 15.672198295593262\n",
      "step 216 : loss 15.705528259277344\n",
      "step 217 : loss 15.736529350280762\n",
      "step 218 : loss 15.756326675415039\n",
      "step 219 : loss 15.71878719329834\n",
      "step 220 : loss 15.642518043518066\n",
      "step 221 : loss 15.527508735656738\n",
      "step 222 : loss 15.422446250915527\n",
      "step 223 : loss 15.34633731842041\n",
      "step 224 : loss 15.304872512817383\n",
      "step 225 : loss 15.29127311706543\n",
      "step 226 : loss 15.297479629516602\n",
      "step 227 : loss 15.319441795349121\n",
      "step 228 : loss 15.348713874816895\n",
      "step 229 : loss 15.385002136230469\n",
      "step 230 : loss 15.395085334777832\n",
      "step 231 : loss 15.378564834594727\n",
      "step 232 : loss 15.29830265045166\n",
      "step 233 : loss 15.19572639465332\n",
      "step 234 : loss 15.088751792907715\n",
      "step 235 : loss 15.010863304138184\n",
      "step 236 : loss 14.967416763305664\n",
      "step 237 : loss 14.953248023986816\n",
      "step 238 : loss 14.960309028625488\n",
      "step 239 : loss 14.980950355529785\n",
      "step 240 : loss 15.013232231140137\n",
      "step 241 : loss 15.04248046875\n",
      "step 242 : loss 15.067220687866211\n",
      "step 243 : loss 15.05189323425293\n",
      "step 244 : loss 15.007433891296387\n",
      "step 245 : loss 14.919285774230957\n",
      "step 246 : loss 14.827536582946777\n",
      "step 247 : loss 14.746210098266602\n",
      "step 248 : loss 14.690686225891113\n",
      "step 249 : loss 14.65967082977295\n",
      "step 250 : loss 14.64792537689209\n",
      "step 251 : loss 14.650934219360352\n",
      "step 252 : loss 14.66621208190918\n",
      "step 253 : loss 14.696708679199219\n",
      "step 254 : loss 14.737470626831055\n",
      "step 255 : loss 14.79236888885498\n",
      "step 256 : loss 14.824094772338867\n",
      "step 257 : loss 14.828058242797852\n",
      "step 258 : loss 14.752069473266602\n",
      "step 259 : loss 14.642339706420898\n",
      "step 260 : loss 14.520822525024414\n",
      "step 261 : loss 14.434313774108887\n",
      "step 262 : loss 14.391371726989746\n",
      "step 263 : loss 14.386423110961914\n",
      "step 264 : loss 14.407927513122559\n",
      "step 265 : loss 14.44249439239502\n",
      "step 266 : loss 14.482054710388184\n",
      "step 267 : loss 14.50322151184082\n",
      "step 268 : loss 14.504944801330566\n",
      "step 269 : loss 14.463278770446777\n",
      "step 270 : loss 14.401962280273438\n",
      "step 271 : loss 14.324712753295898\n",
      "step 272 : loss 14.257375717163086\n",
      "step 273 : loss 14.205124855041504\n",
      "step 274 : loss 14.170524597167969\n",
      "step 275 : loss 14.15005874633789\n",
      "step 276 : loss 14.140192031860352\n",
      "step 277 : loss 14.139305114746094\n",
      "step 278 : loss 14.147981643676758\n",
      "step 279 : loss 14.171514511108398\n",
      "step 280 : loss 14.212762832641602\n",
      "step 281 : loss 14.283387184143066\n",
      "step 282 : loss 14.361566543579102\n",
      "step 283 : loss 14.438200950622559\n",
      "step 284 : loss 14.41833209991455\n",
      "step 285 : loss 14.322163581848145\n",
      "step 286 : loss 14.152891159057617\n",
      "step 287 : loss 14.012579917907715\n",
      "step 288 : loss 13.93563461303711\n",
      "step 289 : loss 13.926410675048828\n",
      "step 290 : loss 13.965847969055176\n",
      "step 291 : loss 14.025222778320312\n",
      "step 292 : loss 14.079036712646484\n",
      "step 293 : loss 14.084870338439941\n",
      "step 294 : loss 14.047526359558105\n",
      "step 295 : loss 13.965682029724121\n",
      "step 296 : loss 13.883223533630371\n",
      "step 297 : loss 13.817505836486816\n",
      "step 298 : loss 13.77914047241211\n",
      "step 299 : loss 13.76479721069336\n",
      "step 300 : loss 13.768407821655273\n",
      "step 301 : loss 13.785286903381348\n",
      "step 302 : loss 13.810962677001953\n",
      "step 303 : loss 13.846172332763672\n",
      "step 304 : loss 13.879520416259766\n",
      "step 305 : loss 13.912489891052246\n",
      "step 306 : loss 13.91550064086914\n",
      "step 307 : loss 13.896822929382324\n",
      "step 308 : loss 13.835670471191406\n",
      "step 309 : loss 13.76362419128418\n",
      "step 310 : loss 13.687475204467773\n",
      "step 311 : loss 13.627991676330566\n",
      "step 312 : loss 13.5869722366333\n",
      "step 313 : loss 13.563437461853027\n",
      "step 314 : loss 13.553208351135254\n",
      "step 315 : loss 13.553064346313477\n",
      "step 316 : loss 13.56233024597168\n",
      "step 317 : loss 13.581629753112793\n",
      "step 318 : loss 13.617105484008789\n",
      "step 319 : loss 13.66753101348877\n",
      "step 320 : loss 13.741579055786133\n",
      "step 321 : loss 13.804922103881836\n",
      "step 322 : loss 13.84974193572998\n",
      "step 323 : loss 13.800814628601074\n",
      "step 324 : loss 13.699402809143066\n",
      "step 325 : loss 13.558652877807617\n",
      "step 326 : loss 13.448269844055176\n",
      "step 327 : loss 13.384848594665527\n",
      "step 328 : loss 13.369001388549805\n",
      "step 329 : loss 13.388933181762695\n",
      "step 330 : loss 13.429845809936523\n",
      "step 331 : loss 13.479497909545898\n",
      "step 332 : loss 13.513178825378418\n",
      "step 333 : loss 13.526052474975586\n",
      "step 334 : loss 13.494508743286133\n",
      "step 335 : loss 13.441685676574707\n",
      "step 336 : loss 13.371858596801758\n",
      "step 337 : loss 13.310784339904785\n",
      "step 338 : loss 13.263766288757324\n",
      "step 339 : loss 13.23400592803955\n",
      "step 340 : loss 13.218517303466797\n",
      "step 341 : loss 13.213739395141602\n",
      "step 342 : loss 13.217248916625977\n",
      "step 343 : loss 13.227822303771973\n",
      "step 344 : loss 13.247231483459473\n",
      "step 345 : loss 13.27417278289795\n",
      "step 346 : loss 13.313880920410156\n",
      "step 347 : loss 13.35348892211914\n",
      "step 348 : loss 13.395660400390625\n",
      "step 349 : loss 13.401949882507324\n",
      "step 350 : loss 13.381743431091309\n",
      "step 351 : loss 13.30974292755127\n",
      "step 352 : loss 13.2269287109375\n",
      "step 353 : loss 13.14395809173584\n",
      "step 354 : loss 13.084283828735352\n",
      "step 355 : loss 13.049689292907715\n",
      "step 356 : loss 13.037430763244629\n",
      "step 357 : loss 13.04185676574707\n",
      "step 358 : loss 13.057588577270508\n",
      "step 359 : loss 13.081735610961914\n",
      "step 360 : loss 13.10788631439209\n",
      "step 361 : loss 13.136746406555176\n",
      "step 362 : loss 13.153398513793945\n",
      "step 363 : loss 13.162453651428223\n",
      "step 364 : loss 13.1439208984375\n",
      "step 365 : loss 13.112970352172852\n",
      "step 366 : loss 13.061948776245117\n",
      "step 367 : loss 13.011244773864746\n",
      "step 368 : loss 12.962597846984863\n",
      "step 369 : loss 12.924673080444336\n",
      "step 370 : loss 12.896820068359375\n",
      "step 371 : loss 12.878227233886719\n",
      "step 372 : loss 12.866643905639648\n",
      "step 373 : loss 12.860241889953613\n",
      "step 374 : loss 12.858104705810547\n",
      "step 375 : loss 12.860166549682617\n",
      "step 376 : loss 12.868315696716309\n",
      "step 377 : loss 12.884071350097656\n",
      "step 378 : loss 12.913668632507324\n",
      "step 379 : loss 12.955991744995117\n",
      "step 380 : loss 13.019705772399902\n",
      "step 381 : loss 13.077702522277832\n",
      "step 382 : loss 13.128311157226562\n",
      "step 383 : loss 13.104503631591797\n",
      "step 384 : loss 13.036306381225586\n",
      "step 385 : loss 12.91757583618164\n",
      "step 386 : loss 12.813274383544922\n",
      "step 387 : loss 12.740825653076172\n",
      "step 388 : loss 12.709759712219238\n",
      "step 389 : loss 12.712896347045898\n",
      "step 390 : loss 12.738903999328613\n",
      "step 391 : loss 12.7765531539917\n",
      "step 392 : loss 12.808517456054688\n",
      "step 393 : loss 12.829204559326172\n",
      "step 394 : loss 12.81935977935791\n",
      "step 395 : loss 12.791932106018066\n",
      "step 396 : loss 12.744166374206543\n",
      "step 397 : loss 12.696784019470215\n",
      "step 398 : loss 12.65381908416748\n",
      "step 399 : loss 12.622271537780762\n",
      "step 400 : loss 12.601404190063477\n",
      "step 401 : loss 12.589659690856934\n",
      "step 402 : loss 12.584752082824707\n",
      "step 403 : loss 12.584940910339355\n",
      "step 404 : loss 12.589505195617676\n",
      "step 405 : loss 12.597837448120117\n",
      "step 406 : loss 12.611865997314453\n",
      "step 407 : loss 12.629843711853027\n",
      "step 408 : loss 12.656281471252441\n",
      "step 409 : loss 12.682235717773438\n",
      "step 410 : loss 12.713153839111328\n",
      "step 411 : loss 12.724937438964844\n",
      "step 412 : loss 12.72661304473877\n",
      "step 413 : loss 12.69189167022705\n",
      "step 414 : loss 12.645254135131836\n",
      "step 415 : loss 12.582351684570312\n",
      "step 416 : loss 12.526911735534668\n",
      "step 417 : loss 12.481332778930664\n",
      "step 418 : loss 12.450689315795898\n",
      "step 419 : loss 12.43280029296875\n",
      "step 420 : loss 12.425049781799316\n",
      "step 421 : loss 12.424825668334961\n",
      "step 422 : loss 12.43031120300293\n",
      "step 423 : loss 12.441427230834961\n",
      "step 424 : loss 12.457122802734375\n",
      "step 425 : loss 12.4805326461792\n",
      "step 426 : loss 12.506654739379883\n",
      "step 427 : loss 12.540644645690918\n",
      "step 428 : loss 12.56398868560791\n",
      "step 429 : loss 12.583108901977539\n",
      "step 430 : loss 12.567627906799316\n",
      "step 431 : loss 12.536785125732422\n",
      "step 432 : loss 12.477548599243164\n",
      "step 433 : loss 12.41881275177002\n",
      "step 434 : loss 12.363383293151855\n",
      "step 435 : loss 12.322905540466309\n",
      "step 436 : loss 12.296640396118164\n",
      "step 437 : loss 12.282995223999023\n",
      "step 438 : loss 12.278907775878906\n",
      "step 439 : loss 12.281901359558105\n",
      "step 440 : loss 12.29088306427002\n",
      "step 441 : loss 12.3047456741333\n",
      "step 442 : loss 12.325824737548828\n",
      "step 443 : loss 12.35069751739502\n",
      "step 444 : loss 12.384572982788086\n",
      "step 445 : loss 12.412799835205078\n",
      "step 446 : loss 12.44143295288086\n",
      "step 447 : loss 12.439668655395508\n",
      "step 448 : loss 12.422818183898926\n",
      "step 449 : loss 12.370027542114258\n",
      "step 450 : loss 12.312095642089844\n",
      "step 451 : loss 12.25016975402832\n",
      "step 452 : loss 12.20205020904541\n",
      "step 453 : loss 12.168342590332031\n",
      "step 454 : loss 12.149276733398438\n",
      "step 455 : loss 12.141746520996094\n",
      "step 456 : loss 12.142768859863281\n",
      "step 457 : loss 12.150416374206543\n",
      "step 458 : loss 12.163132667541504\n",
      "step 459 : loss 12.182328224182129\n",
      "step 460 : loss 12.205074310302734\n",
      "step 461 : loss 12.236038208007812\n",
      "step 462 : loss 12.26330852508545\n",
      "step 463 : loss 12.293170928955078\n",
      "step 464 : loss 12.298395156860352\n",
      "step 465 : loss 12.291885375976562\n",
      "step 466 : loss 12.249825477600098\n",
      "step 467 : loss 12.199966430664062\n",
      "step 468 : loss 12.139591217041016\n",
      "step 469 : loss 12.089288711547852\n",
      "step 470 : loss 12.049954414367676\n",
      "step 471 : loss 12.024420738220215\n",
      "step 472 : loss 12.010150909423828\n",
      "step 473 : loss 12.00456714630127\n",
      "step 474 : loss 12.005517959594727\n",
      "step 475 : loss 12.011754035949707\n",
      "step 476 : loss 12.023968696594238\n",
      "step 477 : loss 12.041860580444336\n",
      "step 478 : loss 12.069981575012207\n",
      "step 479 : loss 12.103734016418457\n",
      "step 480 : loss 12.150148391723633\n",
      "step 481 : loss 12.185898780822754\n",
      "step 482 : loss 12.217500686645508\n",
      "step 483 : loss 12.201324462890625\n",
      "step 484 : loss 12.163066864013672\n",
      "step 485 : loss 12.086851119995117\n",
      "step 486 : loss 12.014012336730957\n",
      "step 487 : loss 11.949874877929688\n",
      "step 488 : loss 11.90737533569336\n",
      "step 489 : loss 11.884476661682129\n",
      "step 490 : loss 11.877671241760254\n",
      "step 491 : loss 11.882840156555176\n",
      "step 492 : loss 11.896764755249023\n",
      "step 493 : loss 11.918730735778809\n",
      "step 494 : loss 11.945281028747559\n",
      "step 495 : loss 11.979989051818848\n",
      "step 496 : loss 12.010510444641113\n",
      "step 497 : loss 12.04306697845459\n",
      "step 498 : loss 12.049600601196289\n",
      "step 499 : loss 12.043999671936035\n",
      "step 500 : loss 12.001821517944336\n",
      "step 501 : loss 11.952134132385254\n",
      "step 502 : loss 11.891545295715332\n",
      "step 503 : loss 11.8411865234375\n",
      "step 504 : loss 11.801227569580078\n",
      "step 505 : loss 11.774622917175293\n",
      "step 506 : loss 11.758685111999512\n",
      "step 507 : loss 11.7509126663208\n",
      "step 508 : loss 11.749277114868164\n",
      "step 509 : loss 11.752777099609375\n",
      "step 510 : loss 11.762202262878418\n",
      "step 511 : loss 11.778568267822266\n",
      "step 512 : loss 11.80721378326416\n",
      "step 513 : loss 11.847524642944336\n",
      "step 514 : loss 11.909295082092285\n",
      "step 515 : loss 11.970467567443848\n",
      "step 516 : loss 12.035027503967285\n",
      "step 517 : loss 12.03576374053955\n",
      "step 518 : loss 11.998442649841309\n",
      "step 519 : loss 11.894893646240234\n",
      "step 520 : loss 11.793862342834473\n",
      "step 521 : loss 11.707636833190918\n",
      "step 522 : loss 11.655818939208984\n",
      "step 523 : loss 11.634285926818848\n",
      "step 524 : loss 11.636672019958496\n",
      "step 525 : loss 11.656713485717773\n",
      "step 526 : loss 11.688687324523926\n",
      "step 527 : loss 11.731632232666016\n",
      "step 528 : loss 11.772982597351074\n",
      "step 529 : loss 11.816452026367188\n",
      "step 530 : loss 11.8314790725708\n",
      "step 531 : loss 11.831841468811035\n",
      "step 532 : loss 11.789724349975586\n",
      "step 533 : loss 11.737918853759766\n",
      "step 534 : loss 11.672592163085938\n",
      "step 535 : loss 11.618224143981934\n",
      "step 536 : loss 11.574579238891602\n",
      "step 537 : loss 11.54526424407959\n",
      "step 538 : loss 11.526991844177246\n",
      "step 539 : loss 11.517107963562012\n",
      "step 540 : loss 11.513385772705078\n",
      "step 541 : loss 11.514813423156738\n",
      "step 542 : loss 11.5221586227417\n",
      "step 543 : loss 11.537118911743164\n",
      "step 544 : loss 11.56584358215332\n",
      "step 545 : loss 11.610899925231934\n",
      "step 546 : loss 11.68591594696045\n",
      "step 547 : loss 11.771570205688477\n",
      "step 548 : loss 11.870820999145508\n",
      "step 549 : loss 11.889443397521973\n",
      "step 550 : loss 11.850302696228027\n",
      "step 551 : loss 11.713677406311035\n",
      "step 552 : loss 11.582124710083008\n",
      "step 553 : loss 11.476475715637207\n",
      "step 554 : loss 11.419417381286621\n",
      "step 555 : loss 11.402689933776855\n",
      "step 556 : loss 11.41663932800293\n",
      "step 557 : loss 11.453804969787598\n",
      "step 558 : loss 11.505794525146484\n",
      "step 559 : loss 11.571268081665039\n",
      "step 560 : loss 11.622215270996094\n",
      "step 561 : loss 11.663118362426758\n",
      "step 562 : loss 11.645350456237793\n",
      "step 563 : loss 11.6039457321167\n",
      "step 564 : loss 11.52371597290039\n",
      "step 565 : loss 11.450008392333984\n",
      "step 566 : loss 11.385115623474121\n",
      "step 567 : loss 11.34068775177002\n",
      "step 568 : loss 11.312976837158203\n",
      "step 569 : loss 11.29859733581543\n",
      "step 570 : loss 11.293865203857422\n",
      "step 571 : loss 11.296753883361816\n",
      "step 572 : loss 11.307564735412598\n",
      "step 573 : loss 11.32806396484375\n",
      "step 574 : loss 11.365309715270996\n",
      "step 575 : loss 11.421059608459473\n",
      "step 576 : loss 11.509077072143555\n",
      "step 577 : loss 11.59840202331543\n",
      "step 578 : loss 11.688467025756836\n",
      "step 579 : loss 11.67424488067627\n",
      "step 580 : loss 11.603294372558594\n",
      "step 581 : loss 11.456831932067871\n",
      "step 582 : loss 11.332521438598633\n",
      "step 583 : loss 11.242271423339844\n",
      "step 584 : loss 11.196288108825684\n",
      "step 585 : loss 11.184361457824707\n",
      "step 586 : loss 11.198039054870605\n",
      "step 587 : loss 11.23299789428711\n",
      "step 588 : loss 11.285247802734375\n",
      "step 589 : loss 11.358715057373047\n",
      "step 590 : loss 11.429033279418945\n",
      "step 591 : loss 11.499616622924805\n",
      "step 592 : loss 11.501200675964355\n",
      "step 593 : loss 11.466948509216309\n",
      "step 594 : loss 11.366698265075684\n",
      "step 595 : loss 11.270403861999512\n",
      "step 596 : loss 11.184087753295898\n",
      "step 597 : loss 11.12732982635498\n",
      "step 598 : loss 11.09449291229248\n",
      "step 599 : loss 11.080435752868652\n",
      "step 600 : loss 11.080055236816406\n",
      "step 601 : loss 11.091046333312988\n",
      "step 602 : loss 11.114888191223145\n",
      "step 603 : loss 11.153955459594727\n",
      "step 604 : loss 11.219024658203125\n",
      "step 605 : loss 11.301603317260742\n",
      "step 606 : loss 11.41035270690918\n",
      "step 607 : loss 11.467375755310059\n",
      "step 608 : loss 11.480162620544434\n",
      "step 609 : loss 11.372162818908691\n",
      "step 610 : loss 11.246164321899414\n",
      "step 611 : loss 11.11850643157959\n",
      "step 612 : loss 11.034928321838379\n",
      "step 613 : loss 10.989121437072754\n",
      "step 614 : loss 10.97383975982666\n",
      "step 615 : loss 10.98082160949707\n",
      "step 616 : loss 11.006179809570312\n",
      "step 617 : loss 11.051666259765625\n",
      "step 618 : loss 11.115715026855469\n",
      "step 619 : loss 11.20691204071045\n",
      "step 620 : loss 11.287032127380371\n",
      "step 621 : loss 11.356826782226562\n",
      "step 622 : loss 11.324454307556152\n",
      "step 623 : loss 11.25039005279541\n",
      "step 624 : loss 11.121133804321289\n",
      "step 625 : loss 11.016276359558105\n",
      "step 626 : loss 10.938151359558105\n",
      "step 627 : loss 10.894081115722656\n",
      "step 628 : loss 10.87449836730957\n",
      "step 629 : loss 10.872737884521484\n",
      "step 630 : loss 10.885271072387695\n",
      "step 631 : loss 10.91215705871582\n",
      "step 632 : loss 10.959590911865234\n",
      "step 633 : loss 11.0278902053833\n",
      "step 634 : loss 11.129342079162598\n",
      "step 635 : loss 11.217954635620117\n",
      "step 636 : loss 11.291911125183105\n",
      "step 637 : loss 11.245026588439941\n",
      "step 638 : loss 11.152149200439453\n",
      "step 639 : loss 11.009509086608887\n",
      "step 640 : loss 10.900001525878906\n",
      "step 641 : loss 10.824494361877441\n",
      "step 642 : loss 10.784868240356445\n",
      "step 643 : loss 10.770174980163574\n",
      "step 644 : loss 10.7733154296875\n",
      "step 645 : loss 10.791557312011719\n",
      "step 646 : loss 10.825923919677734\n",
      "step 647 : loss 10.884303092956543\n",
      "step 648 : loss 10.963509559631348\n",
      "step 649 : loss 11.072213172912598\n",
      "step 650 : loss 11.147172927856445\n",
      "step 651 : loss 11.188977241516113\n",
      "step 652 : loss 11.107757568359375\n",
      "step 653 : loss 10.998167037963867\n",
      "step 654 : loss 10.866233825683594\n",
      "step 655 : loss 10.774237632751465\n",
      "step 656 : loss 10.71491813659668\n",
      "step 657 : loss 10.685565948486328\n",
      "step 658 : loss 10.67561149597168\n",
      "step 659 : loss 10.679632186889648\n",
      "step 660 : loss 10.695544242858887\n",
      "step 661 : loss 10.725247383117676\n",
      "step 662 : loss 10.774040222167969\n",
      "step 663 : loss 10.84222412109375\n",
      "step 664 : loss 10.935285568237305\n",
      "step 665 : loss 11.012575149536133\n",
      "step 666 : loss 11.073997497558594\n",
      "step 667 : loss 11.032753944396973\n",
      "step 668 : loss 10.963964462280273\n",
      "step 669 : loss 10.840949058532715\n",
      "step 670 : loss 10.747905731201172\n",
      "step 671 : loss 10.667391777038574\n",
      "step 672 : loss 10.616128921508789\n",
      "step 673 : loss 10.582561492919922\n",
      "step 674 : loss 10.566144943237305\n",
      "step 675 : loss 10.564342498779297\n",
      "step 676 : loss 10.57632064819336\n",
      "step 677 : loss 10.60387134552002\n",
      "step 678 : loss 10.647013664245605\n",
      "step 679 : loss 10.718499183654785\n",
      "step 680 : loss 10.80196762084961\n",
      "step 681 : loss 10.917679786682129\n",
      "step 682 : loss 10.97793960571289\n",
      "step 683 : loss 11.006436347961426\n",
      "step 684 : loss 10.913970947265625\n",
      "step 685 : loss 10.796199798583984\n",
      "step 686 : loss 10.665034294128418\n",
      "step 687 : loss 10.567819595336914\n",
      "step 688 : loss 10.504640579223633\n",
      "step 689 : loss 10.472251892089844\n",
      "step 690 : loss 10.462813377380371\n",
      "step 691 : loss 10.469978332519531\n",
      "step 692 : loss 10.490313529968262\n",
      "step 693 : loss 10.523581504821777\n",
      "step 694 : loss 10.574984550476074\n",
      "step 695 : loss 10.644153594970703\n",
      "step 696 : loss 10.741470336914062\n",
      "step 697 : loss 10.819690704345703\n",
      "step 698 : loss 10.884038925170898\n",
      "step 699 : loss 10.82965087890625\n",
      "step 700 : loss 10.743430137634277\n",
      "step 701 : loss 10.608028411865234\n",
      "step 702 : loss 10.506446838378906\n",
      "step 703 : loss 10.433907508850098\n",
      "step 704 : loss 10.393872261047363\n",
      "step 705 : loss 10.374831199645996\n",
      "step 706 : loss 10.368766784667969\n",
      "step 707 : loss 10.371163368225098\n",
      "step 708 : loss 10.380816459655762\n",
      "step 709 : loss 10.402023315429688\n",
      "step 710 : loss 10.438199996948242\n",
      "step 711 : loss 10.503458976745605\n",
      "step 712 : loss 10.591322898864746\n",
      "step 713 : loss 10.713518142700195\n",
      "step 714 : loss 10.790312767028809\n",
      "step 715 : loss 10.822524070739746\n",
      "step 716 : loss 10.72046947479248\n",
      "step 717 : loss 10.594307899475098\n",
      "step 718 : loss 10.458012580871582\n",
      "step 719 : loss 10.366541862487793\n",
      "step 720 : loss 10.309791564941406\n",
      "step 721 : loss 10.281736373901367\n",
      "step 722 : loss 10.271965026855469\n",
      "step 723 : loss 10.27517032623291\n",
      "step 724 : loss 10.290060043334961\n",
      "step 725 : loss 10.318448066711426\n",
      "step 726 : loss 10.367717742919922\n",
      "step 727 : loss 10.43696403503418\n",
      "step 728 : loss 10.538196563720703\n",
      "step 729 : loss 10.621216773986816\n",
      "step 730 : loss 10.691164016723633\n",
      "step 731 : loss 10.644193649291992\n",
      "step 732 : loss 10.56167221069336\n",
      "step 733 : loss 10.431700706481934\n",
      "step 734 : loss 10.33171558380127\n",
      "step 735 : loss 10.258164405822754\n",
      "step 736 : loss 10.21469497680664\n",
      "step 737 : loss 10.190839767456055\n",
      "step 738 : loss 10.179834365844727\n",
      "step 739 : loss 10.177412986755371\n",
      "step 740 : loss 10.1820650100708\n",
      "step 741 : loss 10.195589065551758\n",
      "step 742 : loss 10.22082805633545\n",
      "step 743 : loss 10.267807960510254\n",
      "step 744 : loss 10.338176727294922\n",
      "step 745 : loss 10.449040412902832\n",
      "step 746 : loss 10.553926467895508\n",
      "step 747 : loss 10.64882755279541\n",
      "step 748 : loss 10.609975814819336\n",
      "step 749 : loss 10.514803886413574\n",
      "step 750 : loss 10.360401153564453\n",
      "step 751 : loss 10.240676879882812\n",
      "step 752 : loss 10.156647682189941\n",
      "step 753 : loss 10.110514640808105\n",
      "step 754 : loss 10.089845657348633\n",
      "step 755 : loss 10.086617469787598\n",
      "step 756 : loss 10.09674072265625\n",
      "step 757 : loss 10.119881629943848\n",
      "step 758 : loss 10.160543441772461\n",
      "step 759 : loss 10.219691276550293\n",
      "step 760 : loss 10.307168960571289\n",
      "step 761 : loss 10.392684936523438\n",
      "step 762 : loss 10.476804733276367\n",
      "step 763 : loss 10.469658851623535\n",
      "step 764 : loss 10.420867919921875\n",
      "step 765 : loss 10.302245140075684\n",
      "step 766 : loss 10.200892448425293\n",
      "step 767 : loss 10.11446475982666\n",
      "step 768 : loss 10.060149192810059\n",
      "step 769 : loss 10.026321411132812\n",
      "step 770 : loss 10.007883071899414\n",
      "step 771 : loss 9.998802185058594\n",
      "step 772 : loss 9.996293067932129\n",
      "step 773 : loss 9.999424934387207\n",
      "step 774 : loss 10.009462356567383\n",
      "step 775 : loss 10.030360221862793\n",
      "step 776 : loss 10.067770004272461\n",
      "step 777 : loss 10.134110450744629\n",
      "step 778 : loss 10.229641914367676\n",
      "step 779 : loss 10.362497329711914\n",
      "step 780 : loss 10.453798294067383\n",
      "step 781 : loss 10.493191719055176\n",
      "step 782 : loss 10.381360054016113\n",
      "step 783 : loss 10.246835708618164\n",
      "step 784 : loss 10.103535652160645\n",
      "step 785 : loss 10.01443099975586\n",
      "step 786 : loss 9.96218204498291\n",
      "step 787 : loss 9.941819190979004\n",
      "step 788 : loss 9.937544822692871\n",
      "step 789 : loss 9.944836616516113\n",
      "step 790 : loss 9.957101821899414\n",
      "step 791 : loss 9.977361679077148\n",
      "step 792 : loss 10.009450912475586\n",
      "step 793 : loss 10.058028221130371\n",
      "step 794 : loss 10.135565757751465\n",
      "step 795 : loss 10.21162223815918\n",
      "step 796 : loss 10.293417930603027\n",
      "step 797 : loss 10.276926040649414\n",
      "step 798 : loss 10.226655960083008\n",
      "step 799 : loss 10.103229522705078\n",
      "step 800 : loss 10.003317832946777\n",
      "step 801 : loss 9.92393970489502\n",
      "step 802 : loss 9.877988815307617\n",
      "step 803 : loss 9.852755546569824\n",
      "step 804 : loss 9.838991165161133\n",
      "step 805 : loss 9.830144882202148\n",
      "step 806 : loss 9.821992874145508\n",
      "step 807 : loss 9.815387725830078\n",
      "step 808 : loss 9.81136703491211\n",
      "step 809 : loss 9.814075469970703\n",
      "step 810 : loss 9.827548027038574\n",
      "step 811 : loss 9.861139297485352\n",
      "step 812 : loss 9.924310684204102\n",
      "step 813 : loss 10.038617134094238\n",
      "step 814 : loss 10.188074111938477\n",
      "step 815 : loss 10.35705852508545\n",
      "step 816 : loss 10.378070831298828\n",
      "step 817 : loss 10.292905807495117\n",
      "step 818 : loss 10.08571720123291\n",
      "step 819 : loss 9.924402236938477\n",
      "step 820 : loss 9.81242561340332\n",
      "step 821 : loss 9.756117820739746\n",
      "step 822 : loss 9.732950210571289\n",
      "step 823 : loss 9.732441902160645\n",
      "step 824 : loss 9.750129699707031\n",
      "step 825 : loss 9.787638664245605\n",
      "step 826 : loss 9.852058410644531\n",
      "step 827 : loss 9.93657398223877\n",
      "step 828 : loss 10.04592227935791\n",
      "step 829 : loss 10.105955123901367\n",
      "step 830 : loss 10.130096435546875\n",
      "step 831 : loss 10.041894912719727\n",
      "step 832 : loss 9.94124698638916\n",
      "step 833 : loss 9.830244064331055\n",
      "step 834 : loss 9.753739356994629\n",
      "step 835 : loss 9.702390670776367\n",
      "step 836 : loss 9.672119140625\n",
      "step 837 : loss 9.654242515563965\n",
      "step 838 : loss 9.643479347229004\n",
      "step 839 : loss 9.637062072753906\n",
      "step 840 : loss 9.633720397949219\n",
      "step 841 : loss 9.63430404663086\n",
      "step 842 : loss 9.64056396484375\n",
      "step 843 : loss 9.658136367797852\n",
      "step 844 : loss 9.693761825561523\n",
      "step 845 : loss 9.76574420928955\n",
      "step 846 : loss 9.879164695739746\n",
      "step 847 : loss 10.052774429321289\n",
      "step 848 : loss 10.179099082946777\n",
      "step 849 : loss 10.229536056518555\n",
      "step 850 : loss 10.073325157165527\n",
      "step 851 : loss 9.889893531799316\n",
      "step 852 : loss 9.721718788146973\n",
      "step 853 : loss 9.620882034301758\n",
      "step 854 : loss 9.567641258239746\n",
      "step 855 : loss 9.54667854309082\n",
      "step 856 : loss 9.54638957977295\n",
      "step 857 : loss 9.562646865844727\n",
      "step 858 : loss 9.597343444824219\n",
      "step 859 : loss 9.653707504272461\n",
      "step 860 : loss 9.740900039672852\n",
      "step 861 : loss 9.839488983154297\n",
      "step 862 : loss 9.944258689880371\n",
      "step 863 : loss 9.963578224182129\n",
      "step 864 : loss 9.929159164428711\n",
      "step 865 : loss 9.807393074035645\n",
      "step 866 : loss 9.698328018188477\n",
      "step 867 : loss 9.602936744689941\n",
      "step 868 : loss 9.544849395751953\n",
      "step 869 : loss 9.509096145629883\n",
      "step 870 : loss 9.491575241088867\n",
      "step 871 : loss 9.483260154724121\n",
      "step 872 : loss 9.482251167297363\n",
      "step 873 : loss 9.483814239501953\n",
      "step 874 : loss 9.489554405212402\n",
      "step 875 : loss 9.4955472946167\n",
      "step 876 : loss 9.506332397460938\n",
      "step 877 : loss 9.520882606506348\n",
      "step 878 : loss 9.549582481384277\n",
      "step 879 : loss 9.604217529296875\n",
      "step 880 : loss 9.69546127319336\n",
      "step 881 : loss 9.840964317321777\n",
      "step 882 : loss 9.954963684082031\n",
      "step 883 : loss 10.024072647094727\n",
      "step 884 : loss 9.886714935302734\n",
      "step 885 : loss 9.72398853302002\n",
      "step 886 : loss 9.551239013671875\n",
      "step 887 : loss 9.446075439453125\n",
      "step 888 : loss 9.389657020568848\n",
      "step 889 : loss 9.368227005004883\n",
      "step 890 : loss 9.367254257202148\n",
      "step 891 : loss 9.378122329711914\n",
      "step 892 : loss 9.399704933166504\n",
      "step 893 : loss 9.430986404418945\n",
      "step 894 : loss 9.485271453857422\n",
      "step 895 : loss 9.558026313781738\n",
      "step 896 : loss 9.66684627532959\n",
      "step 897 : loss 9.752098083496094\n",
      "step 898 : loss 9.805848121643066\n",
      "step 899 : loss 9.74088191986084\n",
      "step 900 : loss 9.630682945251465\n",
      "step 901 : loss 9.498302459716797\n",
      "step 902 : loss 9.401825904846191\n",
      "step 903 : loss 9.338942527770996\n",
      "step 904 : loss 9.305558204650879\n",
      "step 905 : loss 9.288596153259277\n",
      "step 906 : loss 9.280366897583008\n",
      "step 907 : loss 9.275382995605469\n",
      "step 908 : loss 9.272567749023438\n",
      "step 909 : loss 9.272360801696777\n",
      "step 910 : loss 9.278258323669434\n",
      "step 911 : loss 9.296331405639648\n",
      "step 912 : loss 9.335782051086426\n",
      "step 913 : loss 9.415200233459473\n",
      "step 914 : loss 9.537323951721191\n",
      "step 915 : loss 9.713339805603027\n",
      "step 916 : loss 9.81236457824707\n",
      "step 917 : loss 9.824055671691895\n",
      "step 918 : loss 9.648259162902832\n",
      "step 919 : loss 9.47329044342041\n",
      "step 920 : loss 9.328500747680664\n",
      "step 921 : loss 9.245100975036621\n",
      "step 922 : loss 9.201568603515625\n",
      "step 923 : loss 9.182930946350098\n",
      "step 924 : loss 9.179537773132324\n",
      "step 925 : loss 9.187834739685059\n",
      "step 926 : loss 9.209659576416016\n",
      "step 927 : loss 9.248011589050293\n",
      "step 928 : loss 9.314577102661133\n",
      "step 929 : loss 9.40323257446289\n",
      "step 930 : loss 9.521151542663574\n",
      "step 931 : loss 9.591666221618652\n",
      "step 932 : loss 9.612196922302246\n",
      "step 933 : loss 9.515613555908203\n",
      "step 934 : loss 9.397400856018066\n",
      "step 935 : loss 9.277652740478516\n",
      "step 936 : loss 9.19543743133545\n",
      "step 937 : loss 9.142541885375977\n",
      "step 938 : loss 9.112311363220215\n",
      "step 939 : loss 9.095571517944336\n",
      "step 940 : loss 9.087050437927246\n",
      "step 941 : loss 9.083966255187988\n",
      "step 942 : loss 9.085625648498535\n",
      "step 943 : loss 9.093257904052734\n",
      "step 944 : loss 9.110344886779785\n",
      "step 945 : loss 9.144708633422852\n",
      "step 946 : loss 9.205560684204102\n",
      "step 947 : loss 9.30907154083252\n",
      "step 948 : loss 9.43757438659668\n",
      "step 949 : loss 9.572288513183594\n",
      "step 950 : loss 9.583024978637695\n",
      "step 951 : loss 9.510627746582031\n",
      "step 952 : loss 9.345215797424316\n",
      "step 953 : loss 9.217018127441406\n",
      "step 954 : loss 9.123061180114746\n",
      "step 955 : loss 9.07550048828125\n",
      "step 956 : loss 9.050015449523926\n",
      "step 957 : loss 9.041266441345215\n",
      "step 958 : loss 9.03575325012207\n",
      "step 959 : loss 9.034749984741211\n",
      "step 960 : loss 9.033591270446777\n",
      "step 961 : loss 9.039429664611816\n",
      "step 962 : loss 9.058055877685547\n",
      "step 963 : loss 9.098210334777832\n",
      "step 964 : loss 9.172408103942871\n",
      "step 965 : loss 9.26337718963623\n",
      "step 966 : loss 9.369512557983398\n",
      "step 967 : loss 9.387392044067383\n",
      "step 968 : loss 9.355022430419922\n",
      "step 969 : loss 9.23269271850586\n",
      "step 970 : loss 9.12602710723877\n",
      "step 971 : loss 9.038485527038574\n",
      "step 972 : loss 8.986104011535645\n",
      "step 973 : loss 8.955388069152832\n",
      "step 974 : loss 8.937451362609863\n",
      "step 975 : loss 8.925497055053711\n",
      "step 976 : loss 8.91482925415039\n",
      "step 977 : loss 8.904768943786621\n",
      "step 978 : loss 8.894560813903809\n",
      "step 979 : loss 8.885252952575684\n",
      "step 980 : loss 8.877034187316895\n",
      "step 981 : loss 8.870214462280273\n",
      "step 982 : loss 8.864715576171875\n",
      "step 983 : loss 8.860339164733887\n",
      "step 984 : loss 8.856919288635254\n",
      "step 985 : loss 8.854488372802734\n",
      "step 986 : loss 8.853758811950684\n",
      "step 987 : loss 8.856367111206055\n",
      "step 988 : loss 8.86657428741455\n",
      "step 989 : loss 8.893301010131836\n",
      "step 990 : loss 8.95518684387207\n",
      "step 991 : loss 9.087127685546875\n",
      "step 992 : loss 9.308263778686523\n",
      "step 993 : loss 9.593844413757324\n",
      "step 994 : loss 9.649911880493164\n",
      "step 995 : loss 9.499217987060547\n",
      "step 996 : loss 9.179985046386719\n",
      "step 997 : loss 8.971445083618164\n",
      "step 998 : loss 8.854049682617188\n",
      "step 999 : loss 8.80898380279541\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAia0lEQVR4Ae2d2Y4kx3WGK5eq7umZIYeLKMmCIBgG/AS+8yv4Tf0gNnxlGPCNBViyFpsSJS4z7KUqN5///050RU0PxaHI6brJBCoq8sSWGfGfEydOLNn80z//22az+cXf/U240/Q83M+XXbjz3RjuZrkMZ2ztbw7hbzZtuP1i/yJ60zp+1zi0C3dZ7G+X8CtFXHjlS6+pvi+UvDn5q5Kd0L/vzeKMlwfPclrefF/M7DdamsmUbbhNqzeYGrntrJiza2OhTkbRG1fb1dOr8G92qqXr5Y/hPhluw/3PX/5HuKrN9TpjDfR3lz+O4n/byl3unoR7cfcy3GZSG87P3M5DH/6pV/s3i9oMBLVGQd8INzPg6fTXjHIX08OjS9mUCzT5zgAKnxOTQ4n1CP/lofRGxc+/n99vyrO1BmpDrNkcYH8zqWZ6Q32Ebn9/oRx2nWpsaiRFNpYrV8NdeJ9vvwr34uk/huuM43+9zlQD/SfvC/u7vdpqmH8X7ngh/7zI7ZtX4Tat2nnpjRTku/mjMYA7hzazsLOACyN6Nps8lLMR7XjBSg9kMbg7RntLHzx0BPFfSEYkRTj6Xi/VfOBn80tv6NQa9wT0D7NJs3vEGTC7v9xbEsyT6nDZfxbuPPw+3KkVB8yDeOjmUrW6ckBUwjmv/mV/EeVfDUO4Ta/+ut2q5Q8ibK7crI0BYIhvWovDplHrNRvpPE0jlwsILuaMphFKUm6CM9MT9E5AH1BDlhyiA3Facj26GXokpC+7mxrMtd+x6rS8UU3B35CRHxF/Yw4YmyNSUzfK/JUOStPqv/dbj9YMp141M5iyda0ujWr7rhMHdB+pio/5xs16PX4N9PMkub/pX4RzcA++20h9RasZzAGz9dzWPT4yfXHLtchHg2eGQUyZJ2EhlQhTTgRthOkyhOzQc0BN13meopKQB8CGTNQqiweEKiyeDaFuGu+SfRXZZ+m6gUeXhH2VCTnA5Q5GEMDxDQmcanIdMlaYWo2f+uVWGS0rB1T1eS5vf7WVPNpdqLHaUTJr6SSnGku9tlOLLa3ok7X+tsIO40NEIJjqrBW0yPoeOB0xm6g8kbORcQh8x6lyzrE0HEYGFSqVJq6SXX1jf5WAsMw5E9zH4Z7HKU/p/3QKLRLwhC6ys4SAg+H7xlXQWU4w/J1ytKQcLmZJlN7ccGEN6mJUrSJd1j4gquKcVz93z6L8lHFucg9jRYvfaEk9A7ZZWi3XPKsNidMs5hva3DGBS0EKKRwbSFVqUJv5GwfwjSmFA0gr8GRSE077DIU05EkkciApz5P+6s88kRzgOPV4ZUm9hnDLhtRWRGH0wzvO1gOnqvR8BFfVSLVab5xcCu5obqCnXDmgapVzePtlr754v5EVaDaWuwvJLLCZ+rLx0lgx6iwyOxrOzQ0ikHoNfYCh01bjA14NRAVcuQ0XnaE1vuaNxhYF68oa0c14ItPwVyHdSYquYpSRA/o7hOwCqlASkA3vmNxMduaAzMF+ekEC6eEY97bJK64OP1v2Z53epcc6kM9sTjKvzObR2X3kygFZ5ef668PEE2Wjz6SstxafY1FbM9Bkw+ytp2xt33Bvjhxs3DdMbufUgm0p8gRBoE4B0BOJIEJ5pTxFpkOenWnRLkSDjpTHX+eTKHasjEkK3xTJ7sLSKbHus67le5bmN02/4i9GLmVhGWWc5GFAcIHiYBcg96XSguDIdJ3PslEdzi535YCoinNe/WLtvmnUEzAH0NuKTQeOPaQ1xmfL7haLf6PRw+yRc8cY2E2f2gvNitUo3y6REXeoDJCRs6nDGEctBTt6m+Yn3RQ9B2w6tQFZepFj/uAULgG5FrkUWFwHp83K5Sankg3j24yrEsktuQ1trRo+zJYNaIPUEpbgzq+K7khvQQ6YVRsrQysHlCY5039vI/8GDYcuvTdg0kLiBkoJCAf4QQdrOGi16E60c+MxM++y0GcYU6cSPGEW0bAm6T8u50m5Me4WweQZHiUfpG1i34lMIT79RY4SkNqOmdyg6MkMC1k7T94ue4sK3UVZUyRm98AvzwzSmSGf01aqx+XdUhdyFov70dlv1DpmyoCqPvVk63WWGghVVW3WdtL9Q6iHM1l2g4jF9g1arLW+FFEVf5LLyoDF8zvoA92WUXEEhlHE0tOYQAKWPIXulL8GJ3anCXQwAwFylU3MQOjZUprDAbgpeRU19fGU3SQ+9hYFlcot9TH3NPAKT15Gv0axM0gw81f1CgS2cJi5M7nHMeccGVC6SoaTkDRlDKQ8BitSZnI92Hqdpwb6nnaw/G0ntUc7GLnHJgymUIu5sTfYOx0l5wws4rIXaa0XzcZXCkYDoLFFMCUpNiUDCd0Z6Q9SmtkcBizNkW2BaDxDos91hV22uCZlnvYDe1PwltSEKiA5I4PJWy5SIaFc52A/cr/GMpok8UtZ+s/3ReOiI+IN3NNQ3soBbo/zOf3USqPfeKZmttG66zQmiMnNcCajdUkLj/mjE0LvrLfQqOi/jISRjIwDcyRsWZlDBYN8cQ6kTSuQx42jLYuLeZGVNgZKzNOBKrEk3NA5MSNSP9rGg5OEOJhiOIF6FQnjKtg83kAp88N5F8E8LTaukgrw665zpsj6epVUk7Ys5b/kuyg+PSV4n/zk+OGhlQNUX2e8+jLDZUtkrxbD2tcYwOjgPF/O+hpyi3sOkGLDn6YO4srWToQaPXY6w5VuhVFiprVMhIc2Hl1Ptsi2G8+XGh5FgzIHOH6HDHXfgGad/YcfFETDPdlp+Hns8CrhKmueB70ICm6OzzMLJfFLJIcx2s8bGMPhmarEVTL7sxRg7xtsR1iTVg5wRZ3P6WlmkDujgy/uFdxWqTWj7Y6ip2V0o3njTS/Yz5NXR1vo7rbuPwzIXW9/rrBzTCNiwtpqcC7G++wSwQXYH0nl53GUSCkITcQsxvig0Is0XpMcqlhQOpfSeOSJ4QnMoq0n3t3rwIUxCR6pSmjFGck3HuPDPlVfSB+AtQf7fo6QXTpTjMwVL35aNCt6puRF88TKAVH557z60Rr6ZhJCm0HtsVgXAinFNmm6R8WN8csaocn60jIK6dOoHFj7yJzB6G4BJDYeH0xGaEGBAFBs6LCbJC3SNleoeVxyT4vQIqmF2aQby6mN0BU4CzQx4pT5BgIQxn4jE1Kvz5JBZD6FC4Fi90S1quK4N6HGUmZU6lcpXeUWv9ImU6mM9TpfDfRWuze9tX7aZIQDDJRhkHxvbf/pva4RlZs+w0rT5onnD0aj7+mV1ny1Xi180d2EnzVi2HOSA/y2OQfnNabDRr3L7ah56WlR7zJPosCLdx6LsPoa2OTQGOUfQ5Wx2dbWFeh+KrDKaAb8p4ymAyTmvU4UBTtVYpkEGSfCAtvkh18uulaulvANTwsFPQ07AhYwRshYn+Av57I656iBPpbDRbkDHOD+uvOgFnGK3X/xIojFmglj0WaS3O+McXccsXpuL0r753AvNsL+1fY6XDSB3nPI3jiVeEn9ZyMOu/NOtG7zfvgPs/jg4F0lw6S9JdlP2LQE38CRCX2zrfuQmGEWNhNTJxwgerFZhjcuAbtOVbQghSEJwHnZF2ZGoFJcwmKeI2bmY84opYjGyCBzg5MyB5XiRyhPa8LqnKEG+h0IOkjbnbR9I9hBDrpBt9UI+bDzCMCSunfwj55+GfSuF8Y/Wv433I330vzsyX+H93L7Ktz3duIGtKAuZ8eMREYVnlFA7u/nq4j56vBJuHfTs3C/vP0o3H3/XP7x43Cnjbjh5eaDcNtB+YzumZhBazZew5qDGvAeUdJ2hNBm/X49Tq6il3UPZh+Qm2MIkAs7wGGJfWEcO0Jyj0PLKFoJskQPN+BOuEFPFnxGv8XN6p6rBvq0LNJ6xulsiY8OMHeS0aMtpsMg7XuyRv/1LIn/ZBbS+81X4W474f3Z/Fm4V92X4b7fi95mz6GeBqtOziRb/dotkvi3zdNwWS3TNy/CH91LOK9sj7rdiD8OBs/WT9i725mxBVnWA1MljKui5FoK4zfFb4YqRaIVEe6kOTdulqn5AB5Ce8kuwvGVx/0Fl3CLvyqXeNkxOU7qSPfJV89ZaqAfAAYDPYn6aFOhL9cN7IwU60VXdtFnP+7/FHHe6+R+sJHcb578Uf6n/yX6xdfhXr2vLgXdKdT78PfG79IJcsx83Y3C/t47qq4m5TbdfhjuZ96i1u9vwn93LS5kh8mrG/UHo3PgyVs/PyMPcIqFB+zHwr+IDxzDExfPD7rLijY9T2rldAuZSu9e5oqN4MJEpjtXy/FSAuUc3aIRQYHRkhMiB4pKnS3u1+ssNdDn/i830nxQe3QMjm1j4ZAINKUL23YuFuH6Rf+v4f742a/C/en8y3A3u/8L5/n2t3JbjYcvfLYEVkNmTTtL7cljAnZbtsuziLkxB7TeS961Qn3fqW8AQS/bn4R/nES5MOKwpI9YgcyvaEEtq4mwlYJN3gU9JPX+yCay1gsn3C3HATf4TE2JiI6E7M554LwB16Rw1HSgO39zEnxWuKSOKf/KAa/XyCPfx0jYbWCHhT+jW3gyXpbtGA+EDnvVS7Jf9p+G+8HF78L98Pmvw/3pLOwvl9KILnfKaOt2bVthdoM13OhebNXpbMPpFba56PV/aY3+equxSHf3ZbhXl78Kd9lKu/96fE/+aR/u9fxJuNOoXmHvMUpjvsy5a4+W2akLtnLmjm7BQjgxnlJeOGUnBHZKNJwTaV3AHzHBNpjFX7slPCLmRegJj/imynLlgFJZ5/rv0VIQmLOFKzjNeUtr3A2nfozigKV5KXf5Mtxp+kLuE/UK7IDdGyWdbZm7g7jHA4bN6P2XKVs9MsCUecEKuwupXzc3ir/1qRXbRaUw69C1P5e/lb7U+ayFxb0LEp+xRctMtaX5yRyyRXuuN7U/OSBBGFm+8XoDdt8Y7/sT4afvn8+aw19ZAyEw1Qatz7ppvQKuSChJwh2oMWafd0L6U9t/ftII+z/ZifLckvowSoIvnJkzKs8Gm75XusETs0cDG5/FhT4+eMQ7O/5gEvtpl3aIHPoL9StPr/4U7p3to92NKAtnWvSX4cemOVsjQo6jzzCuZt5iYQIhZbgTIYuJar4B80XPcZxHcVYOeJRq/uZCevQEVkRjbZ88Pzxbu0AT3/lUg8aWn9bu0/7zyPN591m4/aX0k+FWHIOUn2w3Rb9avNrHIIvTWBSnow9w00+99JmmkbXn2fgy3Pc8z8z+5KvYvalSRL+z+8yzDnvO5EFPs+4/Ws8xA0duXcQv6zLDy4YUee4vLF15C/jTpY9IfriP/y0eopP0W6K+HrxywOs18sj3fWfdudmqJTj/qTfekcLYrLcpkTW+3V5oDqC91Hh1cyV/dymELvKGlEUuK7fR870br5lobMEHlZ11KrTvwTl3tvxMRjHrU1lx1BA6qaxuEDe03qPJ+h8zUtqsWB0U4XoG9wfiteAty/30k8B0nOwzYM90HfI9EF1l/1ZePfF6nbEGYm2bJGbrOd7J8rQ1QhtjrbVFvksRLiG3eOTcMGdgP7P+GcVnQeUa/+q10LVydZgXk86W1Mji4goNrPtklfXWdpidtaOdLanoTuK0ctFLwVvFuulQazjFDlNix/9fJeSr9D+wd+WAH7hCv2t2/c7YB7NYB1nHAMi2xnhv4CG1WY+/Nb46j5ybPAVKbXmL1cUr2hb3K0UXUii29dmaDA86+ixSVh6Mkyw/+wu5GC4P5jNWXi6em5tt/1nYiebeK204iWtjn9EGOj4jAL9YrrZzzOQ5x0Fzq7uAEz8P+s7clQPeWdW+XcaxMk4WmBC9chm1cnrELDtlM4hub+wbkbY+zs/CHfbSdqZRcSbHIeaFCAEg6R3o8rnL3rPKiy1CW+YVrCMdvJqB4+W2tnH2FypxstbErOnkk1ym+UJ5et3c5HVE7E8uqyIiMMrVaJw9lzmjK3IC2m94332YV3LQT49Cz+EEEKq0FcHUH85ZOeCHq8u/Kqce2TqyH8YaNHoRu5n22Ii8E7hrxQFTKw740nxwdSt/YwY52NbfegzRMavs1dQH53znebSyKob5MrX9xMlb1tDZUR6L9II+DLJ9vvKuq+vbT+S/+1G413cvwr05PA/3Fn3MPcHOsn5Gc3MxuVe9AnfZ7x9J73lCwYVXjv7kFUWs9C3fvtmpE7w5xjdSVw74xqp5nIC+8xmJYWiP8pDa5XQgP0AjW00gNX5z/0TuTtgcbJ1f2hfh33gt2+aV5P7OttWdcTcav5yKkzyBNuLx6s7uaBS7U4gTewWkZ15yfT2rj+k9X9Z4N07r3Mq+YsVM/Sd84QeDuKDe9Noh8ISS8b8hgaN+U5YPc6tzfnv/ygFvX1fvJGY/e2cL684mz391nCNtOe5F05vJ/HFzkB4ye/XyV9sX4f9iUB8wjaI34124253s9ehU3W4Mb8uSaM/6IlDbnfqArcfDo8+TmDx7PHpEcmsd7CsZfjavBuV8O6jvuZ7EebetKAdraxNjeKBo3sp57IgRT2VY545Pxykco4CHuK65AP/DOM44nTp+Tf+u/pUDvmuN/cDxY05YbdAb9fT5NueETVEIYPSbWLM1f/LXAu7mn0bojb+F8uSrPyiHvUC7dZwnPn8ruCUonMK151RZ43prfuptvB/NH5Pj3xj7h4O0oNErIab2/fAfjP3JewUmj7E5cZM1rIAZeydjgkQ63YLHuqj7NWaJU1augfUo6u10HkU8vWqWOQ351ruVA761it5thH7wgojc08R42NpInqZoaTt77cKwl910nCTBPz18oOfaS0O/vfrbcJ8fvhDFuwdujej+va/jvvOuyhEOwDLjGeDOc7zXSPl+GzH3N0/C3e6E+i/Gvw/38+m9cP88/jzcz4YPwz14DHzwPBqn1+V6CKw6lW0nUW1smhypfSVa/VeFph5VYj3a/8oBj1bVby6oXxoJ5sWWmckClZ3mNsbEvUYAk9cubD3mZB3n1ntXmouPFbr5KNyDrZWLd40xu7CYe2JJW4S22SsM4WefZZ8nQ0i3OXhu4LZ7P/xD8zzcL5cX4b4aRbm+U5w788rBvUjubWZFRYRJdoNou/bjo4eAG4hTcwah6TofnIxTUd6dd+WAd1e3b5VzbBB2G1gzyXNDAZMPUedU3Dwly6o1K23+PAj7LHg4eFbgutWk8LKXpL7xyoknt38I/3YW6hu+HuSewEXFuglp9C/95bJr7xG7PoiTmub9cF9Z7l/faJxxa/owajQQh72H29EzWblBvsOdzIul7u+RNnoNr5grIegnIheV5T+YJWGvvxOCo7w7Z+WAd1e3b5VznJwraw9IR6Pgm4jsMOFsn8OsUe4yYxfS+LbrPwj3U6/Zv2mlq7Se5/p8fhH+57P0n/e8uxHr/ybXlUpf7zx/0E/igBvvjmdv8BeLuKeb1Qe8Gl+EO3gW4dbzAYPHH3vraTwtq9iYJc6ZYSbSsJLSE7DoNfKKK7EPviGZfPSmL5nhAf1dEFYOeBe1+h3y7Jf8nINaAinZe21a531YrdchoyMd2D5gq87g9T/DnVD89STkMnvVff2z8D/1PNfO64W26FHLTdDZl7L1wujWc1u3nksYvHvg4K80xW6BiDiyvojRuLHvzTsyIUUos7sdJ7h7kpo9AbmrnRXXKi8YU3iHs/kOARKedURlJOyYKflr/nhrTnjriJRUuysH1LVxBn8seABTLtstiRZRTj+GDo7wq83Ym5iatXmCnfVtr3Eya6SX/NKA5P5ipC/Yfwyy1mdfDUbraN7aJ3I1KoYnkO+cRohRlQE15/lyTjWnsbD3WDxc+Bgkl3Oh/WLmJzSfGuekioS+vgeYSxbf6X/lgO9UXT985Dw7OpY/RN6sX4uPfcpvkHACOqiYfQbc4ukrTszf8PVoztwy+qbhoLQeMXAS3Gj7zwR0bctkb37nFdSzOYNvEbWMnD0m35onzJyxU6yPPDm7izPaQHGHtdXPiRErovk64hsf/VNq/SXSg/8j9jNVSfxazGJtNZlEjplnAVVkEpJNZuKbKlGOVjJ0/Xv8GohzQ12oD4DmPDhOQI/BawRwBhXfN2pZ7WxYpoU9TYiWYzSrJxNiqUWk5eTRXA3nFXOMSEenYlXP3vYcWYtkEeLfGfGN4lz3oEdkb3DOMRj7ubfd2stUj2+t+/No6n/iSXAZOfsGCq+O31FSEyr+OgR/RTFDkQMuqSgNLqliv5ZziRs1fPSuvnPUQKyOVvtxpglryrx8LVbA6XHQQ0av+ZnZoejVCbQb35ABYMkMbnR0dr4Aw0nL7BXwAud7DUpRc72miuKw6twBMLl34Sz2Jtf1+4F8VguntjXeJ4N2z85IdHxGM8nZxmnuHqBbc1k4NUILRGua/PlVHF6vdgtfOSunqqvgYegJ5cgzKwdUDXIOb3zYQchK+W6JVL4n47ZB9HremD2UNCScwU4VTptAbcqxpcxF8akNMCt/ntvD2mkR4jIKUnYbQQ5dcBOQioMOk1LViM61bDybk6aGk6qbSS7j6BOWRSrr4OrgIx5NvXeO9DJmhlK5FAyBwo6J7vOpPA/irBxQ1c45vPHJJI08F++KKaccq5k4L2iwLWhkJkDqeChHbmJrGmX/iSiAj/0tVm0ipvKhhTlPH7iw+4X1Fixpw5/r9OljrGvljgTzKGWB4mAK5ewHKZByOaZTLixU9siXWOI7ICoKPnFFoZd4/NvloSOG4ohSc6TJZFByK1lkkBLYm9x5JONbOeD1Gnnk+zg9nTZwM0l9z3WWc0pwyfFYPBQuOk/afJyI3eiLdfYCLAUg6vnuaioOnJhu0GKfQYDz5ciU+7Ud39nl2v/UfCLjoGqsgBxHg4IjeaqTFdGKnuCrUW9yhtQcwLinpCCW6uREo4cb3qDtKD7aF/FJf+rCCKe0IiFep673j1YDHKoWDeH2cdvybciUtqawWiL1JWPTrML2r1gtKi5J9BmhFtoBCWtBzqFgVu+FdT6lP3HMT6nvmyPxJ286ThkxKE9yS1mewPKdC2SMrZKEX12JTccsOCRvwuVnRzS9S5H1dRxnZI4qfEZ2dq0lvoHu+KTELfxBuaJRRh1n9T9qDYR4N36xrmTD0Kq4eppyzo/8tJjDAuJKULp3EmdI0EtrQyGd3DxHEXQ4B2Q0J1UIr7L4OH5yDzkcUVPmtkw3Oc94zIj6I3Z5hiDEdaRzf8yR+5LqzXeFWv5JnUUGMfnySCgRq/+HgdRLFWX1Pm4N9LPns5D4HDfIrhUsk2VGCS5Rm3PyIctHJ88N8PUKtONUoZCJFcBKjyKSBXUgXH64B8mL1QicQk9Nv4JN4gV9n5qqQiHkM/gmlfh8Ev7yRqWTwA9nZksKb106ED8vwVlNxxwyDrxlcmpc+cIuIKPrr5DtN/evHEAjnM0NLUitgcUfyZunlqTdRi1EuxVJrfiDdRWbfNKKyUnOfGs1BXjVuMWmeHxPMM4gRDlGKSal35jiXLki8RWS+Ero6i8xXvMBjAMqlXHiuvwdKZlNGrZMN6l8I8M3OA9cehdekdVTOe9GvwXHKMt4ZiWml2IGu2hxoleVpMjr9dg1EPsQLeMQzCmSvQKOlvQoFKlaLDNqN9T3tPx4r1ZOWbHwMym8jNsfL3m6xBwZmF4woph5mRFAd34pzM+WMfwHr5QE/icBkcy2xEkuSYF9TJcRTS9yn4KVW8GpczY5YV2SOcAxTWG0Ab+lPYoxzX288JDWJbLjc+WAunrO4I8+QGsgcjTgtWmz52ax1eRJEu4Pmpyz9VMmGKQrgZ2U6cyd5RwWratGT9RZOyp3ohXs25+9jvJH1qfFFOzTEVUIgpC5JV1pi1WVfKqAxJ3opOKp0nXEYs9xFDNO9jr5Bo4L+0NhhtzRESI8VekVRCs2AvutXGK5os9YOcCVdz4nV0ez0o1xQPkGlh6q2COBh9vQOgPndNLmmIQ4fZH1OZyqhcArKKu4AZLfOfFp7CcZEhLc/vwSJCzG2Bu/cyBVnnFkSpGzusn87/+JEG4mowC5xKS3yNGP47D2IuV7srniwhmlXNVEajh+8nxbx89acpELip0lAXmuHBBVd86rXw7GNdqLWwwsAImuspKmyl0FZz9eQRcVvEh2t26lOpSIzgKMV9jM0Ko2KKpgrdwJrfkQ93FTywZlCe/7wPA8yLsoRvdhPCZz13nSbto4nY8z4L2Y0cvBEZZa24BPVma4JpErdZ9ULMrKM2dWnP3qnK0GevZEZuu5PTtOfDNq0IIaLxUCI6CA0XKC26M5+oDeLV92rNfyDczKPeEDsJx4rHDqfDIuw2XSpd/1VfMrhKzGmleSpL8Ttjk+SVqxHDFT8jz0dpkB73J8whz3OtOGM1/gElcKYwhMXclV1gxnTud2/p3XNdV1lEWtf49ZA/3kz+fV33lPqFkCtl7Mll23R7DFqqOWw/5T1hEJALn+h51ZRiuYydUJCaAKimANekVOm6npZS5MN4ks11Ch+4bxPPTCY7qDkzIfYuJS2NF9Q0/Dim6iMG9R85z9zAwyU90y/ve700vll2StBpWRtkpnzXksng3/ygG0x9ncvmUX/Fargw5b7Ybk/Fy+/J7S3CdX0fsvVvUXn+yGVCUHuKHjbGfaHCRaJtYzXMC9vLEBZhJjSACHwE68OwBWKRxQJXBGtV50whlkSmEnBascUmVPVsVkwM45MpDreeYcMzmAb5lN9rdOhtbfMqQyvr3wPA4MUIk8ArzSHkRZOYDGOZvbzz679rDVfsehl/vEZwfRho2/pIdInz1eLV+aRPqpDTlfcWIdkRuUdi5o1buBI+ggDm0KpNdCW7FPL5VRLvjghD8ySHmXmJTjgCTVoSRQQInnSH5EKJxxzdwGiM5zLxzRUI60ztP9BF8T51S7tKo5I/ayTch6r0Dcev9o7+9FNT4nbOUA2uNsbs/ZbWhB24Mart+71f1NGL52wW76aVQ/wRppzjVn3pgdYZNVpa0RgSV18dlBaE3qWYQ4QQg7Unh81UgstNP/mpOSlTIleD2NrbvX6QZuUvETp9DLf7wdrJor+ETPFSFVnhkbue9X5SwNbLd834/ZEc6enz2e4JlGy/1cO+sdRysHPGy/R6XEl/SE96UaleXOSFP4pgY7fpkBLuhSKnr/HeNA9B/zAX3GxnMDR8l8fK+ShyjgibDarzjlvo5fp3mdXmO/pCXnOtWRUvtyBAPSMWlV8xOFfVxXvmGAwXw1X/PjVAF2WWMVLjMolhTeN8cXNHmxxfa3lQPqVjiDP86ME1ba8bkKf+oDqYxcdOHOTTm7B6eX50uT7iVi9Km2pf9Y+PaSe3y+H7nxd8RAYo6EVUZovqLVWlBBa/l3tMp5Hekl3uv0Ksm3eEsORCOfows3NN7Ln2NaXthj3QmZ4d4OjDMC4Ax4mAfbAV9nG3baWMEXpIZbnyTgMwH2v/806CsHfEtTvevg/qvPfh1lXH74D+HuvRxie/cy/IxvkVmLd60MVsLByQ7bntuPPexoCygRyRORS7nQmssd/+QkLJax6CkuS+yk8udEmdubo5dkf/G/1qx4ZvqPXIOUOVvi83AGaqK1dHEqwScMdGz/dC1l4KXHSXQF9o47SYv2mbLeWj/cOnTlAFXjGa/+F7/5TRQ/tP8TLt+tuPHqB07ljM8F6OGw/BkLzJFufD4Eswgj63ywFDJUTfs4m8rIQNAF8/fKjQOEiARcBov8jVdG/cbw7xigIsvomuJ5X2dTrXjgKGrOZMn4jo59n11G7GLD8hPHq0YWWm+i/UVy4ZLrW9Enn5796b//S/hXDlDtnPH6f554I73epY36AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_init_tensor = image_to_tensor(new_image)\n",
    "\n",
    "autoencoder = AutoEncoder()\n",
    "lr = 1e-4\n",
    "num_steps = 1000\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters() , lr=lr)\n",
    "for step in range(num_steps):\n",
    "    y = autoencoder(new_init_tensor)\n",
    "    loss = (y-new_init_tensor).norm()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"step {step} : loss {loss.item()}\")\n",
    "\n",
    "result = autoencoder(new_init_tensor)\n",
    "tensor_to_image(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_train = 20\n",
    "num_images_test = 5\n",
    "dataset_train = [None] * num_images_train\n",
    "dataset_test = [None] * num_images_test\n",
    "\n",
    "for i in range(num_images_train):\n",
    "    dataset_train[i] = image_to_tensor(generate_image(image_size))\n",
    "\n",
    "for i in range(num_images_test):\n",
    "    dataset_test[i] = image_to_tensor(generate_image(image_size))\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 : loss 116.97880554199219\n",
      "step 1 : loss 116.64715576171875\n",
      "step 2 : loss 116.29903411865234\n",
      "step 3 : loss 115.91722106933594\n",
      "step 4 : loss 115.4833984375\n",
      "step 5 : loss 114.97599029541016\n",
      "step 6 : loss 114.3666000366211\n",
      "step 7 : loss 113.6183090209961\n",
      "step 8 : loss 112.6842269897461\n",
      "step 9 : loss 111.5044174194336\n",
      "step 10 : loss 110.00482177734375\n",
      "step 11 : loss 108.0951156616211\n",
      "step 12 : loss 105.66751861572266\n",
      "step 13 : loss 102.5966796875\n",
      "step 14 : loss 98.74269104003906\n",
      "step 15 : loss 93.96373748779297\n",
      "step 16 : loss 88.15357971191406\n",
      "step 17 : loss 81.33827209472656\n",
      "step 18 : loss 73.92469787597656\n",
      "step 19 : loss 67.32197570800781\n",
      "step 20 : loss 64.80978393554688\n",
      "step 21 : loss 68.824462890625\n",
      "step 22 : loss 72.8460464477539\n",
      "step 23 : loss 72.23407745361328\n",
      "step 24 : loss 68.79522705078125\n",
      "step 25 : loss 65.153564453125\n",
      "step 26 : loss 62.92864227294922\n",
      "step 27 : loss 62.42051315307617\n",
      "step 28 : loss 63.03845977783203\n",
      "step 29 : loss 64.01029205322266\n",
      "step 30 : loss 64.80449676513672\n",
      "step 31 : loss 65.18022155761719\n",
      "step 32 : loss 65.09380340576172\n",
      "step 33 : loss 64.61366271972656\n",
      "step 34 : loss 63.87248992919922\n",
      "step 35 : loss 63.039215087890625\n",
      "step 36 : loss 62.29072189331055\n",
      "step 37 : loss 61.77143478393555\n",
      "step 38 : loss 61.545814514160156\n",
      "step 39 : loss 61.56987380981445\n",
      "step 40 : loss 61.71001052856445\n",
      "step 41 : loss 61.80983352661133\n",
      "step 42 : loss 61.765968322753906\n",
      "step 43 : loss 61.5658073425293\n",
      "step 44 : loss 61.27167892456055\n",
      "step 45 : loss 60.97315216064453\n",
      "step 46 : loss 60.74090576171875\n",
      "step 47 : loss 60.6031608581543\n",
      "step 48 : loss 60.5470085144043\n",
      "step 49 : loss 60.53440475463867\n",
      "step 50 : loss 60.52174758911133\n",
      "step 51 : loss 60.47435760498047\n",
      "step 52 : loss 60.37451934814453\n",
      "step 53 : loss 60.22290802001953\n",
      "step 54 : loss 60.03568649291992\n",
      "step 55 : loss 59.838661193847656\n",
      "step 56 : loss 59.6591796875\n",
      "step 57 : loss 59.51755905151367\n",
      "step 58 : loss 59.41986083984375\n",
      "step 59 : loss 59.35493850708008\n",
      "step 60 : loss 59.29848098754883\n",
      "step 61 : loss 59.2232780456543\n",
      "step 62 : loss 59.11170196533203\n",
      "step 63 : loss 58.962982177734375\n",
      "step 64 : loss 58.79180908203125\n",
      "step 65 : loss 58.61922073364258\n",
      "step 66 : loss 58.4618034362793\n",
      "step 67 : loss 58.32523727416992\n",
      "step 68 : loss 58.20349884033203\n",
      "step 69 : loss 58.083778381347656\n",
      "step 70 : loss 57.95299530029297\n",
      "step 71 : loss 57.80364990234375\n",
      "step 72 : loss 57.6366081237793\n",
      "step 73 : loss 57.46014404296875\n",
      "step 74 : loss 57.28602981567383\n",
      "step 75 : loss 57.123321533203125\n",
      "step 76 : loss 56.97331619262695\n",
      "step 77 : loss 56.828643798828125\n",
      "step 78 : loss 56.67830276489258\n",
      "step 79 : loss 56.51637649536133\n",
      "step 80 : loss 56.3472785949707\n",
      "step 81 : loss 56.18274688720703\n",
      "step 82 : loss 56.032325744628906\n",
      "step 83 : loss 55.89643478393555\n",
      "step 84 : loss 55.76723098754883\n",
      "step 85 : loss 55.636009216308594\n",
      "step 86 : loss 55.5012092590332\n",
      "step 87 : loss 55.36836624145508\n",
      "step 88 : loss 55.24312210083008\n",
      "step 89 : loss 55.122772216796875\n",
      "step 90 : loss 54.99762725830078\n",
      "step 91 : loss 54.86181640625\n",
      "step 92 : loss 54.71966552734375\n",
      "step 93 : loss 54.57880783081055\n",
      "step 94 : loss 54.43879318237305\n",
      "step 95 : loss 54.29180145263672\n",
      "step 96 : loss 54.13340377807617\n",
      "step 97 : loss 53.96870803833008\n",
      "step 98 : loss 53.8044319152832\n",
      "step 99 : loss 53.63835906982422\n",
      "step 100 : loss 53.463623046875\n",
      "step 101 : loss 53.28065872192383\n",
      "step 102 : loss 53.094520568847656\n",
      "step 103 : loss 52.90241622924805\n",
      "step 104 : loss 52.696922302246094\n",
      "step 105 : loss 52.48063278198242\n",
      "step 106 : loss 52.25938034057617\n",
      "step 107 : loss 52.028221130371094\n",
      "step 108 : loss 51.785614013671875\n",
      "step 109 : loss 51.53955078125\n",
      "step 110 : loss 51.28602981567383\n",
      "step 111 : loss 51.022735595703125\n",
      "step 112 : loss 50.75886535644531\n",
      "step 113 : loss 50.48728561401367\n",
      "step 114 : loss 50.21177673339844\n",
      "step 115 : loss 49.92797088623047\n",
      "step 116 : loss 49.63246536254883\n",
      "step 117 : loss 49.32428741455078\n",
      "step 118 : loss 49.000160217285156\n",
      "step 119 : loss 48.65283966064453\n",
      "step 120 : loss 48.286216735839844\n",
      "step 121 : loss 47.8953857421875\n",
      "step 122 : loss 47.483551025390625\n",
      "step 123 : loss 47.05796432495117\n",
      "step 124 : loss 46.625328063964844\n",
      "step 125 : loss 46.20160675048828\n",
      "step 126 : loss 45.855377197265625\n",
      "step 127 : loss 45.82472229003906\n",
      "step 128 : loss 45.570404052734375\n",
      "step 129 : loss 44.718116760253906\n",
      "step 130 : loss 44.731971740722656\n",
      "step 131 : loss 44.451690673828125\n",
      "step 132 : loss 43.78691864013672\n",
      "step 133 : loss 43.879371643066406\n",
      "step 134 : loss 43.39427947998047\n",
      "step 135 : loss 42.993873596191406\n",
      "step 136 : loss 42.95143127441406\n",
      "step 137 : loss 42.504554748535156\n",
      "step 138 : loss 42.17298126220703\n",
      "step 139 : loss 42.053749084472656\n",
      "step 140 : loss 41.708553314208984\n",
      "step 141 : loss 41.32097625732422\n",
      "step 142 : loss 41.22605895996094\n",
      "step 143 : loss 40.889198303222656\n",
      "step 144 : loss 40.51199722290039\n",
      "step 145 : loss 40.27241516113281\n",
      "step 146 : loss 40.06219482421875\n",
      "step 147 : loss 39.65876007080078\n",
      "step 148 : loss 39.2821159362793\n",
      "step 149 : loss 38.94938278198242\n",
      "step 150 : loss 38.68548583984375\n",
      "step 151 : loss 38.401512145996094\n",
      "step 152 : loss 38.08538055419922\n",
      "step 153 : loss 37.68468475341797\n",
      "step 154 : loss 37.252479553222656\n",
      "step 155 : loss 36.86870574951172\n",
      "step 156 : loss 36.505043029785156\n",
      "step 157 : loss 36.194053649902344\n",
      "step 158 : loss 35.91541290283203\n",
      "step 159 : loss 35.826133728027344\n",
      "step 160 : loss 36.364498138427734\n",
      "step 161 : loss 37.26513671875\n",
      "step 162 : loss 35.261993408203125\n",
      "step 163 : loss 34.989540100097656\n",
      "step 164 : loss 35.946937561035156\n",
      "step 165 : loss 34.40169143676758\n",
      "step 166 : loss 34.74213790893555\n",
      "step 167 : loss 34.80573654174805\n",
      "step 168 : loss 33.77617645263672\n",
      "step 169 : loss 34.53834915161133\n",
      "step 170 : loss 33.637386322021484\n",
      "step 171 : loss 33.653099060058594\n",
      "step 172 : loss 33.65057373046875\n",
      "step 173 : loss 33.025543212890625\n",
      "step 174 : loss 33.33038330078125\n",
      "step 175 : loss 32.77790069580078\n",
      "step 176 : loss 32.809791564941406\n",
      "step 177 : loss 32.69577407836914\n",
      "step 178 : loss 32.33383560180664\n",
      "step 179 : loss 32.52302551269531\n",
      "step 180 : loss 32.064762115478516\n",
      "step 181 : loss 32.14141082763672\n",
      "step 182 : loss 31.946269989013672\n",
      "step 183 : loss 31.75351333618164\n",
      "step 184 : loss 31.796600341796875\n",
      "step 185 : loss 31.513797760009766\n",
      "step 186 : loss 31.523128509521484\n",
      "step 187 : loss 31.395782470703125\n",
      "step 188 : loss 31.221996307373047\n",
      "step 189 : loss 31.23980712890625\n",
      "step 190 : loss 31.033111572265625\n",
      "step 191 : loss 30.978946685791016\n",
      "step 192 : loss 30.907550811767578\n",
      "step 193 : loss 30.737131118774414\n",
      "step 194 : loss 30.71720314025879\n",
      "step 195 : loss 30.578266143798828\n",
      "step 196 : loss 30.47857666015625\n",
      "step 197 : loss 30.422494888305664\n",
      "step 198 : loss 30.282581329345703\n",
      "step 199 : loss 30.211822509765625\n",
      "step 200 : loss 30.125381469726562\n",
      "step 201 : loss 29.9992618560791\n",
      "step 202 : loss 29.936756134033203\n",
      "step 203 : loss 29.828210830688477\n",
      "step 204 : loss 29.721294403076172\n",
      "step 205 : loss 29.65060043334961\n",
      "step 206 : loss 29.534008026123047\n",
      "step 207 : loss 29.440526962280273\n",
      "step 208 : loss 29.355676651000977\n",
      "step 209 : loss 29.24338722229004\n",
      "step 210 : loss 29.149734497070312\n",
      "step 211 : loss 29.05813980102539\n",
      "step 212 : loss 28.94869613647461\n",
      "step 213 : loss 28.849590301513672\n",
      "step 214 : loss 28.7556095123291\n",
      "step 215 : loss 28.645248413085938\n",
      "step 216 : loss 28.539758682250977\n",
      "step 217 : loss 28.441959381103516\n",
      "step 218 : loss 28.331064224243164\n",
      "step 219 : loss 28.218124389648438\n",
      "step 220 : loss 28.112728118896484\n",
      "step 221 : loss 28.003000259399414\n",
      "step 222 : loss 27.885522842407227\n",
      "step 223 : loss 27.7687931060791\n",
      "step 224 : loss 27.655420303344727\n",
      "step 225 : loss 27.540502548217773\n",
      "step 226 : loss 27.420917510986328\n",
      "step 227 : loss 27.297924041748047\n",
      "step 228 : loss 27.1765079498291\n",
      "step 229 : loss 27.0562801361084\n",
      "step 230 : loss 26.937368392944336\n",
      "step 231 : loss 26.821481704711914\n",
      "step 232 : loss 26.709564208984375\n",
      "step 233 : loss 26.611902236938477\n",
      "step 234 : loss 26.554943084716797\n",
      "step 235 : loss 26.591487884521484\n",
      "step 236 : loss 26.813207626342773\n",
      "step 237 : loss 27.05167579650879\n",
      "step 238 : loss 26.76384925842285\n",
      "step 239 : loss 26.12765121459961\n",
      "step 240 : loss 25.888097763061523\n",
      "step 241 : loss 26.136959075927734\n",
      "step 242 : loss 26.26357650756836\n",
      "step 243 : loss 25.873077392578125\n",
      "step 244 : loss 25.54183006286621\n",
      "step 245 : loss 25.633670806884766\n",
      "step 246 : loss 25.775671005249023\n",
      "step 247 : loss 25.572643280029297\n",
      "step 248 : loss 25.268291473388672\n",
      "step 249 : loss 25.244699478149414\n",
      "step 250 : loss 25.36688804626465\n",
      "step 251 : loss 25.28590965270996\n",
      "step 252 : loss 25.04564666748047\n",
      "step 253 : loss 24.92514991760254\n",
      "step 254 : loss 24.974231719970703\n",
      "step 255 : loss 24.997920989990234\n",
      "step 256 : loss 24.867691040039062\n",
      "step 257 : loss 24.698993682861328\n",
      "step 258 : loss 24.628467559814453\n",
      "step 259 : loss 24.644556045532227\n",
      "step 260 : loss 24.646970748901367\n",
      "step 261 : loss 24.5658016204834\n",
      "step 262 : loss 24.438474655151367\n",
      "step 263 : loss 24.338088989257812\n",
      "step 264 : loss 24.295400619506836\n",
      "step 265 : loss 24.290376663208008\n",
      "step 266 : loss 24.283588409423828\n",
      "step 267 : loss 24.24909019470215\n",
      "step 268 : loss 24.17947769165039\n",
      "step 269 : loss 24.092220306396484\n",
      "step 270 : loss 24.006155014038086\n",
      "step 271 : loss 23.93465232849121\n",
      "step 272 : loss 23.87868309020996\n",
      "step 273 : loss 23.835430145263672\n",
      "step 274 : loss 23.80268669128418\n",
      "step 275 : loss 23.78278160095215\n",
      "step 276 : loss 23.78559684753418\n",
      "step 277 : loss 23.830154418945312\n",
      "step 278 : loss 23.942432403564453\n",
      "step 279 : loss 24.105823516845703\n",
      "step 280 : loss 24.191865921020508\n",
      "step 281 : loss 24.003978729248047\n",
      "step 282 : loss 23.658836364746094\n",
      "step 283 : loss 23.419124603271484\n",
      "step 284 : loss 23.394258499145508\n",
      "step 285 : loss 23.516828536987305\n",
      "step 286 : loss 23.634166717529297\n",
      "step 287 : loss 23.591196060180664\n",
      "step 288 : loss 23.395456314086914\n",
      "step 289 : loss 23.223928451538086\n",
      "step 290 : loss 23.168277740478516\n",
      "step 291 : loss 23.202470779418945\n",
      "step 292 : loss 23.239212036132812\n",
      "step 293 : loss 23.221683502197266\n",
      "step 294 : loss 23.15290069580078\n",
      "step 295 : loss 23.07392120361328\n",
      "step 296 : loss 23.020368576049805\n",
      "step 297 : loss 22.969125747680664\n",
      "step 298 : loss 22.913562774658203\n",
      "step 299 : loss 22.854618072509766\n",
      "step 300 : loss 22.826183319091797\n",
      "step 301 : loss 22.838109970092773\n",
      "step 302 : loss 22.866743087768555\n",
      "step 303 : loss 22.88473129272461\n",
      "step 304 : loss 22.84615135192871\n",
      "step 305 : loss 22.789058685302734\n",
      "step 306 : loss 22.737918853759766\n",
      "step 307 : loss 22.719249725341797\n",
      "step 308 : loss 22.711978912353516\n",
      "step 309 : loss 22.67403793334961\n",
      "step 310 : loss 22.60736083984375\n",
      "step 311 : loss 22.532323837280273\n",
      "step 312 : loss 22.485368728637695\n",
      "step 313 : loss 22.471538543701172\n",
      "step 314 : loss 22.46605110168457\n",
      "step 315 : loss 22.45536994934082\n",
      "step 316 : loss 22.42287826538086\n",
      "step 317 : loss 22.39908790588379\n",
      "step 318 : loss 22.399049758911133\n",
      "step 319 : loss 22.438365936279297\n",
      "step 320 : loss 22.49636459350586\n",
      "step 321 : loss 22.5194034576416\n",
      "step 322 : loss 22.469419479370117\n",
      "step 323 : loss 22.349140167236328\n",
      "step 324 : loss 22.221574783325195\n",
      "step 325 : loss 22.134862899780273\n",
      "step 326 : loss 22.083126068115234\n",
      "step 327 : loss 22.04941177368164\n",
      "step 328 : loss 22.01056671142578\n",
      "step 329 : loss 21.97299575805664\n",
      "step 330 : loss 21.947486877441406\n",
      "step 331 : loss 21.94991111755371\n",
      "step 332 : loss 21.989032745361328\n",
      "step 333 : loss 22.059001922607422\n",
      "step 334 : loss 22.14754295349121\n",
      "step 335 : loss 22.179460525512695\n",
      "step 336 : loss 22.14018440246582\n",
      "step 337 : loss 22.02326202392578\n",
      "step 338 : loss 21.907176971435547\n",
      "step 339 : loss 21.827571868896484\n",
      "step 340 : loss 21.767959594726562\n",
      "step 341 : loss 21.718496322631836\n",
      "step 342 : loss 21.66583824157715\n",
      "step 343 : loss 21.6296443939209\n",
      "step 344 : loss 21.6231689453125\n",
      "step 345 : loss 21.655630111694336\n",
      "step 346 : loss 21.725154876708984\n",
      "step 347 : loss 21.801488876342773\n",
      "step 348 : loss 21.85087013244629\n",
      "step 349 : loss 21.807422637939453\n",
      "step 350 : loss 21.700397491455078\n",
      "step 351 : loss 21.58144760131836\n",
      "step 352 : loss 21.49664878845215\n",
      "step 353 : loss 21.450889587402344\n",
      "step 354 : loss 21.4173583984375\n",
      "step 355 : loss 21.3863582611084\n",
      "step 356 : loss 21.350603103637695\n",
      "step 357 : loss 21.327533721923828\n",
      "step 358 : loss 21.329137802124023\n",
      "step 359 : loss 21.365375518798828\n",
      "step 360 : loss 21.43335723876953\n",
      "step 361 : loss 21.498382568359375\n",
      "step 362 : loss 21.522979736328125\n",
      "step 363 : loss 21.456436157226562\n",
      "step 364 : loss 21.348159790039062\n",
      "step 365 : loss 21.24928855895996\n",
      "step 366 : loss 21.187969207763672\n",
      "step 367 : loss 21.16220474243164\n",
      "step 368 : loss 21.14109230041504\n",
      "step 369 : loss 21.115083694458008\n",
      "step 370 : loss 21.067026138305664\n",
      "step 371 : loss 21.014360427856445\n",
      "step 372 : loss 20.965551376342773\n",
      "step 373 : loss 20.931486129760742\n",
      "step 374 : loss 20.912614822387695\n",
      "step 375 : loss 20.905498504638672\n",
      "step 376 : loss 20.907756805419922\n",
      "step 377 : loss 20.918405532836914\n",
      "step 378 : loss 20.95104217529297\n",
      "step 379 : loss 21.017677307128906\n",
      "step 380 : loss 21.175012588500977\n",
      "step 381 : loss 21.389522552490234\n",
      "step 382 : loss 21.55649757385254\n",
      "step 383 : loss 21.410263061523438\n",
      "step 384 : loss 21.06266212463379\n",
      "step 385 : loss 20.803749084472656\n",
      "step 386 : loss 20.71290397644043\n",
      "step 387 : loss 20.755725860595703\n",
      "step 388 : loss 20.87467384338379\n",
      "step 389 : loss 20.99582290649414\n",
      "step 390 : loss 20.975696563720703\n",
      "step 391 : loss 20.808574676513672\n",
      "step 392 : loss 20.63296127319336\n",
      "step 393 : loss 20.53768539428711\n",
      "step 394 : loss 20.53486442565918\n",
      "step 395 : loss 20.59372329711914\n",
      "step 396 : loss 20.669414520263672\n",
      "step 397 : loss 20.686931610107422\n",
      "step 398 : loss 20.611522674560547\n",
      "step 399 : loss 20.489002227783203\n",
      "step 400 : loss 20.38580322265625\n",
      "step 401 : loss 20.328590393066406\n",
      "step 402 : loss 20.315418243408203\n",
      "step 403 : loss 20.33603858947754\n",
      "step 404 : loss 20.378936767578125\n",
      "step 405 : loss 20.42812156677246\n",
      "step 406 : loss 20.450162887573242\n",
      "step 407 : loss 20.43375015258789\n",
      "step 408 : loss 20.372102737426758\n",
      "step 409 : loss 20.308578491210938\n",
      "step 410 : loss 20.25475311279297\n",
      "step 411 : loss 20.233394622802734\n",
      "step 412 : loss 20.225038528442383\n",
      "step 413 : loss 20.233871459960938\n",
      "step 414 : loss 20.211421966552734\n",
      "step 415 : loss 20.16695785522461\n",
      "step 416 : loss 20.078710556030273\n",
      "step 417 : loss 19.994741439819336\n",
      "step 418 : loss 19.93225860595703\n",
      "step 419 : loss 19.90384292602539\n",
      "step 420 : loss 19.905139923095703\n",
      "step 421 : loss 19.9257755279541\n",
      "step 422 : loss 19.958805084228516\n",
      "step 423 : loss 19.990970611572266\n",
      "step 424 : loss 20.03280258178711\n",
      "step 425 : loss 20.091068267822266\n",
      "step 426 : loss 20.183448791503906\n",
      "step 427 : loss 20.29524040222168\n",
      "step 428 : loss 20.26806640625\n",
      "step 429 : loss 20.11646842956543\n",
      "step 430 : loss 19.83602523803711\n",
      "step 431 : loss 19.63551902770996\n",
      "step 432 : loss 19.55228614807129\n",
      "step 433 : loss 19.571359634399414\n",
      "step 434 : loss 19.650484085083008\n",
      "step 435 : loss 19.72191047668457\n",
      "step 436 : loss 19.766189575195312\n",
      "step 437 : loss 19.74240493774414\n",
      "step 438 : loss 19.704471588134766\n",
      "step 439 : loss 19.642475128173828\n",
      "step 440 : loss 19.54077911376953\n",
      "step 441 : loss 19.416654586791992\n",
      "step 442 : loss 19.303829193115234\n",
      "step 443 : loss 19.23403549194336\n",
      "step 444 : loss 19.208663940429688\n",
      "step 445 : loss 19.214462280273438\n",
      "step 446 : loss 19.2364444732666\n",
      "step 447 : loss 19.261615753173828\n",
      "step 448 : loss 19.29301643371582\n",
      "step 449 : loss 19.33592987060547\n",
      "step 450 : loss 19.38979148864746\n",
      "step 451 : loss 19.428401947021484\n",
      "step 452 : loss 19.371191024780273\n",
      "step 453 : loss 19.239200592041016\n",
      "step 454 : loss 19.053890228271484\n",
      "step 455 : loss 18.90697479248047\n",
      "step 456 : loss 18.812875747680664\n",
      "step 457 : loss 18.763774871826172\n",
      "step 458 : loss 18.740880966186523\n",
      "step 459 : loss 18.729061126708984\n",
      "step 460 : loss 18.72119140625\n",
      "step 461 : loss 18.70956802368164\n",
      "step 462 : loss 18.691421508789062\n",
      "step 463 : loss 18.664220809936523\n",
      "step 464 : loss 18.646419525146484\n",
      "step 465 : loss 18.6752872467041\n",
      "step 466 : loss 18.792985916137695\n",
      "step 467 : loss 18.960786819458008\n",
      "step 468 : loss 18.983806610107422\n",
      "step 469 : loss 18.77425765991211\n",
      "step 470 : loss 18.53986358642578\n",
      "step 471 : loss 18.39530372619629\n",
      "step 472 : loss 18.345552444458008\n",
      "step 473 : loss 18.282146453857422\n",
      "step 474 : loss 18.208797454833984\n",
      "step 475 : loss 18.1260986328125\n",
      "step 476 : loss 18.103473663330078\n",
      "step 477 : loss 18.1644344329834\n",
      "step 478 : loss 18.27401351928711\n",
      "step 479 : loss 18.325946807861328\n",
      "step 480 : loss 18.185321807861328\n",
      "step 481 : loss 17.967411041259766\n",
      "step 482 : loss 17.786666870117188\n",
      "step 483 : loss 17.72153663635254\n",
      "step 484 : loss 17.764137268066406\n",
      "step 485 : loss 17.886898040771484\n",
      "step 486 : loss 17.905054092407227\n",
      "step 487 : loss 17.855300903320312\n",
      "step 488 : loss 17.741008758544922\n",
      "step 489 : loss 17.71504783630371\n",
      "step 490 : loss 17.544010162353516\n",
      "step 491 : loss 17.29729652404785\n",
      "step 492 : loss 17.114459991455078\n",
      "step 493 : loss 17.115074157714844\n",
      "step 494 : loss 17.285818099975586\n",
      "step 495 : loss 17.427494049072266\n",
      "step 496 : loss 17.488767623901367\n",
      "step 497 : loss 17.274288177490234\n",
      "step 498 : loss 17.114585876464844\n",
      "step 499 : loss 16.922706604003906\n",
      "step 500 : loss 16.79110336303711\n",
      "step 501 : loss 16.759586334228516\n",
      "step 502 : loss 16.787952423095703\n",
      "step 503 : loss 16.755210876464844\n",
      "step 504 : loss 16.53169822692871\n",
      "step 505 : loss 16.318721771240234\n",
      "step 506 : loss 16.274585723876953\n",
      "step 507 : loss 16.521259307861328\n",
      "step 508 : loss 17.014202117919922\n",
      "step 509 : loss 17.45125389099121\n",
      "step 510 : loss 16.791425704956055\n",
      "step 511 : loss 16.11736488342285\n",
      "step 512 : loss 15.805623054504395\n",
      "step 513 : loss 15.828622817993164\n",
      "step 514 : loss 15.994325637817383\n",
      "step 515 : loss 16.088375091552734\n",
      "step 516 : loss 15.992599487304688\n",
      "step 517 : loss 15.946113586425781\n",
      "step 518 : loss 16.26392364501953\n",
      "step 519 : loss 16.222991943359375\n",
      "step 520 : loss 15.80560302734375\n",
      "step 521 : loss 15.193931579589844\n",
      "step 522 : loss 14.956329345703125\n",
      "step 523 : loss 15.030972480773926\n",
      "step 524 : loss 15.239811897277832\n",
      "step 525 : loss 15.424896240234375\n",
      "step 526 : loss 15.377128601074219\n",
      "step 527 : loss 15.429003715515137\n",
      "step 528 : loss 15.409566879272461\n",
      "step 529 : loss 15.341484069824219\n",
      "step 530 : loss 14.974119186401367\n",
      "step 531 : loss 14.62939167022705\n",
      "step 532 : loss 14.47618579864502\n",
      "step 533 : loss 14.500265121459961\n",
      "step 534 : loss 14.623438835144043\n",
      "step 535 : loss 14.742422103881836\n",
      "step 536 : loss 14.838831901550293\n",
      "step 537 : loss 14.903460502624512\n",
      "step 538 : loss 15.026771545410156\n",
      "step 539 : loss 14.872491836547852\n",
      "step 540 : loss 14.614921569824219\n",
      "step 541 : loss 14.315503120422363\n",
      "step 542 : loss 14.168713569641113\n",
      "step 543 : loss 14.163511276245117\n",
      "step 544 : loss 14.260526657104492\n",
      "step 545 : loss 14.401087760925293\n",
      "step 546 : loss 14.432805061340332\n",
      "step 547 : loss 14.4091796875\n",
      "step 548 : loss 14.308245658874512\n",
      "step 549 : loss 14.263079643249512\n",
      "step 550 : loss 14.2191743850708\n",
      "step 551 : loss 14.141067504882812\n",
      "step 552 : loss 14.035807609558105\n",
      "step 553 : loss 13.940533638000488\n",
      "step 554 : loss 13.88410758972168\n",
      "step 555 : loss 13.867884635925293\n",
      "step 556 : loss 13.885313034057617\n",
      "step 557 : loss 13.931100845336914\n",
      "step 558 : loss 13.999992370605469\n",
      "step 559 : loss 14.085844039916992\n",
      "step 560 : loss 14.184310913085938\n",
      "step 561 : loss 14.242919921875\n",
      "step 562 : loss 14.276843070983887\n",
      "step 563 : loss 14.166404724121094\n",
      "step 564 : loss 14.031100273132324\n",
      "step 565 : loss 13.854701042175293\n",
      "step 566 : loss 13.734048843383789\n",
      "step 567 : loss 13.659464836120605\n",
      "step 568 : loss 13.624180793762207\n",
      "step 569 : loss 13.61555004119873\n",
      "step 570 : loss 13.626848220825195\n",
      "step 571 : loss 13.659541130065918\n",
      "step 572 : loss 13.71226978302002\n",
      "step 573 : loss 13.799481391906738\n",
      "step 574 : loss 13.883230209350586\n",
      "step 575 : loss 13.974004745483398\n",
      "step 576 : loss 13.974247932434082\n",
      "step 577 : loss 13.939645767211914\n",
      "step 578 : loss 13.857501029968262\n",
      "step 579 : loss 13.768068313598633\n",
      "step 580 : loss 13.687826156616211\n",
      "step 581 : loss 13.603022575378418\n",
      "step 582 : loss 13.533857345581055\n",
      "step 583 : loss 13.470744132995605\n",
      "step 584 : loss 13.423673629760742\n",
      "step 585 : loss 13.387784004211426\n",
      "step 586 : loss 13.362113952636719\n",
      "step 587 : loss 13.342809677124023\n",
      "step 588 : loss 13.326995849609375\n",
      "step 589 : loss 13.312812805175781\n",
      "step 590 : loss 13.299577713012695\n",
      "step 591 : loss 13.287745475769043\n",
      "step 592 : loss 13.278663635253906\n",
      "step 593 : loss 13.275337219238281\n",
      "step 594 : loss 13.28327465057373\n",
      "step 595 : loss 13.314981460571289\n",
      "step 596 : loss 13.386088371276855\n",
      "step 597 : loss 13.516942977905273\n",
      "step 598 : loss 13.652944564819336\n",
      "step 599 : loss 13.717964172363281\n",
      "step 600 : loss 13.58265209197998\n",
      "step 601 : loss 13.396398544311523\n",
      "step 602 : loss 13.241887092590332\n",
      "step 603 : loss 13.176997184753418\n",
      "step 604 : loss 13.21142292022705\n",
      "step 605 : loss 13.40998649597168\n",
      "step 606 : loss 13.85154914855957\n",
      "step 607 : loss 14.218612670898438\n",
      "step 608 : loss 14.070222854614258\n",
      "step 609 : loss 13.598817825317383\n",
      "step 610 : loss 13.336633682250977\n",
      "step 611 : loss 13.26646900177002\n",
      "step 612 : loss 13.237016677856445\n",
      "step 613 : loss 13.207789421081543\n",
      "step 614 : loss 13.17186450958252\n",
      "step 615 : loss 13.217257499694824\n",
      "step 616 : loss 13.359174728393555\n",
      "step 617 : loss 13.530423164367676\n",
      "step 618 : loss 13.548787117004395\n",
      "step 619 : loss 13.3171968460083\n",
      "step 620 : loss 13.098653793334961\n",
      "step 621 : loss 12.982340812683105\n",
      "step 622 : loss 12.960797309875488\n",
      "step 623 : loss 12.988197326660156\n",
      "step 624 : loss 13.020177841186523\n",
      "step 625 : loss 13.033703804016113\n",
      "step 626 : loss 13.008100509643555\n",
      "step 627 : loss 12.983787536621094\n",
      "step 628 : loss 12.987167358398438\n",
      "step 629 : loss 13.052459716796875\n",
      "step 630 : loss 13.177988052368164\n",
      "step 631 : loss 13.287923812866211\n",
      "step 632 : loss 13.271588325500488\n",
      "step 633 : loss 13.123098373413086\n",
      "step 634 : loss 12.965907096862793\n",
      "step 635 : loss 12.870292663574219\n",
      "step 636 : loss 12.830263137817383\n",
      "step 637 : loss 12.82537841796875\n",
      "step 638 : loss 12.830967903137207\n",
      "step 639 : loss 12.842781066894531\n",
      "step 640 : loss 12.848358154296875\n",
      "step 641 : loss 12.857511520385742\n",
      "step 642 : loss 12.867874145507812\n",
      "step 643 : loss 12.892341613769531\n",
      "step 644 : loss 12.933046340942383\n",
      "step 645 : loss 12.99482250213623\n",
      "step 646 : loss 13.059137344360352\n",
      "step 647 : loss 13.087498664855957\n",
      "step 648 : loss 13.041574478149414\n",
      "step 649 : loss 12.948968887329102\n",
      "step 650 : loss 12.840174674987793\n",
      "step 651 : loss 12.75629997253418\n",
      "step 652 : loss 12.69399356842041\n",
      "step 653 : loss 12.653740882873535\n",
      "step 654 : loss 12.626540184020996\n",
      "step 655 : loss 12.609430313110352\n",
      "step 656 : loss 12.600214004516602\n",
      "step 657 : loss 12.597047805786133\n",
      "step 658 : loss 12.601936340332031\n",
      "step 659 : loss 12.614866256713867\n",
      "step 660 : loss 12.643611907958984\n",
      "step 661 : loss 12.68795394897461\n",
      "step 662 : loss 12.753173828125\n",
      "step 663 : loss 12.824350357055664\n",
      "step 664 : loss 12.876167297363281\n",
      "step 665 : loss 12.900815963745117\n",
      "step 666 : loss 12.88048267364502\n",
      "step 667 : loss 12.864587783813477\n",
      "step 668 : loss 12.829229354858398\n",
      "step 669 : loss 12.80394458770752\n",
      "step 670 : loss 12.748666763305664\n",
      "step 671 : loss 12.679646492004395\n",
      "step 672 : loss 12.598997116088867\n",
      "step 673 : loss 12.521649360656738\n",
      "step 674 : loss 12.461341857910156\n",
      "step 675 : loss 12.419853210449219\n",
      "step 676 : loss 12.39631175994873\n",
      "step 677 : loss 12.388444900512695\n",
      "step 678 : loss 12.394552230834961\n",
      "step 679 : loss 12.419293403625488\n",
      "step 680 : loss 12.469313621520996\n",
      "step 681 : loss 12.564193725585938\n",
      "step 682 : loss 12.68435001373291\n",
      "step 683 : loss 12.800771713256836\n",
      "step 684 : loss 12.79582691192627\n",
      "step 685 : loss 12.700826644897461\n",
      "step 686 : loss 12.571623802185059\n",
      "step 687 : loss 12.471145629882812\n",
      "step 688 : loss 12.408183097839355\n",
      "step 689 : loss 12.368867874145508\n",
      "step 690 : loss 12.348180770874023\n",
      "step 691 : loss 12.343652725219727\n",
      "step 692 : loss 12.361427307128906\n",
      "step 693 : loss 12.410451889038086\n",
      "step 694 : loss 12.479330062866211\n",
      "step 695 : loss 12.55443000793457\n",
      "step 696 : loss 12.549487113952637\n",
      "step 697 : loss 12.49632740020752\n",
      "step 698 : loss 12.395251274108887\n",
      "step 699 : loss 12.322386741638184\n",
      "step 700 : loss 12.281205177307129\n",
      "step 701 : loss 12.28004264831543\n",
      "step 702 : loss 12.320634841918945\n",
      "step 703 : loss 12.410821914672852\n",
      "step 704 : loss 12.524556159973145\n",
      "step 705 : loss 12.592494010925293\n",
      "step 706 : loss 12.536904335021973\n",
      "step 707 : loss 12.418387413024902\n",
      "step 708 : loss 12.298690795898438\n",
      "step 709 : loss 12.229302406311035\n",
      "step 710 : loss 12.191243171691895\n",
      "step 711 : loss 12.179023742675781\n",
      "step 712 : loss 12.177844047546387\n",
      "step 713 : loss 12.191499710083008\n",
      "step 714 : loss 12.210162162780762\n",
      "step 715 : loss 12.247770309448242\n",
      "step 716 : loss 12.283748626708984\n",
      "step 717 : loss 12.33502197265625\n",
      "step 718 : loss 12.36181640625\n",
      "step 719 : loss 12.378206253051758\n",
      "step 720 : loss 12.356680870056152\n",
      "step 721 : loss 12.316797256469727\n",
      "step 722 : loss 12.266039848327637\n",
      "step 723 : loss 12.221171379089355\n",
      "step 724 : loss 12.19556999206543\n",
      "step 725 : loss 12.195775032043457\n",
      "step 726 : loss 12.221261024475098\n",
      "step 727 : loss 12.268555641174316\n",
      "step 728 : loss 12.292281150817871\n",
      "step 729 : loss 12.290456771850586\n",
      "step 730 : loss 12.219012260437012\n",
      "step 731 : loss 12.139744758605957\n",
      "step 732 : loss 12.057413101196289\n",
      "step 733 : loss 12.002711296081543\n",
      "step 734 : loss 11.971088409423828\n",
      "step 735 : loss 11.96240234375\n",
      "step 736 : loss 11.97494125366211\n",
      "step 737 : loss 12.014364242553711\n",
      "step 738 : loss 12.08574390411377\n",
      "step 739 : loss 12.193272590637207\n",
      "step 740 : loss 12.289079666137695\n",
      "step 741 : loss 12.331116676330566\n",
      "step 742 : loss 12.256916999816895\n",
      "step 743 : loss 12.15717887878418\n",
      "step 744 : loss 12.065786361694336\n",
      "step 745 : loss 12.027273178100586\n",
      "step 746 : loss 12.027355194091797\n",
      "step 747 : loss 12.062204360961914\n",
      "step 748 : loss 12.097786903381348\n",
      "step 749 : loss 12.118106842041016\n",
      "step 750 : loss 12.083142280578613\n",
      "step 751 : loss 12.020414352416992\n",
      "step 752 : loss 11.949870109558105\n",
      "step 753 : loss 11.898992538452148\n",
      "step 754 : loss 11.872106552124023\n",
      "step 755 : loss 11.870051383972168\n",
      "step 756 : loss 11.893470764160156\n",
      "step 757 : loss 11.949586868286133\n",
      "step 758 : loss 12.038823127746582\n",
      "step 759 : loss 12.148397445678711\n",
      "step 760 : loss 12.201324462890625\n",
      "step 761 : loss 12.177848815917969\n",
      "step 762 : loss 12.062865257263184\n",
      "step 763 : loss 11.960768699645996\n",
      "step 764 : loss 11.88648509979248\n",
      "step 765 : loss 11.856197357177734\n",
      "step 766 : loss 11.85168743133545\n",
      "step 767 : loss 11.872238159179688\n",
      "step 768 : loss 11.900545120239258\n",
      "step 769 : loss 11.940035820007324\n",
      "step 770 : loss 11.953920364379883\n",
      "step 771 : loss 11.955053329467773\n",
      "step 772 : loss 11.91653060913086\n",
      "step 773 : loss 11.880033493041992\n",
      "step 774 : loss 11.847428321838379\n",
      "step 775 : loss 11.843975067138672\n",
      "step 776 : loss 11.865501403808594\n",
      "step 777 : loss 11.90869140625\n",
      "step 778 : loss 11.952028274536133\n",
      "step 779 : loss 11.971013069152832\n",
      "step 780 : loss 11.952463150024414\n",
      "step 781 : loss 11.90978717803955\n",
      "step 782 : loss 11.863001823425293\n",
      "step 783 : loss 11.840121269226074\n",
      "step 784 : loss 11.834067344665527\n",
      "step 785 : loss 11.856548309326172\n",
      "step 786 : loss 11.86170482635498\n",
      "step 787 : loss 11.862876892089844\n",
      "step 788 : loss 11.817529678344727\n",
      "step 789 : loss 11.773855209350586\n",
      "step 790 : loss 11.72397518157959\n",
      "step 791 : loss 11.694158554077148\n",
      "step 792 : loss 11.675241470336914\n",
      "step 793 : loss 11.673847198486328\n",
      "step 794 : loss 11.683954238891602\n",
      "step 795 : loss 11.712858200073242\n",
      "step 796 : loss 11.751895904541016\n",
      "step 797 : loss 11.8023099899292\n",
      "step 798 : loss 11.831380844116211\n",
      "step 799 : loss 11.836576461791992\n",
      "step 800 : loss 11.799250602722168\n",
      "step 801 : loss 11.753087997436523\n",
      "step 802 : loss 11.709753036499023\n",
      "step 803 : loss 11.693314552307129\n",
      "step 804 : loss 11.708131790161133\n",
      "step 805 : loss 11.76652717590332\n",
      "step 806 : loss 11.844706535339355\n",
      "step 807 : loss 11.908550262451172\n",
      "step 808 : loss 11.88011360168457\n",
      "step 809 : loss 11.80205249786377\n",
      "step 810 : loss 11.70341682434082\n",
      "step 811 : loss 11.641134262084961\n",
      "step 812 : loss 11.60517406463623\n",
      "step 813 : loss 11.597105979919434\n",
      "step 814 : loss 11.603638648986816\n",
      "step 815 : loss 11.627815246582031\n",
      "step 816 : loss 11.651817321777344\n",
      "step 817 : loss 11.677528381347656\n",
      "step 818 : loss 11.672144889831543\n",
      "step 819 : loss 11.657965660095215\n",
      "step 820 : loss 11.624659538269043\n",
      "step 821 : loss 11.610849380493164\n",
      "step 822 : loss 11.61320686340332\n",
      "step 823 : loss 11.651249885559082\n",
      "step 824 : loss 11.706048011779785\n",
      "step 825 : loss 11.763466835021973\n",
      "step 826 : loss 11.772518157958984\n",
      "step 827 : loss 11.726850509643555\n",
      "step 828 : loss 11.645576477050781\n",
      "step 829 : loss 11.572065353393555\n",
      "step 830 : loss 11.521145820617676\n",
      "step 831 : loss 11.497089385986328\n",
      "step 832 : loss 11.494197845458984\n",
      "step 833 : loss 11.515554428100586\n",
      "step 834 : loss 11.556039810180664\n",
      "step 835 : loss 11.62110424041748\n",
      "step 836 : loss 11.669201850891113\n",
      "step 837 : loss 11.695425987243652\n",
      "step 838 : loss 11.64643669128418\n",
      "step 839 : loss 11.580617904663086\n",
      "step 840 : loss 11.504859924316406\n",
      "step 841 : loss 11.45320987701416\n",
      "step 842 : loss 11.419702529907227\n",
      "step 843 : loss 11.403603553771973\n",
      "step 844 : loss 11.400620460510254\n",
      "step 845 : loss 11.410387992858887\n",
      "step 846 : loss 11.436196327209473\n",
      "step 847 : loss 11.473264694213867\n",
      "step 848 : loss 11.518173217773438\n",
      "step 849 : loss 11.534721374511719\n",
      "step 850 : loss 11.525650024414062\n",
      "step 851 : loss 11.481365203857422\n",
      "step 852 : loss 11.442148208618164\n",
      "step 853 : loss 11.419622421264648\n",
      "step 854 : loss 11.430893898010254\n",
      "step 855 : loss 11.494218826293945\n",
      "step 856 : loss 11.61903190612793\n",
      "step 857 : loss 11.789965629577637\n",
      "step 858 : loss 11.833440780639648\n",
      "step 859 : loss 11.746749877929688\n",
      "step 860 : loss 11.554361343383789\n",
      "step 861 : loss 11.424528121948242\n",
      "step 862 : loss 11.352645874023438\n",
      "step 863 : loss 11.32154655456543\n",
      "step 864 : loss 11.311861038208008\n",
      "step 865 : loss 11.315417289733887\n",
      "step 866 : loss 11.332468032836914\n",
      "step 867 : loss 11.363576889038086\n",
      "step 868 : loss 11.415754318237305\n",
      "step 869 : loss 11.470852851867676\n",
      "step 870 : loss 11.520622253417969\n",
      "step 871 : loss 11.50815486907959\n",
      "step 872 : loss 11.459972381591797\n",
      "step 873 : loss 11.381656646728516\n",
      "step 874 : loss 11.332347869873047\n",
      "step 875 : loss 11.327157020568848\n",
      "step 876 : loss 11.388404846191406\n",
      "step 877 : loss 11.503946304321289\n",
      "step 878 : loss 11.631036758422852\n",
      "step 879 : loss 11.648117065429688\n",
      "step 880 : loss 11.56092357635498\n",
      "step 881 : loss 11.422394752502441\n",
      "step 882 : loss 11.335963249206543\n",
      "step 883 : loss 11.296415328979492\n",
      "step 884 : loss 11.300724029541016\n",
      "step 885 : loss 11.321730613708496\n",
      "step 886 : loss 11.351243019104004\n",
      "step 887 : loss 11.354622840881348\n",
      "step 888 : loss 11.34309196472168\n",
      "step 889 : loss 11.305720329284668\n",
      "step 890 : loss 11.279253005981445\n",
      "step 891 : loss 11.262163162231445\n",
      "step 892 : loss 11.273625373840332\n",
      "step 893 : loss 11.299524307250977\n",
      "step 894 : loss 11.34339714050293\n",
      "step 895 : loss 11.37738037109375\n",
      "step 896 : loss 11.394927024841309\n",
      "step 897 : loss 11.377111434936523\n",
      "step 898 : loss 11.35203742980957\n",
      "step 899 : loss 11.32634162902832\n",
      "step 900 : loss 11.332334518432617\n",
      "step 901 : loss 11.358134269714355\n",
      "step 902 : loss 11.407377243041992\n",
      "step 903 : loss 11.420117378234863\n",
      "step 904 : loss 11.402547836303711\n",
      "step 905 : loss 11.332367897033691\n",
      "step 906 : loss 11.264592170715332\n",
      "step 907 : loss 11.209602355957031\n",
      "step 908 : loss 11.178491592407227\n",
      "step 909 : loss 11.1671781539917\n",
      "step 910 : loss 11.171911239624023\n",
      "step 911 : loss 11.19238567352295\n",
      "step 912 : loss 11.219198226928711\n",
      "step 913 : loss 11.24846363067627\n",
      "step 914 : loss 11.258458137512207\n",
      "step 915 : loss 11.252508163452148\n",
      "step 916 : loss 11.230359077453613\n",
      "step 917 : loss 11.212760925292969\n",
      "step 918 : loss 11.212743759155273\n",
      "step 919 : loss 11.235562324523926\n",
      "step 920 : loss 11.290937423706055\n",
      "step 921 : loss 11.338826179504395\n",
      "step 922 : loss 11.371333122253418\n",
      "step 923 : loss 11.32210922241211\n",
      "step 924 : loss 11.255746841430664\n",
      "step 925 : loss 11.176956176757812\n",
      "step 926 : loss 11.127900123596191\n",
      "step 927 : loss 11.096993446350098\n",
      "step 928 : loss 11.086141586303711\n",
      "step 929 : loss 11.087181091308594\n",
      "step 930 : loss 11.105859756469727\n",
      "step 931 : loss 11.137765884399414\n",
      "step 932 : loss 11.191061019897461\n",
      "step 933 : loss 11.235968589782715\n",
      "step 934 : loss 11.271027565002441\n",
      "step 935 : loss 11.248873710632324\n",
      "step 936 : loss 11.211674690246582\n",
      "step 937 : loss 11.158145904541016\n",
      "step 938 : loss 11.124441146850586\n",
      "step 939 : loss 11.106404304504395\n",
      "step 940 : loss 11.110770225524902\n",
      "step 941 : loss 11.132043838500977\n",
      "step 942 : loss 11.166509628295898\n",
      "step 943 : loss 11.197893142700195\n",
      "step 944 : loss 11.200784683227539\n",
      "step 945 : loss 11.172800064086914\n",
      "step 946 : loss 11.120633125305176\n",
      "step 947 : loss 11.076499938964844\n",
      "step 948 : loss 11.048410415649414\n",
      "step 949 : loss 11.04679012298584\n",
      "step 950 : loss 11.070314407348633\n",
      "step 951 : loss 11.120790481567383\n",
      "step 952 : loss 11.188194274902344\n",
      "step 953 : loss 11.234437942504883\n",
      "step 954 : loss 11.240827560424805\n",
      "step 955 : loss 11.179622650146484\n",
      "step 956 : loss 11.106019973754883\n",
      "step 957 : loss 11.036429405212402\n",
      "step 958 : loss 10.996930122375488\n",
      "step 959 : loss 10.986132621765137\n",
      "step 960 : loss 11.005592346191406\n",
      "step 961 : loss 11.040605545043945\n",
      "step 962 : loss 11.076227188110352\n",
      "step 963 : loss 11.067937850952148\n",
      "step 964 : loss 11.033879280090332\n",
      "step 965 : loss 10.982584953308105\n",
      "step 966 : loss 10.94491195678711\n",
      "step 967 : loss 10.923673629760742\n",
      "step 968 : loss 10.91997241973877\n",
      "step 969 : loss 10.940486907958984\n",
      "step 970 : loss 10.998067855834961\n",
      "step 971 : loss 11.118322372436523\n",
      "step 972 : loss 11.256309509277344\n",
      "step 973 : loss 11.346105575561523\n",
      "step 974 : loss 11.247031211853027\n",
      "step 975 : loss 11.115911483764648\n",
      "step 976 : loss 11.006444931030273\n",
      "step 977 : loss 10.963875770568848\n",
      "step 978 : loss 10.9633150100708\n",
      "step 979 : loss 10.991144180297852\n",
      "step 980 : loss 11.03308391571045\n",
      "step 981 : loss 11.066827774047852\n",
      "step 982 : loss 11.073762893676758\n",
      "step 983 : loss 11.045953750610352\n",
      "step 984 : loss 11.00248908996582\n",
      "step 985 : loss 10.969758987426758\n",
      "step 986 : loss 10.959972381591797\n",
      "step 987 : loss 10.988191604614258\n",
      "step 988 : loss 11.03454875946045\n",
      "step 989 : loss 11.091952323913574\n",
      "step 990 : loss 11.090112686157227\n",
      "step 991 : loss 11.053739547729492\n",
      "step 992 : loss 10.974782943725586\n",
      "step 993 : loss 10.913832664489746\n",
      "step 994 : loss 10.87048625946045\n",
      "step 995 : loss 10.851834297180176\n",
      "step 996 : loss 10.849074363708496\n",
      "step 997 : loss 10.865670204162598\n",
      "step 998 : loss 10.898048400878906\n",
      "step 999 : loss 10.951601028442383\n"
     ]
    }
   ],
   "source": [
    "autoencoder = AutoEncoder()\n",
    "autoencoder.train()\n",
    "lr = 1e-4\n",
    "num_steps = 1000\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters() , lr=lr)\n",
    "for step in range(num_steps):\n",
    "    loss_iter = 0\n",
    "    for image in dataset_train:\n",
    "        y = autoencoder(image)\n",
    "        loss = (y-image).norm()\n",
    "        loss_iter += loss\n",
    "    loss = loss_iter/num_images_train\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"step {step} : loss {loss.item()}\")\n",
    "\n",
    "# result = autoencoder(new_init_tensor)\n",
    "# tensor_to_image(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD2eiiiviCwoopCQoJJAA5JNAtgZlRSzMFA7k4qjLqsSnEas/v0FULy8a6fuIx91f6mq1fV4LIoKKlidX27HyWOz+o5uGG0Xfuaq6upYboSB6hs1dguYrgZjcE91PUVztOR2jcOhIYdCK3xGQ4ecf3Xuv71+Jhhs/xMJfvveXpZ/Kx0tFV7O6F1DuwA44YVYr5GrSnSm6c1Zo+wo1YVoKpB3TCiiiszUKKKKACiiigAooooAKp6lIY7MgZ+chcg/wCfSrlUtUQtZ5GPlYE/y/rXZl6i8VTUtro4sxclhKjjvZmLRRRX6EfnIUUUUAXdMkKXYTnDgjr+NbVYmmIWvVIx8oJP8v61t18Zn6isWrdlf8f0sfbcPOTwjv3dvw/W4UUUV4h7oUUUUAFFFFABRRRQAUjKHQqwyCMEUtFCbTuhNJqzOeubZ7aTa3IP3W9ahrpJYkmTZIoZetZ0uknOYpB9H/xr7DBZ5SnFRxDtLv0f+R8bjshq05uWHXNHt1X+f5mZSgFiAASTwAKvrpMpYbpEA9Rk1etrGK2IYAs/94/0rfEZ1haUfcfM/L/Mww2R4qrL31yru/8AISwtTbQnfje3Jx29qtUUV8bXrTr1HUnuz7ShQhQpqlDZBRRRWRsFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAADHUlEQVR4Ae2bQWoUURgGjXpGL+LOO3gRz+YJBMGWIUOIUJCerveb7spCox959VLVk7iITz9/ffvQ25yBj3PoyH8NFGD4OSjAcIDPw/xn/JffX5/fff37j0/fX//Vif78NPtNGLz/K/mUJcYCvEn9yxgnyzAQYLf6U2ZY/U34EPtbiaPOeRl15P2lAY61duxpI/Y36LoAhi/jzMUlFgXwTHknrymxIoDtyD5fLaEHWGNnDcUooQcwLn2mM90AKx/MlawDnwA3wIEXPetRYoD1j+R64uOPhRjg8ctd4YQCDFe2Akx9NZji7s5oBdh9oat9YAGGixegAMMGhvG9AgowbGAY3yugAMMGhvHWK2Dqh0emuLszWgF2X+hqH1iA4eJigPVfDdYTH68nBnj8clc4wQ2w8pFcyTrwyXADHHjRsx6lB1jzYK6hGA+BHmC7tG3HPt/wfj9zRQC1wbu2v5lZFEBq8N7tLw1weIMT2F8d4MAG57C/CRn4L0obdXvb/eMLp1F/8zAW4IZ/U4aTqf8vAtwusf0KJU7p/f6JD78C7ve47Dvr/hl6WcX8iReA/ehrAXTFDCgA+9HXAuiKGVAA9qOvBdAVM6AA7EdfC6ArZkAB2I++FkBXzIACsB99LYCumAEFYD/6WgBdMQMKwH70tQC6YgYUgP3oawF0xQwoAPvR1wLoihlQAPajrwXQFTOgAOxHXwugK2ZAAdiPvhZAV8yAArAffS2ArpgBBWA/+loAXTEDCsB+9LUAumIGFID96GsBdMUMKAD70dcC6IoZUAD2o68F0BUzoADsR18LoCtmQAHYj74WQFfMgAKwH30tgK6YAQVgP/paAF0xAwrAfvS1ALpiBhSA/ehrAXTFDCgA+9HXAuiKGVAA9qOvBdAVM6AA7EdfC6ArZkAB2I++FkBXzIACsB99LYCumAEFYD/6WgBdMQMKwH70tQC6YgYUgP3oawF0xQwoAPvR1wLoihlQAPajrwXQFTOgAOxHXwugK2ZAAdiPvhZAV8yAArAffS2ArpgBBWA/+loAXTEDCsB+9LUAumIGFID96OsfAYBe+5rE4JsAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDd8Vw3YhuLTTJPJuYtvkttDbc7S3DcHIz1rF1e+8X6DfRXuoSfZ558+W+2J87QAeBkdCK7zTfC5Cxy3h9d0P54+YH6GuN8fa9qp1rUNG+0/wDEv/d/uti/3VbrjP3uetePl04zmsPCMZJJttrpotH+NtvM34Pw1bEV6rxlCD55c65/ekktEle6XLdcqsnunbQ4Oz0nT7OZJreHZIucNvY47dz71dmc460AYIpLezutSvo7Kzi824kztTcFzgZPJ46A19fS5pPmm/mz9CqQp4anL2aUI7u1kvXoWNA8UXfhq+M0Q823l/10HC+ZgEL82CRgtnivWtM8RaZrvnf2bd+f5O3zP3bLjOcfeA9DWV4d8Njwp9r/ANN+1fadn/LLZt259zn736VfmvgDjFceKhRxU+anDX+bv6q3Tbc/KeIMyoYmtJ0k7q3vJtX23TXTbdfdY0GYnvUsGfWufN/z0/z+VXrS8DDpXFXy+ShsfPUa1Tm3/r7zya/8Q6proi/tK68/yM+X+7VcbsZ+6B6CqwBwea7fxX4Q1PUtbk1LTY/tX2nHmR7lTytqqo5Zvmzg9uMVw8bgg8V60XSqU70Ul5Lp+He/ruftWS42niMPF0Gl3S6X6W9b9NdyK5t47q3eCZd8bYyMkZ5z2rZ0jXpdNnhE8f2mzj3Zt9wTdkH+IDI5OfwrOJHPFIQPSuWrSVSPJNaHrYnL8LjocmKpxmn/ADJPa9t+qu7PdXdtz3XSNQi8TeHobue28uK43Zh3k42uR1AH93NTLpenxxSwJb/u5cbxvbnHI71znw1mE2hyQf2h5/k4/wBF8nb9nyzn7/8AHu6+3Suz2AN0r4LF03h606cLpJ+fy3PznM8voQxk1KCdm0rrXlfTXW1nbs/NO5mTaZDLprWEQ8qI42nJbHOfWuetNLu/7avLYeIPtFnabN+nfYwnlb1yP3mcnJ+b26V2m3HaszUtIsNTkt5LyDzJLfd5R3sNu7Geh56DrU0MS4JxfXyT/P8ANNPr5Pno0KFKr7aMffUeWPa26VtVbzSut1e1nb022+w2Edrv37M/NjGcknp+NeQ+PBnxpqH/AGz/APRa167pt4L+yiufL2b8/LuzjBI/pXkfjwf8Vnf8f88//Ra16+Rc31uXNvZ/mj3eFfZqovY/Byaenu23127nPsoGK7f4ZkD+2P8Ath/7PXDOBxxXa+AddyJNGurn0+xQ7P8AeZ/mA+h5P0r67Ewk8LJJX2+6/wDXy1PU4mU5ZfUUFfa/one/9W0u+h09+44/z6VhXMgzWzfxHjj/ADxWFcQH0rbAKHKj8br3uyq0vPWtPTpBx/n1rIMBzWpp0J4/z612YpQ9mZ0ebmR1tg4wf8+teVeOSD421H/tl/6LWvUrCPr/AJ9a89+I2qfbNbTTfI2fYM/vN+d+9UbpjjH1NfO4HTGS5VfR38tv10+Z99whKaxlkr3Tv5LTXz1svnc5IYpcDFNCj0pwUY6V6U9z9Vhsd/4E8X2ml2NxZavf+Vbx7fsqeSWxksX5VSepHX8Kn1f4liXRYf7Nj8jUJt3mfNu+z4YY+8uH3Ln6VzGiePb7w9PZWLSedZjzNlptVd/BJ+faSME5/St7xp4mutU8LaTLEn2a31HzvOgyHz5bqF+bAPUZ4x1r52vgI/W1OdK6k9+bTRPpy9bXe6vpfc+drYGlLHqUqSalLfm0TSbs48t7te807pu2tm79HoHiS5uLDw9Der9ouNT+0758hNvlkkfKBg5GB2/GuklGCTis3wpf3WqeFLO9vJPNuJN+99oXOHYDgADoBWlIODmvmsXyqtKMY2s2nbbd+np8j5bHcqxEoxio2bTttfme22iVlt0uU/Dn/IFtv+B/+hGvL/Hg/wCKzv8A/tn/AOi1r1Dw5/yBLb/gf/oRry/x3/yOeof9s/8A0Wtexkz/ANtn6P8ANG/Bi9yn/wBel/7ac+y5xT9L1L+w9bt9S8jz/J3fu9+3OVK9cH19KD2qvPHkV9pSkmnGWz0PtMTQhVhKnNXTVn8z2u9t84rImtM03QfG1r4ivjZS232O4b/UpvMnmcEtztAGAO/XNdDJaV4ccRVwzVOqrM/GsZl1XD1HTrRszlDac1fsrXGP8+taZs6sW9tg9a0rZjeNrnNTw6UloT2cO3NeD3clrPeyy2Vn9kt2xsg80ybOMH5jycnJ/Gup8TeKdM1fXLT/AEL7dp9nv/5atF5+9R7ArtYfjiuSVcV04CjOipTqXvJLTtv577brS9u5+n8NZVPCU3UqJpyS07avz32eqVr27jgKKWkreTufYR2OTuUlk8YskM3kyHGH2hsfu/Q16Zrf/Ik+Fv8At7/9GCuGu7eKPxHYTouJJfM3nJ5wmBXda3/yJPhb/t7/APRgqcfPmlh7f17skeBgqDo4ifNu60nu7WdNyWnfXX9bI9H8Cf8AIi6f/wBtP/RrVty/xVyPgTxBpf8AYOn6N9q/4mH7z9z5bf3mbrjH3eetddL0b8K/P8fCUMVPmVrtv5XPlMzpzhjKnOmrybV+qu9fQo+Hf+QJbf8AA/8A0I15f47/AORzv/8Atn/6LWvUPD3/ACBLb/gf/oRry3x2f+Kz1D/tn/6LWvVyf/fZ+j/NHRwWvcp/9e1/7aYvcU11yKTPIpSRivq02j71wuVZY81veFPEw8LfbP8AQftX2nZ/y12bdu72OfvfpWM2KaQK1qONWm6dTVM5sRgqWJpulVV4v/h+h3h+KX/UD/8AJv8A+wp8fxTx/wAwP/yb/wDsK89IFAGK5Hl+Ea+D8X/mecuG8tT/AIf4y/zHRxgU/GKAaQmumU22e7GCQGm0E0mak0SKN2kTapYO82yRfM2JtJ35Xnntiux1v/kSfC3/AG9/+jBXE33/ACG9K/7bf+giu21v/kSfC3/b3/6MFZYveh6v8pnk3TxNkrWqff8Auf6Wltu5H4E/5HXT/wDtp/6LavZpejfhXjPgT/kddP8A+2n/AKLavZpejfhXymf/AO9R/wAK/NnzvE/++Q/wr85FHw9/yBLb/gf/AKEa8r8ef8jnqH/bP/0WtegeEet3/wAA/wDZq8/8ef8AI56h/wBs/wD0WtdGUx5cdNeX5tM83gKt7alCVre5b/wGSj+NrmCTyKM8U09qK+osfo6EY0maDTaZaQppKKSi5Vh+aQmkopDsGaKSlFAjMvv+Q5pX/bb/ANBFdvrf/Ik+Fv8At7/9GCuIvf8AkOaV/wBtv/QRXb63/wAiT4W/7e//AEYKzxe9D1f5TPGX+9P/AK+/+4UR+BP+R10//tp/6LavZpejfhXjPgT/AJHXT/8Atp/6LavZpejfhXyef/71H/CvzZ89xP8A75D/AAr85HPeEet3/wAA/wDZq8+8ef8AI56h/wBs/wD0WtegeG7y1t7K4kkTyvL2+ZLktuyTjjtjpxXn/jz/AJHPUP8Atn/6LWurLL/X5Nr7P+R4/h24qjGCkm+Rv75/8Ou107XOfPUUdqUjkUYr6a+h+nIYabTyKqS39rD5/mS7fs+3zflJ27unbn8KaTlsE6sKavUkkvPTpf8AJN+iLGKMGs3/AISDS/8An6/8ht/hR/wkGl/8/X/kNv8ACr9jV/lf3HN/amB/5/Q/8CX+Zpc0c1m/8JBpf/P1/wCQ2/wo/wCEg0v/AJ+v/Ibf4Uexqfyv7mH9qYH/AJ/Q/wDAl/maXNFZv/CQaX/z9f8AkNv8K0LaeK7gWaB90bZwcEZwcd6UoTiryTRrSxmGry5aVSMn5NP8jPvf+Q5pX/bX/wBBFdZqmoWtx4X0Cyil3XFr9o85NpG3c4K84wcj0ri57vzvFVrbbMeRv+bP3tyZ6dq2T96liKSapuXRX+/mX5M4sJ7PEVqtSL+Gp+KhGL/X/hjofAn/ACOun/8AbT/0W1ezS9G/CvGvAn/I66f/ANtP/RbV7NL0b8K+Nz//AHqP+Ffmz5nif/fIf4V+cjmtGYapokum/wCq8vH7z72csW6cenrXAePX/wCK01Dj/nn/AOi1rv8AQb+wjt7qdLb7JGmzed7SZySB2/zmtCXw1av4ntNeibyriPf5wwW87KbF74XA9BzTw2JjhMRKc07WdvXR+e9vO1z57hDG0cHTVaclOXJy3V9UpPlVmk0tGr8u/e1zxAvyOKUscdKlv7C60u/eyvYvKuIsb03BsZAI5GR0IqktxFJPLCjZkixvGDxkZFfXJxlHmjqj9WU4OzTXvbefXTvpr6ExY+lJk001QuNZsLWdoZp9ki4yNjHGRnsKpRctIq46talQjzVZKK83b8zRyaMmsn/hIdL/AOfr/wAht/hR/wAJDpf/AD9f+Q2/wqvY1P5X9xz/ANp4H/n9H/wJf5mtk0ZNZP8AwkOl/wDP1/5Db/Cj/hIdL/5+v/Ibf4Uexqfyv7g/tPA/8/o/+BL/ADNbJoyayv8AhIdL/wCfr/yG3+FH/CQ6X/z9f+Q2/wAKPY1P5X9wf2lgv+f0f/Al/mXPsFr9t+2+V/pH9/cfTHTOOlX54rZLO1liu/NuJN/nQeWV8nBwvzdGyOeOladp4Q12/wB/2ax37Mbv3yDGenVvauk1Pwhrtx4W0Gzisd1xafaPOTzkG3c4K87sHI9K8+tj6MZRi5re260Vm/u+79HyQzHL/dlhqsHGcm24yjZ6O7bW+qSvo7216PB8B5PjXT/+2n/otq9nl6N+FcvoPhu5t9P8Py3rfZ7jTPtO+DAfd5hOPmBwMDB7/hXTnBVj9K+UzfEwxFdTh00+6T/NWfzPk87xVPFYlSg9tPulL81Z/M5zSdWv7qBVSy+0yJ99/NVM5Jxxj/OK27LVIrqSe1K7Ly12/aIck+Xu5X5sYORzxXFpbarbrqCi1xpS+XsuvMX/AEj1+T7y7W49+tdZpsmolJf7SXJ48vlffP3fwqMRTgoc6trtZ+nr320tp6HxOV4vFKqsNi1NyS/u8q1dm2ld6KyfM7yb7a8vf/DG1uL95bK++x27Y2QeUZNvAB+Yvk5OT+NZ0/w5tre9tbOXX9txd7/JT7GTu2jLc7sDA9a7f/hItKwD5/8A443+FV5tesnvLWWLU/Kt49/nQeQzedkfL82Mrg88da6KWPx6Vm3a3by0+y/+D3W59TT4qmtHio2S7x7aa2bev39Wtzmf+FUn/oNf+Sv/ANnSf8Kp/wCo1/5K/wD2ddgfEukf89//ABx/8KT/AISXSP8Anv8A+OP/AIUv7RzHz/8AAV/kT/rdW/6CY/8AkhyH/CqT/wBBr/yV/wDs6P8AhVJ/6DX/AJK//Z11/wDwkmkf89//ABx/8KP+Ek0j/nv/AOOP/hS/tHMfP/wFf5B/rfW/6CY/+SHIf8KpP/Qa/wDJX/7Oj/hVJ/6DX/kr/wDZ11//AAkmkf8APf8A8cf/AAo/4STSP+e//jj/AOFH9o5j5/8AgK/yD/W+t/0Ex/8AJDkP+FUn/oNf+Sv/ANnR/wAKp/6jX/kr/wDZ11//AAkmkf8APf8A8cf/AAo/4SXSP+fj/wAcf/Cn/aOY+f8A4Cv8h/63Vv8AoJj/AOSGGPhrpZ0P7Jv/AOJh/wA/2G/vZ/1e7H3fl/WrE2h67o3he1stB1HdcWm/KeQg8/c+erkhdoLfWrl9r9lcWUkNnqf2O4bGyfyGk2cgn5SMHIyPxpdP12ytrJIr3VPtdwud0/2do93Jx8oGBgYH4Vk6+MlG8/e1vyuN/wBLW6Wvp0XUzfEMJxUquJhL3r8smn0+63Syem6S3N5wGU4qnJNFFIkLPiSXOxcHnHJqHURevCG06XbIP+We1Tv6d26Y5rn9ON7EtrcSxZs4d+xtw4zkH361yQoc0HLmXp1PGxOOqUsVDDxpNt2d7aWuk3o+ibu3azto07n/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAf1UlEQVR4Ae2dyZIdSVqFY7pDZkqqAShos17Ugh3GK/SOl+HxWLFhwyuwaYbeYNZWFFBDS8rh3pjw853f83oopSoNqbwsIs3Sr4fP4X7+MTzC63/8h2+qqvrd879L4W++/e8UHr758xTeXP8mhV19VPj8JoU/NFcpfL7dpbC5nBRepKC6udjoZ7hUMCr+alCZu7FJ4c2hI6wV3qnCYVZ8IhzGVinUGucUrfpRLc+kTyQ1g9LnSj+XzSGFL7Z3KeyaMYXPGcOzfYpWl3uN82JibKmGxt+ncNupfDvQQaVazawyVaPcZqDHWbn1pNzKcXqfiE9UbRjz1vFGP4da4x+OuscXo+bqlhZuZrXcHrYpvKjU/o4x/0f3LMX/5z816Kt/0ag0R+vfGWeg/v73f5+6//avtYYXvVb1x6+E4utGdHC4e6n0Sbj7bivkPtuKDuZnWu1xVvzVVuXHWqs69Wrn50YpN0eVf62q1eEo+nh5FGXcQhlDIEsp15Vw1E9CwxEEmQJScyml7YXKGkK4aNTvn0EHu53a/2IvlG2214rvhKnns8p3te6lm25TeFUrfcPdNVBSO6udqhZVdaTP4LQeoQ/iQXnQ0wQJ1LPurt3o7jpIZag0hkOtkX99VI83s3ocuPcdM/PV9kVK2Q5K7y+fp/BfG1HqX/2z7n2lgDQJ5/zrnsObhsNPaRQ3my8Vwh8HcHHYaIVn0DRvBOaRlHEjbE6DcivBomomYWrqdFFPQuW2Ve5FwxoLNNXuCGxa+CbREbROE5gCDR2UMc9GhnppGvHQplaFSzj7Hv67Bact1NBVwlS30RjaXuU31GrBeNuSzn01lgHQVu1cZEAae6oFKaZxiDIaxl9Ra+6ZB0sIRj4w8iMS60B4y2wckZoDnKCe1M7xThTQ0+NPrzTPx0Hh/vdfpHClgDQJ5/zr2ss59b+5fp7C3fYyhV//KI5524K7rbDct8L1PCoc4YNjDexnle/ggMO8T/EBvB8nyfo/UWuAQK5blXzZKv01ZUbwNYD920G9HBpLAo1nVlQkloIaMjOWn9Ua1bQRx7+CJo6tyl+gjTQ1dAB+R1NAJRqqoNr94NYE4GYWzTVQwESbNbQ1WzuyDKDfNJZUcuYu5klJdFvV5hPQ/UA7HsmYtJ5U/krItkZ3W2k+rWtdvJAk2PWiyPlL3cVKAWkSzvnX7cDIthV+Gzjv3aQ1HCfJ6AOaxtxrnbpLYadF+x5axecRHk2tGs29GoAuukSN5KjQghLhpPLTNfiFy49w1ZFaw5/UWg/WepsDoXWofPwBvGmjknUnLFfQaH2jMrW5/06dtXDkDly3aE0dWtzG3B+0Nqg4DVbCBhqqLXsYg+UBJKR+9EdrqG9pakigpKXIyHhq5iHbCiAbVakZNEsjPY5HKA8tcf8HzclKAZrNM/4lBi68N/DrA3z5GivueguaOiEacFQ7UL8xewangDhZAKCe9Z/hrYlJp1oTKsXUi78PoyjseFRfd6z6cBA/7UflXlPmxum2V7E5bZe26NoNaDKK7xALezT0cYQa4MUuj4qU6ogyWto01dpybqDglntsGPnWFVLp9AfSgwKcIpimhpB5jG1G/7Et3XPXiQBTkb3F4qj7MhlbcvRbqFbiqRqwdTCZqz99r3tfKUDzcsa/roED/gzDm+Hgxw78DoSs8Mi6tRtJ865SOmw29P0GPLb4Q2r0mfmota2oVb1WfMQ7NP5M3JbwUWt/pOSB8GhtyhQAjgLRtN+0Qvpxr7DfCWx9Bw8FbMNPosLhS6WPEGyL3T516mU288ZSTYIupdSk1A1aDYpSSCzjHenVMIbwCyGTZgMb7t9YU7KdDFUhXDIJAeyJ9IoyFS6kmXnYQmd7y4w0mvXvjDPQHXfilT0ennG4SvERjWLAXm33wkhTSSMa4YNTJ24+bASVfnihkJITvqADMuAwfpHSXw+CwfBSda97pby6e6YQ9E23yr0B+6+OavMGpNsCr0Ffix1gvaLaCPs7OP4NOL00z91Lp96CSnsle+vye7SjWjQ3TKKP0V4mgFrbPkBFG0PzUaO1ZQDIdTO2DxrucWY8E9qXa81Y3WMneTlac0OOTsitAc1nxu+0R06MyDZT5F2nEUIq6Xf9O9MMdFu4f49l22CjziARkFUtiLDcn2H89szUXm0wZUY3o/tXSILxoLWdbtXGeCsdYMCj2d/CwZE0I/r7EQvjcFD6gX5HMGUKaMB7SQFHPCoD+EV1quo71R1nwqPCCehOtDPhs5qRHzOWcBIIqYxt7GSepmhtzg7ft+7kMiYG2weNy9gXZNIw3RBvrXFZujBxDRrgbNuCDhlC6lccJbnMUtBiA60UoAk54183orP7edOM3biZpO3Yq2OveuZ6Wq0aa6CFf7UYhWOnVW3hjC0ocGh9YwZII/iy3XAkbhVDvDNhHzTdgRfrMBQJf4vRRMEkJwSwW8of0eKtyVjNMbxcEiacniLoyg7Zlp8Wikd8JKteI++MXOivplrUKppzyRlZ4rGFuoOWNeLF6rDVQXiSB+rBEmXGE4Wymfxm5BNO+GhXCtAKnfGvm9C775DUcyOdgWVObFCaQ0hzfIEtSO+wjdvGKyybIGBmfyHhgLUcbNMUxlPfyc9+aXnEez7Z2iAcQd9Y2AENetRsQFpC2BbFfp6sTSGZTMcTQ/fT5gn8Toxksr2qsaZnG8KgQzta60ClaAsGnn6N0xSJqJWVKAhoPSiLg8b2BJqS6cNIH016louUGfw8Ds7RrzKACT5z0A0wJ/Noc8Z4KgRnnKzvoyPZgz+yzres5x267SF0WVGD43cg7gZLuIcCruGJ11DANcgdQOgdKLgmvPE+CSkm2ecOETXGI2i6GDTGG/SoW2vcUMme8I4ej1LBEgULzfbRbum9t05FO7WtdCDdMhLTgTFu/m5ubqKouUc/ORiJ126HeZgZSUgFmpjxF4QWBJnM1GrJzSS92gFaqTP/da11VRZlwmsROwN48jWFP4RR2h9Cee8SGA9ScYNrO34nhE6YqrYGcig8jnda8wG9eMQbOgLX6UAuYEPRT00If7Wf1pqTwlwnUmwrTKRb3x/Rypxr7E94imypThfqcvb+H/ivn3zF8y/LFTNvdLYa6s8uTY3NNpCtHxPkbNIwtcE6IODkOoLysHuSCZ7qjvig7LWd6L22pc0Mr1pQmqJz/nUNa37J+s+sjPc92Mdp8I3ma1BJg/7TkbHFOzRuWEVkfYuE2FwrhYdpyZYWli8I5WnKWv9ESmvUY0km1STlWneKRxDkYmCEgvIMxF0Bwks0nC0iaw+HdRw3aGjcW6TXlidQHjMqewV5VIn8U4/mAdbZwyeK2YrSl/JVptpIJwzb2PawUtOf7nRmNlrs6rB+2BXRmftjV3XcXW1zgAmLeaaVNTjbDHQd+sC1lX+0kRlbN1YSvj+C0FCm7d0Gv6O94axzjYYbHnZsvARC3VYnb2XDQ6CGPWWtlYCwDwVpoyMwAjqsX9foLS0W77yV277B91lv1Wa7E2dviDulZudScGqeHs/sCp0vZNvP+Ivs/5l5Ijazp8h3OoH0TAf4lBiJadHPzqKkpUVqMWtZo5+vMQMkJwqFVNl7ai9DzV17L4VljPfZuRPXWsMzzEDaPCAe16HJjsYm1mzaeqDhQA21n/oGv3M66A79V6s42w4E9bUeAVQd3tDkqlccRGz2wuyWPXf2jJtivK8m9kuL2coE1x9Wbmv5BAXseL66wzrZbFRoA9Ixz5M/SqNqARXDSTt/dOHQdxEajvU936M1n6AAKnNz1nb8PKBGdDT2VlHSe4TsBchPEZAWVoaQlLO3EHlA1irx49Zhn+tW6S/9rn9nmoHO6+zeYeyJsenK8QjJdtwrFnFKNvYmkoFzMKkMUJWpgXALLnbw/R2VRzR961r2ApkCEENpQyZNoxJZj0qbPdMo9juFWxSdLa1t3D5kaTqwhmMKaP3cmLEZiA30hAG7uEdusZyM5Is1opVjth/Mn2SXD23NJXMSv6e6VqOs4+UiJxJjaJG8/pxhBkBO6tdLwmI1Dlluc0BzcPvKN6SHHYjct6+mMXeD63m3jDV97xryXgq3Zp09ctHib/Gc3DIIO0NNAbZUvbfHT1a/RAf/er5JQ/4LNLcOLfs57wF8xe6gL2yL8oSuQ0J4B9HOfJ/cjnu0FeL92KHvMw8GdPigKOl7N1o9P5kMVMElg0o8lVB80BnLGhNMvAxWCihn4wzxTAGsc148r64VEeKxuKRYZ2BB/XQs6/7SnRu0hdZ7InlYUL2U/r6tpLnvLiT3d/bjo+1MWJjWlIx6VH8/lA2zOCiAXRF79Kg9FsAF/N3WwGancSajJoUtRkSDAd14L6mfVRH6PYOsZvmOVNc+nBThjxTPSaSopOk+QibG7ZTpUZy6OV1pOa5qpoZMZ7nG+nuWGQgtyGsSdiCrBzZCTzDX8/hK701nzyJajZE1oRFdtEL9FZ79kXdmqllPf3nwFQoW5kdSDcQD91iMbORJ26s1ltleWO/DMGI6tfkM3f/Z5jbFL7aqu8HW3beydfdY4BuajvdqkFIep71etlG9r80ySegUKo36FA20Kpb/Au5cBpatCLpATJ8ujOvgJfy47qIFl6fuKgM8hWcLve0huresX4zFC2oZEIsr2jBesudEq+i4fY0te29gyFVje5W9CDseBRyt45s+COueHzQHPysOLciWsHGEXNlv1fsWe3iDPey3Fjp26Dekt3aowv29F7q2QzUcTKbtEyKN6OVd68olCrDeF1FapJd04Py3VVB5l7SdfN/SagkXU3GeaJYBrJvfCo9FNeoDB0JDoJ4Ue1S8I2wGDd5vY3/hBTx9jOel4t2bWTy6xbO0M3pgfhMyoMdzcjQFMBLvWpigG++Mm+Dml+jyV7zx8gI/bjNIuuzY8XmB7r+xvg8Bmi5bpIItW/v0U5X0Z4zPRmUB+HJvoOnDu0PMr6fgB25DoW0aW/Ul4bhJl4u46cNTTLjKgNM8niVmkzDL7hIL5fIVQ4tk5IHRkSWBeKvfrY33bEH6vJMF0KHVbO5Ue1P4edIGPNVC+Tew/O5x6EiBXMHG+zu34HqLRrSx7/NSFNbxDKvl7YEWW6HCMvD2CtsrfuPXb5bFnv14xJUaSH/lDSvua0M2nEFOKzMim6SI01gZON21nF6UXCmgnKozxEMLqgvsOx4hKPaCOQybgPW09egdElmz1j1s0TouwO8ETv2gYbZmYjXEfn/CHtuY7cxpX576cZH4QgPTYt/6Dj/rhWWJKQB5s8EC6Njban+nn+56Z6rfjo/nULQdz35p2UEJ0IfxnMIcQKqhEroy3DyXUVLIUXL5eMS92uQKDtXaSgHljJwhfu8LOvVtXIdvJBZaqxv6cnB/YdRfGHH6jFVsLcheQG+uqTfqosMywCSoRp6XGeR+ZNSgz5jmvH3fmkloZVDnjEbkHQ9+p2FLN7Yz/AZk610OFiB0n6WUxp9tF5DKXZimUxa5CovbPaUpo/wroV6mf1R8pYCPmrbHq/QGBRgpat548duwoefArywD/HQ/uStVFIQ2QNc0YQjGXns0dL+g6H07F6qTOlBfphXvO4rnYgU/jXacArHwgLnyW4YX9FuzI8FvKmwZzx5dxVgOCqCkd+mEeCHFjDn8+04Joihpg9EiC0XzGjm57t2ZnxCuFPAJk/cYVXmi+kZDwQiVWvL9e93kPt14D3CYnRc6RjxRsq6CXtSxG8DNB4VhHzRsojMW7LAJ/GIxhGxABvAYOH38RBLIjxtq7w6Czhq0I2tBHnns9smw1y0ZxcSyNz8uih+QThDFGZAT/A6PC9sLUFT84OhKAR88ZY9bIckAcTRboXm16YI1z9aAUswXbTxaNgDK9K0s5YS0MFLQQFp8MtZ0w0EJj0ZuRGuWAd6sb47v/XfWgoItB78W6mPPD4Pw7oqaNmvoz76pMO415PTGpFDrZwAef0kAZMa9G91lmewbdgvKMdXiueUqz0m6+Oi/lQI+euoep+IbWlAgQG0DiRlYBgQjSRlOt9psrh0qdLBwLNmgIRm7Vhz8LpUaz3+mANOf+17IAMYQMgDUxw4MSC+0LL+mHPoY1omB7fHTkeWB7ZLomVtywZLuqVQm5OJx73nc+dfl89XH/K4U8DGz9oh1SoaZmy2WNbAJOEMekOt4tgCUba+9EZp33ZBOE95fHZo+/YQWRNwUFrY3fZUywOAzNzfFNNBlvHPLTiH7drJMKm7A7TuhTI67KLIZRKj4JL+FEJxO6PGHFChbLsq8T3SlgPeZpc9YJsuAAKF7EggDgySEtmDGjs6zYPWkZ8+lwBCAQPUJKRI8FHjTphGUr08QciyQyIU9qWGBUyHXUkO20mkyBQyFvkIQnBpOdxRtqxZxp2QNULlRJJorKzvplHJqKwp/5M9KAR85cY9VLVNAtAe2WFyjLNsBcaVSXnpzTABnNSR8n7RjjmyLIe8xVgt+FyFjWQ2Za5f2tm1LYzPQQY/uthhH9qTbfMjDUv+RomigW9FMHpTMOr4z3KriLm924Dzf8KlETl22kFM//HelgA+fs0etsfAFBRLpwBgMTuouLQOMR8cJ/YjX7NOc3d+aDlBiD2dcC0kLvJsXu6hBXrJhp9B7YLBIcZuBcX4WY/Y4PXKHpLgdN+OuogWXX2SfKrv86Voxp8W4llkfcLVSwAdM1uco+oYMOHXhlc3a7gkBxktOp7wzCaMc0FraDSrpd6xC96Ahb1nLaHJr6tnYPPVKTgpiVGTEGCJJP9aXSkTbG5rfTinbo5rbIXSe68a3VAq6dCd5FP59W9qyxPtcrRTwPrP0GcskCjitZMSMiCKM/oGlkRIIdRmyjWtj2VzeJSMFaJUpgXq6jNMr3NppOPcjU5J79EispQTS8+AocxrQgoaKkft+Q1YFH6eJRe95pNF4LrdI9kUx3Fz4g35XCvig6Xr8wvcywFA8radjce3FLq1l4raWAx6UCYhYMcLxb5wu29FtRHpUIIWGlrjmhosyXEewaNODKEr+cjtR1y2VtSLF+aeMt7RWDuUT4isFfMLkPUbVoACvsHZZ5j+vfnDeEmxkRLp5a1ADNZ1Lcy4TurkzyQ0/DJiNMkFERaHg/24uj+mtvwuwUt7FouoC6/cNlBZP2dV9gSeLrBTwZFP99o6yDHgAFCcsk5dXapCUAnbuJJ5VcVHGnZvL+FeVF30tXPLklJ086KtsM7fkQqe6USbqukflvrMxVy2zSyFQpi+7/4irlQI+YtIes0qmgKLNWOx3rjPwKMpH1OXLWsQzl1cpx0swLUBY1C2iD3tappRFPTRray5V5i7rpatsDTy4o1+s9aCZT0pYKeCTpu/TK7+FAt7W6AOMuFAgxblFWKSXNct47uVtaUtenkueft9eJ+U/QO47S0Zjyo8yyJ7cQP499fm5YisFfK6Zfc9235MCHrb2a9h6WOP/eYpB/+S3tVLAmXERT8S88A+Xv0y39hIp4KWML/mvcrK2U8QLlWhRFz7slJiPov33mqGoXPDuIvprLSx6PhVeaFMqY63JpfO+6Id1lbLMPZXxoE7X3jl76nKNPfkMZBmwwMvpImKnhIWmUSYvR+4cVtqoJ7tIvS/uNIWORUYJkkXGfcVlxGVc6z3KL5svK6vZ5fWbzS2vl1fLQS2v1GfZr3NXGbCcpSe/Sts4WcPS/PUyEdoxE6NyupeszC0WMeREUbKUHG4nywauCgAt0suJcGtlyi/HP7B8Wdxs38+WFyRZjtMDZ0dIQJq3naNuOTY37ZAWYicHKX7yXExeWXONP9UM+CObabG9xMVCFyOIhfQP6UEZRUpRfBF9e4unIkUTRfSU/xQxOvZAyzEQz3sD3xxHOG0XE+HKRQhRxE7ykv8Xk7JSwJsz+8TXIQP83MpvcgXXRjYEXy7Yc+zGeajRBw2ZNWqJMxIUz0uef086tVMIT5mffRI8NneTqV9pTndKLuM7ElLj3gtukS0DDT3HaZXK0UI0yu0xkyYb75JaKYD5Ol8QdoDXZCjWNm9b0PrHHny/FBCvSZLu5XPlCFlnb3r23ogMJLXDfcZ+afcVVgKtPSEF5LFoQHmA+vU7mvl+Y7gqw71ntDLQcld2MA3KR6AypiTvlPXNRV8xESqa24xq689Tz0C2A8zxQaW/DNoT967/2NEfKV5LheaOvAqfqEQpcSYTdxHfKae4l9xYyLxSGW7/LRo0LXzOgGFFBzG6dOVUhyZp20nxxgMZIQkC9UrKgI56tOp4dHD/4zt1nuMrBdxPznkiyQ7QejiMs2JAtk9+M8qd60OEMkcT+mM9AyrCgc+ac+hkf28w1twIg9rcpsWEv2sVvTzRPBi16iysU/rNd5TH6/xUhozI9V1Q3uD3+CfmLdrFmM7fU2KuqJVn8jTnKwV4Is8WJgqAk/sLboDW59+mA8DSoGZezDU1NBxukU9hlPrkE0v54FuCAmsJpOPLmjTs81ICUZY0ofmAAsrEi/Qu9CRTYZzmDn3F/RL117nM5EUh6avXfOfFk9R7/ChMM5+5sPbo7/PGPHAXcT4shMOhemmu1ca25mQp7n2lgCdZ8Hd3ko6B1prUfNjcJ9yOvPY4cBzM3Ct38GrzbR9zzBEtOA5phxFa9TdqDGsfq2WdIVKAXEYWg8og1BhIeJqg6Paeo3tw6t8qfmCT5FD6GXoQgJP4Vm98i9SfgXHThD6H0A8dfbqOz/LoONEsHeWc+lop4GlW/J29dP52rU/BmHAGTfC1Hq7n7zCH/h5Lr8U1im3TxgkqyI+GFXVK2AemD8Ly29TGe6w/dReU8c4BP1bGid7y81u1bD0nvjzh+6Wgd7j6vqzJGOg+0bXmM0bxvVJmwOUnzinziXkdZxpPo3agu2TvWo91Q2s7HzcDXc8Z1Zb1Pu/QDhF/B6sape34tFCf81X7051IBWN2tgMFuomzfP1hq3hDRiiP75HDN0tL2Aw4a+JG1cfdyIfWOlFAKX1C07e/y1IJOrBuE7YLKXHSme/I6lF8/ksj8YGrk3VI5KjPTZsx/X2Gt/n/KgM+dOUeuXw3ckrFwEmNI9TQohEFBweU+Xv6RqiFvfQa80ofQeAvpm9sRSPljTFTlWtaltj/YzGSz/NW/tPKgNM8xlvBHmIkc3cR99hAKrc0MtCQfKh3TQ1nj0/IoFXO+qaj3zga+aKjbZ2Rw/6sF21WLei0COeLpRO16RyuPcD1/I3B2d9h5nu4LVTiE9tt/YZfiDWfLAPQZOwP8ZfOM2cXSIIC+A1Nw2kBe/JLtvyZZ8RaygL0jN8jLbW+PCjKEvgbj0Z0fKM0ZAaDxhdgLtEjCuZbzYDPdjJfSU7jlDJyBs4qAz7zUv9a8+mz4/JLTMM+hY3PX6RO36O9HMXR/AVQi3oOr0jnWaiQV28DU7eeYPk+4PHwp3QDa+DLZ0OGDIACSnkQZELvnzswrk0BmVLpk4zZp9CQnTU9ZdiTM4D3sPyNcc8VN1APKllzGIJ9YsORx47oQrcbyYU9Z+bUcI6VApj38wWd/TwDZz0e4elHFmWwI4OQg17SlznFy6ZwbQgeA1/rnHFz2OvZg44jsDHKQoP2RejUGXlV5a+qm/O6yBNNBYLI47C6H/QXg1BOPLuG1u0P9imxPWQbFMDp4OH3t3eIRlGOqiOzMXLGhwXlkZM+Rk76GNGSVgp4ohV/VzfdM04pfT1fphLDqG/7h3bP0sx8o9x+DOutLeRg83mCYurYA6EK9iP5REmfaGcOa83Hz1dtTxpq9g6VKe8a6COnx4BoNaiziJubB4HwExSje/RpaLYD4gSFRn5NNznD8Rtkg7/13iERKywDjlOrdnzlfeyRu3S7BmebgW6EK22vJKlHePoG9cV8v4dP9UeBZIRh+6u1PbqtvyPestCWAeZoPZiKjzrDYsOWLmSAYRd8loswCc4wFR5L0TG8uzRRLKxqjsoc0XBCf+N0zGaSbhMnVtaygWfzd8uPLSepQRNfYgnvOG22mnQuuGes6HuNPu0MdHssN5898R3yutu/SGO44/TrGw4+6u90XuOW1baHr4av2fd5bLXmNb5v2wR+poZDKOVojYM/QgHpkj/x1rz+ij/AoYt91vDUp/cwWxrZLWUKiNC6P/p7enyoMcXzQe4OFaeGacw9vIST7putDoxqxpcpvBx0jyO0crVTCz9snyk3/a9/Z5yB7tbn9E7fp0HUnU4p2sG8f57EwJoDGBnE4wYeAXNoYwKBVi6OjUG+p8opJXSeg3whHKKdfsFI+k0pBQUYe5ESFxR6yoB+M/YZYZgDUKSCuA7fV4tNa+Hmpx2cgtlA7A10MEEBQ6PTY3cKQqvcc+Lx9ZWqdfWrFLYvv07hSgFpEs751/nU33YjPv7F4bcp/Ms70cG3o2T03XPZdN81sg/mC6V0PBFr/MTYW4LgjDaQG7jbrfcU4UM1bw/KCAo4cfwl9IFc6uPz/7lfjy16Ky0DkkqtrOV+O2x+n4E8Gbu38AzOta+RCiMSsTt+mdp4zvPE7SgJelWJevZHzedvoaEN87NSQJqQc/51f+y1Pn/zXBJ5819aj/qVZPQA3o9b5XYHpd/ciALqreJNI4oZ4zmwLDprPtVR5fvXQth4nYJEOIqXdoDZqjG42Gl8Fj2IMaagxLs5f6QEWWq8rXdvYAPZsq0PwnWLF9knYg69Zm/Cx3xXawp2rcLmIF/DNz9Kmv747DaF//tHUcNKAWkSzvnX/eHfv0v9/9vLv03hV1st926n9bk9SAsaXl0pPkqcf42BewGn23Vaea11Wn/W3HvlqhvVGrESbDNnPgsdGPxa+PQHtCAEU4NTzxA+4P6LMSC3bB809upsjFrxAHu3Jvj7ATSjAFY1c9jX4gfHrzSHm0vNzA943l5df5vi//T6dQpXCkiTcM6//wPP2BONIa2VNQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDjaKKK+xPTCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAopyo752qzY9Bmho3QZZGA9xWftYKXJzK/Ynnje19RtFFFaFBRRRQAUUUUAFFFFABRRRQAUUUUAFXrazGN8o57Ke31qGzj8ycE9F5/GtOvkeIs2qUpfVaLs92+vp/n/AMOeLmeMlB+yg7dwAAAAGAKKKK+KbueEVbizV1LRgK3oOhrOIIJBGCK26z7+PDiQfxcH619hw7m1SVRYSs7p7N7+np2+49rLMZJy9jN37f5FSiiivsz3QooooAKKKKACiiigAooooAu6f/y0/D+tXqyrWURTgnoeDWrX53xJQlTxzqPaSTXyVv0Pmc0puOIcns/+GCiiivnzzgqrf/6hf97+hq1WdfSh5Qg6J/OvayChKrjoNbR1f9ep3ZdTc8RG3TUq0UUV+lH1IUUUUAFFFFABRRRQAUUUUAFW7a78sbJMlex9KqUVy4zB0cZT9lWV1+K9DGtQhWjyTRspIkgyjA/SlZlQZZgB7msWivmnwnDmuqrt6a/ff9Dy3k0b6T09C7cXoKlYieerf4VSoor6LA4Chgqfs6K9X1fqenQw9OhHlgj/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAC8klEQVR4Ae2d0U3DMBRFC2IcRmALxkBiGPZAYggGoxWtkziO7fQlHKEcfnBS+110Ti7wUcTD2/PXyQ+OwCMXbfKFgALg50ABCoAJwPE2QAEwATjeBigAJgDH2wAFwATgeBugAJgAHG8DFAATgONtgAJgAnC8DVAATACOtwEKgAnA8TZAATABON4GKAAmAMfbAAXABOB4G6AAmAAcbwMUABOA422AAmACcLwNUABMAI63AQqACcDxNkABMAE43gYoACYAx9sABcAE4HgboACYABxvAxQAE4DjbYACYAJwvA1QAEwAjrcBCoAJwPE2QAEwATjeBigAJgDH2wAFwATgeBugAJgAHG8DFAATgONtgAJgAnC8DVAATACOtwEKgAnA8TZAATABON4GKAAmAMfbAAXABOB4G6AAmAAcbwMUABOA45/g/H8V//3+uvT1vnx8Lr1Uv//g/xOuAzq/WuE+P7vWhALmDIc7q9APx06nfg0KGHMb1nejH0b0afC3oDGx63oT+udZPXMUkAvooZafWb5uTlPABF6T12R330V9pgIGinVSw771q8pkBVxxVhitB144sTRfARdYS3QKIAO3iikKCBDd4qgC/ujx/5U1L4ECtniMAzOOLmD+SAZgdh3NEo8uoIvZnpsUsCfdjtmHFpB9N+jAtc2Wce6hBWyDMzZFATF+4dMKCCOMDVBAjF/4tALCCGMDFBDjFz6tgDDC2AAFxPiFTx9aQP+bR8KcJwPGuYcWMKECXSgAAn+LPbqA8XeDG5N9P2eJRxewL+yO6QpY8T7ODp6NLdnjf96tgAayvV9WwIXw/MHcg3sxRQFX1EU6G2pYmq+AAfISo2HHvavKZAVMoFZITfatuajPVEDOss4r3926bk5TQAFhk1rhTOlWzxz/RKlE7nZv/PaF272uzz3ofwcpoA10lYZ+9Apoo892VEys5Z4m24CEgln4Q5jhnlIVkFAwCwUw3FOqAhIKZqEAhntKVUBCwSwUwHBPqT96M1YzgQ+U0QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDYooor8/OkKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKhnnEK+rnoKoSTySZ3McHsOld2GwFSuubZHj4/OqGDl7O3NLsv1Zq0VjAkHIOCKsRXboQHO5ffrXRVymcVeEr/gcWH4lozly1YOPne/36I0aKRWDqGU5B70teU007M+kTUldbBRRRSGFFFFABRRRQAUUUUAFIzBVLHoBmlqG7/49n/D+daUoc9SMX1aMMTVdKjOouib+5Gc7F3LN1JptFFfYJJKyPy6UnJuT3YUUUUCLVlIVkMfZv51frJh/wBfH/vD+da1fPZrTUaqkuqPuOHK0p4Zwl9l6fMKKKK8w+hCiiigAooooAKKKKACmyIHjZT3GKdRTTcXdEyipxcZbMxyCrFT1BwaStG5thKNy8OP1qgyMjbWBB96+pwuKhXjdb9j85zDLauDqNNXj0f9dRtFFSxW7ykYGF/vGuidSNOPNN2Rx0aNStNQpq7Y+zj3zbuy81o02ONYkCqOP506vl8ZiPb1eZbdD9DyvA/U8Oqb3er9QooorlPRCiiigAooooAKKKKACiiigApCAwwwBHoaWihO2qE0mrMYIowciNQR7U+iim5OW7JjCMPhVgooopFhRRRQAUUUUAFFFFAH/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAACqklEQVR4Ae2bQU7jUBAFAXGJXIoLcD5YsMyluAZGlr4cRUqk7+4uuV2zckbjX54qP5gF8/r9c3nxF2fgjUNL/jdgAPg9MIABYAMw3gUYADYA412AAWADMN4FGAA2AONdgAFgAzDeBRgANgDjXYABYAMw3gUYADYA412AAWADMN4FGAA2AONdgAFgAzDeBRgANgDjXYABYAMw3gUYADYA412AAWADMN4FGAA2AONdgAFgAzDeBRgANgDjXYABYAMw3gUYADYA412AAWADMN4FGAA2AONdgAFgAzDeBRgANgDjXYABYAMw3gUYADYA412AAWADMN4FGAA2AONdgAFgAzDeBRgANgDjXYABYAMw3gUYADYA412AAWADMN4FGAA2AONdABzgHeZv8J+Xj82nm8uv3+vN50Yf+AAPvA/P48/0K0EGGFqH6KcX6y2dMjABJtRv23TKAHwT3ml/lIg6ZxyIXFQHiLUWe1r/ABm+Ms6sLFG3gDxTeScXlCgKkO0o+/y8EhUBauzUUMJLVAQIf+hOB6YHqHwxK1lRL0F6gKgH7XpOboD6V7KeuPPNyA2w8+HOcLsB4MqJAaivBhR3rmRigLkHOttdBoCLG8AAsAEY7wIMABuA8S7AALABGJ+4AOqHRyjuXMnEAHMPdLa7DAAXzw1Q/9WgnrgzYG6AnQ93htvTA1S+kpWsqJcjPUDUg3Y9pyJAzYtZQwl/DyoCLA+dbSf7/HDv48CiAKkNjmt/0VIXIKnBoe1XBwhvcHT7QIDABg3sLzaY/6K0upv+8YUe6hf7WICVPZGhk/pVArOAlb3NsFw/GEQ/78MAH2A8SmPL4+94f1H6z9B7vL9jAPgdMIABYAMw3gUYADYA412AAWADMN4FGAA2AONdgAFgAzDeBRgANgDj/wDou1i30UP8bgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCvRRRXwZ+ohRRRQAVFcXMNpEZZ5VjQd2PX2HqfaodS1CLTLMzyAtztVR/E3p7dK4G8vJr+5aedsuegHRR6D2r3MpyaeOvOT5YLr39P8zgxmOjh/dWsjrZPFenJIVVZ5AP4lQYP5kGprXxHp10QplMLE4AlGO3XPT9a4SivpJcM4Jxsm0+9/wDgHmLNa6d3Y9RoridD1xtPcW9wS1qx+pjPqPb1H+T21fIZlltXAVeSeqez7/11R7OGxMMRDmjv1QUUUV5x0hRRRQAUUUUAFFFFABRRRQBxfiq6M2prACdsCAYIH3jySPwx+VYVa/iWN01yZmGBIqsvPUYA/mDWRX6nlUYxwVJQ25V971f4nyeLbded+4UUUV3nMFd34cujdaPEGJLRExEkAdOmPwIrhK7XwpG6aQWYYEkrMvPUYA/mDXzvE0YvBJvdNW/E9PKm1XsuxuUUUV+fn0QUUUUAFFFFABRRRQAUUUUAYfiTS3vrZZ4E3TxdQOrL6e5HYfWuKr1GsPVPDcN9I88D+TO3JGPlY+/oTxz+lfVZJncMPD6viPh6Pt5PyPJx+AdR+0p79UcVRWvJ4a1RJCqwrIB/EsgwfzwamtfCt9MQZ2SBc4OTubp1AHH619TLNcFGPO6sbet39y1PJWErt25GZVnZzX9ysEC5c9Seij1PtXoltbx2ltHBEMJGu0e/ufeodP0230yExwKfmOWduWb61br4jOc2+vTUYK0I7efn/ke7gcH9XjeXxMKKKK8M7wooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAADJUlEQVR4Ae2by00DQRAFMSI9yIAkCIQkCIHguLLCkmUJ+Wm9nureT/mALJ53Xm/VjPHBnH7enp989BGQfh/7v2YFKKCZQHO9J6BZwEtz/4369++PG8nT1+vnrWiLvz+t6lNQ4P4f7j5MrEXAXeivZWxdQ7+Axej3oaH5j/AQ+pOJUetcS6153ilgLLWxq9XQn1raBBC8iDVpEz0COFLcypCJBgE0I3r9sSaqBdTQqWkZYqJawJCh97RIqYDKjVnZ9ciGKBXwyKB7vbZOQP2WrG9csEvqBCwY7giXKKDZcpGArneDrt75VosEzB/oaK9UQLNxBSigmUBzvSdAAc0Emus9AQpoJtBcX3QCur480tU732qRgPkDHe2VCmg2Xieg/t2gvnGBzDoBC4Y7wiWlAiq3ZGXXIxulVMAjg+712moBNRuzpmXInqgWMA1N06HXH8L9skiDANTBtuhPKHoEQA42R79TwHAHW6TfLGCgg43Snwj0/4vSNMT0WPz1he2iP9/4WgScp7lLw9bRr1HAeabpZzCxD+6XO13XCbiMdZwnbR9Dj4M436kCMh88VQCOOBcoIPPBUwXgiHOBAjIfPFUAjjgXKCDzwVMF4IhzgQIyHzxVAI44Fygg88FTBeCIc4ECMh88VQCOOBcoIPPBUwXgiHOBAjIfPFUAjjgXKCDzwVMF4IhzgQIyHzxVAI44Fygg88FTBeCIc4ECMh88VQCOOBcoIPPBUwXgiHOBAjIfPFUAjjgXKCDzwVMF4IhzgQIyHzxVAI44Fygg88FTBeCIc4ECMh88VQCOOBcoIPPBUwXgiHOBAjIfPFUAjjgXKCDzwVMF4IhzgQIyHzxVAI44Fygg88FTBeCIc4ECMh88VQCOOBcoIPPBUwXgiHOBAjIfPFUAjjgXKCDzwVMF4IhzgQIyHzxVAI44Fygg88FTBeCIc4ECMh88VQCOOBcoIPPBUwXgiHOBAjIfPFUAjjgXKCDzwVMF4IhzgQIyHzxVAI44Fygg88FTBeCIc4ECMh88VQCOOBcoIPPBUwXgiHOBAjIfPFUAjjgXKCDzwVMF4IhzwS+98lYz6FiO9QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD2Siiiuw8EKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKQuqnBYD6mgBaKQMrfdYH6GloAKKKKACiiigAooooAKKKKACiiigAoJwMmiq90+FCDv1oSuVGPM7DJbgscISF9fWoKKK0SsdsYqKsgBwcirENwc7XPHY1XooauEoqSszSoqK3fdFg9V4qWs2cMlZ2CiiigQUUUUAFFFFABRRRQAVUuv9aP92rdQ3KbkDD+GnHc0pO0inRRRWh2hRRRQBZtP4/wqzUcCbIgD1PJqSs3ucNR3k2FFFFIgKKKKACiiigAooooAKKKKAK0tsSd0ePpVcqVOCCPrWjRVKRtGs0rMzlRnOFBNWobfadz4J7D0qeik5XFOs5KyCiiikZBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAH/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAACsElEQVR4Ae2bMW7CQBQFkygF58j921yHc1CkiCNLK2Rk7Bjvzlt7qIwx+75n9iEKeP++/bz54Ah8cNEm/xFQALwPFKAAmAAcbwMUABOA422AAmACcLwNUABMAI63AQqACcDxNkABMAE43gYoACYAx9sABcAE4HgboACYABxvAxQAE4DjbYACYAJwvA1QAEwAjrcBCoAJwPE2QAEwATjeBigAJgDH2wAFwATgeBugAJgAHG8DFAATgONtgAJgAnC8DVAATACOtwEKgAnA8TZAATABOP4Tzv9//OV6m3vT7esy91Ls+W4EPOFe4JZrOjLRgYCCtYBePBjf0oWGaAEb0N+76UJD7regF+kXE3utUxbc9yBUwL7U9l3t+AJq8Kqx5i4m4hpQj1S9lV8xkSWgNqPa628wESSgDZ02KetNBAlYP/SRrkwR0HJjtsxa3CspAhYHPeoFEQLab8n2iXMbKELA3HBnOK8A2DIvgPo0oHInwnkBk4HO9lQBsHEFKAAmAMfbAAXABOB4G6AAmAAczzeA+vEIlTsRzguYDHS2pwqAjUcIaP9p0D5xznOEgLnhznA+RUDLLdkya3EPpQhYHPSoFwQJaLMx26Ss3y5BAoaha9Opvf567uXKLAFVHQTSH+43TkAlB5n0QwXs7iCWfq6AHR0k0x9uM/ovSiO7zT9fCEc/0E8XMI64QUMX6Me7i27AOOK9huH4SSE64l5urRsBZeIeKZfhHw8Sv4Y+TnngMwqA5SpAATABON4GKAAmAMfbAAXABOB4G6AAmAAcbwMUABOA422AAmACcLwNUABMAI63AQqACcDxNkABMAE43gYoACYAx9sABcAE4HgboACYABxvAxQAE4DjbYACYAJwvA1QAEwAjrcBCoAJwPE2QAEwATjeBigAJgDH2wBYwC9JQljbXRyMeQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder.eval()\n",
    "for image in dataset_test:\n",
    "    result = autoencoder(image)\n",
    "    tensor_to_image(image.data).show()\n",
    "    tensor_to_image(result.data).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
